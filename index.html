<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Kai Lim" />

<meta name="date" content="2022-03-05" />

<title>Investigating the causal risk factors for self-harm by integrating Mendelian randomisation within twin modelling</title>

<script src="site_libs/header-attrs-2.13/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Investigating the causal risk factors for self-harm by integrating Mendelian randomisation within twin modelling</h1>
<h4 class="author">Kai Lim</h4>
<h4 class="date">03/05/2022</h4>

</div>


<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>This is an RMarkdown document to record the steps taken to obtain the results for the MR-DoC project. We will first prepare the data.</p>
<div id="setting-up" class="section level2">
<h2>Setting up</h2>
<p>Load libraries and data wrangling</p>
<pre class="r"><code>rm(list=ls())
path&lt;-&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/data/486 Kai Lim self harm aetiology 030920.sav&quot;
Sys.setenv(OMP_NUM_THREADS=parallel::detectCores()) #this has to be before loading the library OpenMx

library(foreign)
library(data.table)
library(OpenMx)
library(tidyverse)
library(reshape2)
library(kableExtra)
library(rqdatatable)
library(fmsb)
library(MASS)
library(plyr)
library(gee)
library(fastDummies)
mxOption(NULL, &quot;Default optimizer&quot;, &quot;SLSQP&quot;) # SLSQP is a better optimizer for ordinal data

##### [/] read data and data cleaning #####
self_harm_data_c&lt;-read.spss(path,verbose=T,to.data.frame = T)

# recode factors as numerics for self-harm measures so that it&#39;s easier to recode &quot;no&quot; to zero 
SH_index&lt;-c(&quot;u1cslfh021&quot;,&quot;u1cslfh022&quot;,&quot;u1cslfh031&quot;,&quot;u1cslfh032&quot;,&quot;u1cslfh041&quot;,&quot;u1cslfh042&quot;)
self_harm_data_c[,SH_index]&lt;-mutate_if(self_harm_data_c[,c(SH_index)],is.factor,as.numeric)#import as numeric values for all columns

#recode so that no=&quot;0&quot;
self_harm_data_c$u1cslfh021=self_harm_data_c$u1cslfh021-1
self_harm_data_c$u1cslfh022=self_harm_data_c$u1cslfh022-1
self_harm_data_c$u1cslfh031=self_harm_data_c$u1cslfh031-1
self_harm_data_c$u1cslfh032=self_harm_data_c$u1cslfh032-1
self_harm_data_c$u1cslfh041=self_harm_data_c$u1cslfh041-1
self_harm_data_c$u1cslfh042=self_harm_data_c$u1cslfh042-1


#bring zeros from SH question into NSSH and SSH.
self_harm_data_c &lt;- mutate(self_harm_data_c, 
                           NSSH1 = ifelse(is.na(u1cslfh031)&amp;u1cslfh021==0,
                                          u1cslfh021,u1cslfh031)) 
self_harm_data_c &lt;- mutate(self_harm_data_c, 
                           NSSH2 = ifelse(is.na(u1cslfh032)&amp;u1cslfh022==0,
                                          u1cslfh022,u1cslfh032))
self_harm_data_c &lt;- mutate(self_harm_data_c, 
                           SSH1 = ifelse(is.na(u1cslfh041)&amp;u1cslfh021==0,
                                         u1cslfh021,u1cslfh041)) 
self_harm_data_c &lt;- mutate(self_harm_data_c, 
                           SSH2 = ifelse(is.na(u1cslfh042)&amp;u1cslfh022==0,
                                         u1cslfh022,u1cslfh042))


#reverse code TEPS (hedonia) into anhedonia
self_harm_data_c$pcbhtepstr_1=50-self_harm_data_c$pcbhtepst1
self_harm_data_c$pcbhtepstr_2=50-self_harm_data_c$pcbhtepst2</code></pre>
</div>
<div id="data-preparation-prs" class="section level2">
<h2>Data preparation: PRS</h2>
<p>Now we prepare the data for polygenic scoring analyses by giving shorter column names for the polygenic scores</p>
<pre class="r"><code>#add new columns for multiple PRS, easier names
self_harm_data_c[c(&quot;SCZ001&quot;  , &quot;SCZ030&quot;  , &quot;SCZ100&quot;, 
                   &quot;ADHD001&quot; , &quot;ADHD030&quot; , &quot;ADHD100&quot;,
                   &quot;MDD001&quot;  , &quot;MDD030&quot;  , &quot;MDD100&quot;, 
                   &quot;INSOM001&quot;, &quot;INSOM030&quot;, &quot;INSOM100&quot;)]&lt;-
  self_harm_data_c[c(&quot;SCZ_Pardinas2018_FRCT0.01&quot;, 
                     &quot;SCZ_Pardinas2018_FRCT0.3&quot;,
                     &quot;SCZ_Pardinas2018_FRCT1&quot;,
                     &quot;ADHD_PGC2017_FRCT0.01&quot;, 
                     &quot;ADHD_PGC2017_FRCT0.3&quot;, 
                     &quot;ADHD_PGC2017_FRCT1&quot;,
                     &quot;MDD_excl23andme_PGC2018_FRCT0.01&quot;,
                     &quot;MDD_excl23andme_PGC2018_FRCT0.3&quot;,
                     &quot;MDD_excl23andme_PGC2018_FRCT1&quot;,
                     &quot;Insomnia_Hammerschlag2017_FRCT0.01&quot;,
                     &quot;Insomnia_Hammerschlag2017_FRCT0.3&quot;,
                     &quot;Insomnia_Hammerschlag2017_FRCT1&quot;)]</code></pre>
</div>
<div id="data-preparation-twin-modelling" class="section level2">
<h2>Data preparation: twin modelling</h2>
<p>The code chunk below shows the data preparation steps taken for twin modelling. These steps were repeated in each twin modelling R script.</p>
<pre class="r"><code>### fill in blanks for missing co-twin&#39;s age. 
#fill in co-twin&#39;s age as proxy
self_harm_data_c &lt;- mutate(self_harm_data_c, 
                           age1 = ifelse(is.na(u1cage1),
                                         u1cage2 , u1cage1))
self_harm_data_c &lt;- mutate(self_harm_data_c, 
                           age2 = ifelse(is.na(u1cage2),
                                         u1cage1 , u1cage2))

self_harm_data_c &lt;- mutate(self_harm_data_c, 
                           age_161 = ifelse(is.na(pcbhage1),
                                            pcbhage2 , pcbhage1))
self_harm_data_c &lt;- mutate(self_harm_data_c, 
                           age_162 = ifelse(is.na(pcbhage2),
                                            pcbhage1 , pcbhage2))

## regress out effect of PCs, chips for PRS, and standardise them.
# the steps:
# 1. regress out sex, age, PCs and chips 
# 2. then standardise the PGS. Do this for all twins because not all twins within a pair were genotyped
# which resulted in unequal sample size between t1 and t2. 

#create a column for sex and age corresponding to the PRS columns
self_harm_data_c&lt;-mutate(self_harm_data_c, 
                         PGS_sex=ifelse(genotyped1==1,sex1,
                                 ifelse(genotyped1==0,NA,NA)))

self_harm_data_c&lt;-mutate(self_harm_data_c, 
                         PGS_age=ifelse(genotyped1==1,age_161,
                                 ifelse(genotyped1==0,NA,NA)))

#regress out effects of batch, PCs, age and sex for MDD PRS
self_harm_data_c$MDD100_res&lt;- 
  scale(residuals(lm(self_harm_data_c$MDD100~ 
                       self_harm_data_c$Batch+     
                       self_harm_data_c$PC1+
                       self_harm_data_c$PC2+
                       self_harm_data_c$PC3+
                       self_harm_data_c$PC4+                
                       self_harm_data_c$PC5+
                       self_harm_data_c$PC6+
                       self_harm_data_c$PC7+      
                       self_harm_data_c$PC8+
                       self_harm_data_c$PC9+
                       self_harm_data_c$PC10+
                       self_harm_data_c$PGS_sex+
                       self_harm_data_c$PGS_age,
                       na.action=&quot;na.exclude&quot;)))

## same steps for ADHD
self_harm_data_c$ADHD100_res&lt;- 
  scale(residuals(lm(self_harm_data_c$ADHD100~
                       self_harm_data_c$Batch+ 
                       self_harm_data_c$PC1+                                                
                       self_harm_data_c$PC2+
                       self_harm_data_c$PC3+
                       self_harm_data_c$PC4+
                       self_harm_data_c$PC5+
                       self_harm_data_c$PC6+
                       self_harm_data_c$PC7+
                       self_harm_data_c$PC8+
                       self_harm_data_c$PC9+
                       self_harm_data_c$PC10+
                       self_harm_data_c$PGS_sex+
                       self_harm_data_c$PGS_age,
                       na.action=&quot;na.exclude&quot;)))




#### [/] make PRS data wide format so that twin modelling can be conducted ####
# I referred to this website:
# http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/ 
testdata&lt;-self_harm_data_c[,c(&quot;randomtwinid&quot;, &quot;twin&quot;,&quot;ADHD100_res&quot;, &quot;MDD100_res&quot;)]

for (id in seq(from=1,to=length(testdata[,&quot;ADHD100_res&quot;]),by=1))
{if (testdata$twin[id]==1) 
{ testdata$ADHD100_res_t1[id]&lt;-testdata$ADHD100_res[id]
testdata$ADHD100_res_t2[id]&lt;-testdata$ADHD100_res[id+1]}
  else if (testdata$twin[id]==2) 
  {testdata$ADHD100_res_t1[id]&lt;-testdata$ADHD100_res[id]
  testdata$ADHD100_res_t2[id]&lt;-testdata$ADHD100_res[id-1]}
  else{print(&quot;something&#39;s wrong&quot;)}
}


for (id in seq(from=1,to=length(testdata[,&quot;MDD100_res&quot;]),by=1))
{if (testdata$twin[id]==1) 
{ testdata$MDD100_res_t1[id]&lt;-testdata$MDD100_res[id]
testdata$MDD100_res_t2[id]&lt;-testdata$MDD100_res[id+1]}
  else if (testdata$twin[id]==2) 
  {testdata$MDD100_res_t1[id]&lt;-testdata$MDD100_res[id]
  testdata$MDD100_res_t2[id]&lt;-testdata$MDD100_res[id-1]}
  else{print(&quot;something&#39;s wrong&quot;)}
}

#merge the wide data for PRS with original dataset
merged_data&lt;-merge(self_harm_data_c,testdata[,c(1,5:8)],by=c(&quot;randomtwinid&quot;))

# let OpenMx know they are ordinal variables/factors
merged_data$SH1&lt;-mxFactor(merged_data$u1cslfh021, levels=c(0:4) )
merged_data$SH2&lt;-mxFactor(merged_data$u1cslfh022, levels=c(0:4) )
merged_data$NSSH1&lt;-mxFactor(merged_data$NSSH1, levels=c(0:4) )
merged_data$NSSH2&lt;-mxFactor(merged_data$NSSH2, levels=c(0:4) )
merged_data$SSH1&lt;-mxFactor(merged_data$SSH1, levels=c(0:4) )
merged_data$SSH2&lt;-mxFactor(merged_data$SSH2, levels=c(0:4) )</code></pre>
</div>
</div>
<div id="descriptive-statistics" class="section level1">
<h1>Descriptive statistics</h1>
<p>Now the data prepraration has been done, we explore the descriptive statistics. The code chunks below were used to generate Table 1, Table S1 and Figure 1.</p>
<div id="average-age-of-twins" class="section level2">
<h2>Average age of twins</h2>
<p>We first calculate the mean age of twins at adolescence and young adulthood.</p>
<pre class="r"><code> ## mean age for 21 yo
psych::describe(merged_data$age1,na.rm=T) # 22.3 years, sd = 0.92, range = 4.73
## mean age for 16 yo
psych::describe(merged_data$age_162,na.rm=T) #16.3 years, sd=0.69, range = 6.43</code></pre>
<p>At adolescence, the mean age is 22.3 years (SD=0.92), whereas at young adulthood the mean age is 16.3 (SD=0.69).</p>
</div>
<div id="figure-1-flowchart" class="section level2">
<h2>Figure 1: Flowchart</h2>
<p>The code chunk below was used to generate information for Figure 1, a flowchart that shows the number of twins in the analyses.</p>
<pre class="r"><code>#complete data where zygosity of twins are known
complete&lt;-subset(merged_data,!is.na(randomtwinid)&amp;!is.na(zygos))
table(merged_data$zygos) # 1 = MZ, 2 = DZ
## 
##     1     2 
##  6522 11590
table(complete$zygos) # test if it&#39;s the same
## 
##     1     2 
##  6522 11590
sum(table(complete$zygos))
## [1] 18112
#initial twin sample - 18,112 (6522 MZ, 11590 DZ)

number_of_twins_involved&lt;-subset(complete, # with known zygosity
       ((genotyped1==&quot;1&quot;)| # with genotype data
        (!is.na(pcbhmfqt1)| #child-rated MFQ # at least one MH data at age 16
        !is.na(ppbhmfqt1)| #parent-rated MFQ
        !is.na(ppbhconnt1)| #parent-rated ADHD
        !is.na(pcbhprndt1)| #paranoia
        !is.na(pcbhcapst1)| # caps
        !is.na(pcbhcgdst1)| # cognitive disorganisation
        !is.na(pcbhgrndt1)| # grandiosity
        !is.na(pcbhtepst1)| # TEPS
        !is.na(ppbhsanst1)| # SANS
        !is.na(pcbhinsomt1))|
         !is.na(NSSH1)|!is.na(SSH1))) #no missing self-harm data

dim(number_of_twins_involved) #15766
## [1] 15766   442
table(number_of_twins_involved$zygos, useNA=&quot;always&quot;) #5409 MZ, 10357 DZ
## 
##     1     2  &lt;NA&gt; 
##  5409 10357     0
prop.table(table(number_of_twins_involved$sex1)) #53.6% females
## 
##      0      1 
## 0.5359 0.4641

#twins who were genotyped among the twins used
complete1.5&lt;-subset(number_of_twins_involved,genotyped1==&quot;1&quot;)
dim(complete1.5) #10,319
## [1] 10319   442
table(complete1.5$zygos) #2670 MZ, 7649 DZ
## 
##    1    2 
## 2670 7649
prop.table(table(complete1.5$sex1)) #51.9% females
## 
##        0        1 
## 0.518558 0.481442
complete1.6&lt;-subset(number_of_twins_involved,genotyped1==&quot;1&quot;&amp;pcbhdata1==&quot;1&quot;)
dim(complete1.6) #6001
## [1] 6001  442
table(complete1.6$zygos) #1510 MZ, 4491 DZ
## 
##    1    2 
## 1510 4491
DZtwin&lt;-complete1.6%&gt;%
  filter(zygos==2)


freq_table&lt;-DZtwin%&gt;%
  dplyr::select(randomfamid,DZtwinpair)%&gt;%
  dplyr::filter(DZtwinpair==1)%&gt;%
  dplyr::group_by(randomfamid)%&gt;%
  dplyr::tally()

table(freq_table$n) #1992 complete pairs of DZ twins
## 
##    1    2 
##   29 1992

#now filter out twins without even 1 MH data at age 16
complete2&lt;-subset(number_of_twins_involved,
        (!is.na(pcbhmfqt1)| #child-rated MFQ
        !is.na(ppbhmfqt1)| #parent-rated MFQ
        !is.na(ppbhconnt1)| #parent-rated ADHD
        !is.na(pcbhprndt1)| #paranoia
        !is.na(pcbhcapst1)| # caps
        !is.na(pcbhcgdst1)| # cognitive disorganisation
        !is.na(pcbhgrndt1)| # grandiosity
        !is.na(pcbhtepst1)| # TEPS
        !is.na(ppbhsanst1)| # SANS
        !is.na(pcbhinsomt1)))#insomnia
dim(complete2) #10,251
## [1] 10251   442
sum(table(complete2$zygos))
## [1] 10251
table(complete2$zygos, useNA=&quot;always&quot;) #3689 MZ, 6562 DZ
## 
##    1    2 &lt;NA&gt; 
## 3689 6562    0

complete2.5&lt;-subset(complete2,!is.na(age_161))
dim(complete2.5) #10,233
## [1] 10233   442
sum(table(complete2.5$zygos))
## [1] 10233
table(complete2.5$zygos, useNA=&quot;always&quot;) #3861 MZ, 6552 DZ
## 
##    1    2 &lt;NA&gt; 
## 3681 6552    0


# now filter out twins without self-harm data
# Use &quot;number_of_twins_involved&quot; first version
complete3.5&lt;-subset(number_of_twins_involved,
                  !is.na(NSSH1)|!is.na(SSH1))
dim(complete3.5) #9295 total
## [1] 9295  442
table(complete3.5$zygos) #3401 MZ, 5894 DZ
## 
##    1    2 
## 3401 5894

complete3.6&lt;-subset(complete3.5,
                  !is.na(age1))
dim(complete3.6) #9295 total
## [1] 9295  442
table(complete3.6$zygos) #3401 MZ, 5894 DZ
## 
##    1    2 
## 3401 5894

#genotyped twins with self-harm + MH data
complete4&lt;-subset(number_of_twins_involved,
                  ((genotyped1==1&amp;!is.na(age_161))&amp;
        ((!is.na(pcbhmfqt1)| #child-rated MFQ
        !is.na(ppbhmfqt1)| #parent-rated MFQ
        !is.na(ppbhconnt1)| #parent-rated ADHD
        !is.na(pcbhprndt1)| #paranoia
        !is.na(pcbhcapst1)| # caps
        !is.na(pcbhcgdst1)| # cognitive disorganisation
        !is.na(pcbhgrndt1)| # grandiosity
        !is.na(pcbhtepst1)| # TEPS
        !is.na(ppbhsanst1)| # SANS
        !is.na(pcbhinsomt1))&amp;!is.na(age_161))&amp;
         (!is.na(NSSH1)|!is.na(SSH1))))
dim(complete4) #4294 total
## [1] 4294  442
table(complete4$zygos) # 1075 MZ, 3219 DZ
## 
##    1    2 
## 1075 3219

#apple OR rule for the three variables:
#genotyped twins with self-harm + MH data
complete4.5&lt;-subset(number_of_twins_involved,
                  ((genotyped1==1&amp;!is.na(age_161))|
        ((!is.na(pcbhmfqt1)| #child-rated MFQ
        !is.na(ppbhmfqt1)| #parent-rated MFQ
        !is.na(ppbhconnt1)| #parent-rated ADHD
        !is.na(pcbhprndt1)| #paranoia
        !is.na(pcbhcapst1)| # caps
        !is.na(pcbhcgdst1)| # cognitive disorganisation
        !is.na(pcbhgrndt1)| # grandiosity
        !is.na(pcbhtepst1)| # TEPS
        !is.na(ppbhsanst1)| # SANS
        !is.na(pcbhinsomt1))&amp;!is.na(age_161))|
         (!is.na(NSSH1)|!is.na(SSH1))))
dim(complete4.5)
## [1] 12723   442
prop.table(table(complete4.5$sex1)) #56.6% females
## 
##         0         1 
## 0.5656685 0.4343315
table(complete4.5$zygos) # 4586 MZ, 8137 DZ
## 
##    1    2 
## 4586 8137


complete5&lt;-subset(complete4,!is.na(MDD100_res_t1))
dim(complete5);dim(complete4) #4294 total
## [1] 4294  442
## [1] 4294  442
prop.table(table(complete4$sex1)) #61.3% females
## 
##         0         1 
## 0.6134141 0.3865859</code></pre>
</div>
<div id="table-1-prevalence-of-nssh-and-ssh-in-this-sample" class="section level2">
<h2>Table 1: Prevalence of NSSH and SSH in this sample</h2>
<pre class="r"><code># write function to create the table for the full sample, male and female samples: 
table_1_fun&lt;-function(X1,X2,X3){
total_NSSH=sum(table(X1, useNA=&quot;always&quot;)) #total for NSSH
table_NSSH=table(X1)
prop_NSSH=round(prop.table(table(X1))*100,2)
total_SSH=sum(table(X2,useNA=&quot;always&quot;)) #total for NSSH
table_SSH=table(X2)
prop_SSH=round(prop.table(table(X2))*100,2)
meanage=round(mean(X3,na.rm=T),1)
return(rbind(cbind(total_NSSH,table_NSSH,prop_NSSH),cbind(total_SSH,table_SSH,prop_SSH),meanage))

}

# use complete3.6 which has twins without missing self-harm data and without missing age at young adulthood.
fullsample=table_1_fun(complete3.6$NSSH1,
                       complete3.6$SSH1,
                       complete3.6$u1cage1)

final_table&lt;-as.data.frame(cbind(fullsample),
                           row.names=c(rep(&quot;NSSH&quot;,5),rep(&quot;SSH&quot;,5),&quot;mean age (years)&quot;))
colnames(final_table)&lt;-c(&quot;Total N&quot;,&quot;N in each group&quot;,&quot;%&quot;)

rownames(final_table)&lt;-c(&quot;NSSH: No&quot;,
                         &quot;NSSH: Yes, 1-2 times&quot;,
                         &quot;NSSH: Yes, 3-5 times&quot;,
                         &quot;NSSH: Yes, 6-10 times&quot;, 
                         &quot;NSSH: Yes, &gt;10 times&quot;,
                         &quot;SSH: No&quot;,
                         &quot;SSH: Yes, 1-2 times&quot;,
                         &quot;SSH: Yes, 3-5 times&quot;,
                         &quot;SSH: Yes, 6-10 times&quot;, 
                         &quot;SSH: Yes, &gt;10 times&quot;, 
                         &quot;Mean age (Years)&quot;)

kableExtra::kable(final_table,digits=c(0,0,2),align=&quot;c&quot;)%&gt;%
  kableExtra::kable_styling(font_size = 12)%&gt;%
  collapse_rows()</code></pre>
<table class="table" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
Total N
</th>
<th style="text-align:center;">
N in each group
</th>
<th style="text-align:center;">
%
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
NSSH: No
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
7246
</td>
<td style="text-align:center;">
78.09
</td>
</tr>
<tr>
<td style="text-align:left;">
NSSH: Yes, 1-2 times
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
970
</td>
<td style="text-align:center;">
10.45
</td>
</tr>
<tr>
<td style="text-align:left;">
NSSH: Yes, 3-5 times
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
302
</td>
<td style="text-align:center;">
3.25
</td>
</tr>
<tr>
<td style="text-align:left;">
NSSH: Yes, 6-10 times
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
197
</td>
<td style="text-align:center;">
2.12
</td>
</tr>
<tr>
<td style="text-align:left;">
NSSH: Yes, &gt;10 times
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
564
</td>
<td style="text-align:center;">
6.08
</td>
</tr>
<tr>
<td style="text-align:left;">
SSH: No
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
8285
</td>
<td style="text-align:center;">
89.30
</td>
</tr>
<tr>
<td style="text-align:left;">
SSH: Yes, 1-2 times
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
658
</td>
<td style="text-align:center;">
7.09
</td>
</tr>
<tr>
<td style="text-align:left;">
SSH: Yes, 3-5 times
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
152
</td>
<td style="text-align:center;">
1.64
</td>
</tr>
<tr>
<td style="text-align:left;">
SSH: Yes, 6-10 times
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
62
</td>
<td style="text-align:center;">
0.67
</td>
</tr>
<tr>
<td style="text-align:left;">
SSH: Yes, &gt;10 times
</td>
<td style="text-align:center;">
9295
</td>
<td style="text-align:center;">
121
</td>
<td style="text-align:center;">
1.30
</td>
</tr>
<tr>
<td style="text-align:left;">
Mean age (Years)
</td>
<td style="text-align:center;">
22
</td>
<td style="text-align:center;">
22
</td>
<td style="text-align:center;">
22.30
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>#xlsx::write.xlsx(final_table,&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/results/MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;Table1&quot;,append = T)

#xlsx::write.xlsx(final_table,&quot;C:/Users/k1756035/OneDrive - King&#39;s College London/PhD/MR_DOC/write_up/Tables.xlsx&quot;,sheetName = &quot;Table1_updated&quot;,append = T)</code></pre>
<p>The sample size is 9295. <br></p>
</div>
<div id="table-for-mental-health-measures" class="section level2">
<h2>Table for mental health measures</h2>
<pre class="r"><code>#rename some columns to ease the next steps:
MH_descriptive&lt;-complete2.5%&gt;%
  mutate(
    &quot;parent-rated CPRS&quot;=ppbhconnt1,
    &quot;parent-rated MFQ&quot;=ppbhmfqt1,
    &quot;child-rated MFQ&quot;=pcbhmfqt1,
    &quot;child-rated hallucinations&quot;=pcbhcapst1,
    &quot;child-rated grandiosity&quot;=pcbhgrndt1,
    &quot;child-rated paranoia&quot;=pcbhprndt1,
    &quot;parent-rated negative symptoms&quot;=ppbhsanst1,
    &quot;child-rated anhedonia&quot;=pcbhtepstr_1,
    &quot;child-rated cognitive disorganisation&quot;=pcbhcgdst1,
    &quot;child-rated insomnia severity&quot;=pcbhinsomt1)

DesData &lt;- subset(MH_descriptive, !is.na(age_161&amp;age_162) &amp;!is.na(sex1&amp;sex2))
#select only one twin from each pair because of double entry method 
measures&lt;-c(&quot;child-rated MFQ&quot;, 
            &quot;parent-rated MFQ&quot;, 
            &quot;parent-rated CPRS&quot;,
            &quot;child-rated paranoia&quot;,
            &quot;child-rated hallucinations&quot;,
            &quot;child-rated cognitive disorganisation&quot;,
            &quot;child-rated grandiosity&quot;,
            &quot;child-rated anhedonia&quot;,
            &quot;parent-rated negative symptoms&quot;,
            &quot;child-rated insomnia severity&quot;)

des_table&lt;-data.frame()
for (i in 1:length(measures))
{des&lt;-psych::describe(DesData[,measures[i]])
  des_table[i,1]&lt;-measures[i]
  des_table[i,c(2:6)]&lt;-c(des$n,des$mean,des$min,des$max,des$sd)}
colnames(des_table)&lt;-c(&quot;Measure&quot;,&quot;Sample size (N)&quot;,&quot;Mean&quot;,&quot;Minimum&quot;,&quot;Maximum&quot;,&quot;SD&quot;)

kableExtra::kable(des_table,digits=2,align=&quot;c&quot;)%&gt;%
  kableExtra::kable_styling(font_size = 12)</code></pre>
<table class="table" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Measure
</th>
<th style="text-align:center;">
Sample size (N)
</th>
<th style="text-align:center;">
Mean
</th>
<th style="text-align:center;">
Minimum
</th>
<th style="text-align:center;">
Maximum
</th>
<th style="text-align:center;">
SD
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
child-rated MFQ
</td>
<td style="text-align:center;">
10141
</td>
<td style="text-align:center;">
3.64
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
4.44
</td>
</tr>
<tr>
<td style="text-align:center;">
parent-rated MFQ
</td>
<td style="text-align:center;">
10161
</td>
<td style="text-align:center;">
1.00
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
22
</td>
<td style="text-align:center;">
2.32
</td>
</tr>
<tr>
<td style="text-align:center;">
parent-rated CPRS
</td>
<td style="text-align:center;">
10157
</td>
<td style="text-align:center;">
6.89
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
53
</td>
<td style="text-align:center;">
7.55
</td>
</tr>
<tr>
<td style="text-align:center;">
child-rated paranoia
</td>
<td style="text-align:center;">
10132
</td>
<td style="text-align:center;">
12.12
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
72
</td>
<td style="text-align:center;">
10.66
</td>
</tr>
<tr>
<td style="text-align:center;">
child-rated hallucinations
</td>
<td style="text-align:center;">
10141
</td>
<td style="text-align:center;">
4.71
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
45
</td>
<td style="text-align:center;">
6.12
</td>
</tr>
<tr>
<td style="text-align:center;">
child-rated cognitive disorganisation
</td>
<td style="text-align:center;">
10128
</td>
<td style="text-align:center;">
3.99
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
11
</td>
<td style="text-align:center;">
2.87
</td>
</tr>
<tr>
<td style="text-align:center;">
child-rated grandiosity
</td>
<td style="text-align:center;">
10133
</td>
<td style="text-align:center;">
5.37
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
4.49
</td>
</tr>
<tr>
<td style="text-align:center;">
child-rated anhedonia
</td>
<td style="text-align:center;">
10136
</td>
<td style="text-align:center;">
16.27
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
7.87
</td>
</tr>
<tr>
<td style="text-align:center;">
parent-rated negative symptoms
</td>
<td style="text-align:center;">
10157
</td>
<td style="text-align:center;">
2.93
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
30
</td>
<td style="text-align:center;">
3.97
</td>
</tr>
<tr>
<td style="text-align:center;">
child-rated insomnia severity
</td>
<td style="text-align:center;">
7852
</td>
<td style="text-align:center;">
3.85
</td>
<td style="text-align:center;">
0
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
4.22
</td>
</tr>
</tbody>
</table>
<pre class="r"><code>#xlsx::write.xlsx(des_table,&quot;C:/Users/k1756035/OneDrive - King&#39;s College London/PhD/MR_DOC/write_up/Tables.xlsx&quot;,sheetName = &quot;Table_S1_14_Sept_21&quot;,append = T)</code></pre>
</div>
<div id="calculate-the-cronbachs-alphas" class="section level2">
<h2>Calculate the Cronbach’s alphas</h2>
<p>Cronbach’s alphas for each mental health measure are calculated and reported in the manuscript</p>
<pre class="r"><code>(cMFQ_alpha&lt;-merged_data%&gt;%
  dplyr::select(pcbhmfq011, pcbhmfq021, pcbhmfq031,
 pcbhmfq041, pcbhmfq051, pcbhmfq061, pcbhmfq071, pcbhmfq081, pcbhmfq091,
 pcbhmfq101, pcbhmfq111, pcbhmfq121, pcbhmfq131)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 13
## Sample units: 18338
## alpha: 0.883
#0.883

(pMFQ_alpha&lt;-merged_data%&gt;%
  dplyr::select(ppbhmfq011, ppbhmfq021, ppbhmfq031,
 ppbhmfq041, ppbhmfq051, ppbhmfq061, ppbhmfq071, ppbhmfq081,
 ppbhmfq091, ppbhmfq101, ppbhmfq111)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 11
## Sample units: 18338
## alpha: 0.862
#0.862

(pADHD_alpha&lt;-merged_data%&gt;%
  dplyr::select(ppbhconn011, ppbhconn051, ppbhconn081,
 ppbhconn101, ppbhconn111, ppbhconn131, ppbhconn141, ppbhconn161, ppbhconn181,ppbhconn021, ppbhconn031, ppbhconn041,
 ppbhconn061, ppbhconn071, ppbhconn091, ppbhconn121, ppbhconn151, ppbhconn171)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 18
## Sample units: 18338
## alpha: 0.903
#0.903

(pSANS&lt;-merged_data%&gt;%
  dplyr::select(ppbhsans011, ppbhsans021, ppbhsans031,
 ppbhsans041, ppbhsans051, ppbhsans061, ppbhsans071, ppbhsans081, ppbhsans091, ppbhsans101)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 10
## Sample units: 18338
## alpha: 0.855
#0.855

(cTEPS&lt;-merged_data%&gt;%
  dplyr::select(pcbhteps011, pcbhteps021, pcbhteps03r1,
 pcbhteps041, pcbhteps051, pcbhteps061, pcbhteps071, pcbhteps081, pcbhteps091, pcbhteps101)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 10
## Sample units: 18338
## alpha: 0.772
#0.772

(cCAPS&lt;-merged_data%&gt;%
  dplyr::select(pcbhcaps11, pcbhcaps21, pcbhcaps31,pcbhcaps41, pcbhcaps51, pcbhcaps61, pcbhcaps71, pcbhcaps81, pcbhcaps91)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 9
## Sample units: 18338
## alpha: 0.881
#0.881

(cGRND&lt;-merged_data%&gt;%
  dplyr::select(pcbhgrnd11, pcbhgrnd21, pcbhgrnd31,pcbhgrnd41, pcbhgrnd51, pcbhgrnd61, pcbhgrnd71, pcbhgrnd81)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 8
## Sample units: 18338
## alpha: 0.856
#0.856

(cCGDS&lt;-merged_data%&gt;%
  dplyr::select(pcbhcgds011, pcbhcgds021, pcbhcgds031,
 pcbhcgds041, pcbhcgds051, pcbhcgds061, pcbhcgds071, pcbhcgds081,
 pcbhcgds091, pcbhcgds101, pcbhcgds111)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 11
## Sample units: 18338
## alpha: 0.771
#0.771


(cPRND&lt;-merged_data%&gt;%
  dplyr::select(pcbhprnd011, pcbhprnd021, pcbhprnd031,
 pcbhprnd041, pcbhprnd051, pcbhprnd061, pcbhprnd071, pcbhprnd081, pcbhprnd091,
 pcbhprnd101, pcbhprnd111, pcbhprnd121, pcbhprnd131, pcbhprnd141, pcbhprnd151)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 15
## Sample units: 18338
## alpha: 0.926
#0.926


(cINSOM&lt;-merged_data%&gt;%
  dplyr::select(pcbhinsom11, pcbhinsom21, pcbhinsom31,
 pcbhinsom41, pcbhinsom51, pcbhinsom61, pcbhinsom71)%&gt;%
  ltm::cronbach.alpha(na.rm=T))
## 
## Cronbach&#39;s alpha for the &#39;.&#39; data-set
## 
## Items: 7
## Sample units: 18338
## alpha: 0.892
#0.89</code></pre>
</div>
<div id="calculating-the-correlation-between-child-rated-and-parent-rated-mfq" class="section level2">
<h2>Calculating the correlation between child-rated and parent-rated MFQ</h2>
<p>We were asked by the reviewers to present the correlation between child-rated and parent-rated MFQ.</p>
<pre class="r"><code># How about log-tranformed cmfq and pmfq?
merged_data$res_basic_cMFQ1&lt;- residuals(lm(merged_data$pcbhmfqt1
                                           ~merged_data$age_161 + merged_data$sex1,
                                           na.action=&quot;na.exclude&quot;))
merged_data$res_trans_order_cMFQ1 &lt;-log(merged_data$res_basic_cMFQ1+6)*2

merged_data$res_basic_pMFQ1&lt;- residuals(lm(merged_data$ppbhmfqt1
                                           ~merged_data$age_161 + merged_data$sex1,
                                           na.action=&quot;na.exclude&quot;))
merged_data$res_trans_order_pMFQ1 &lt;-log(merged_data$res_basic_pMFQ1+1.5)*3

cor&lt;-cor.test(merged_data$res_trans_order_pMFQ1,merged_data$res_trans_order_cMFQ1,use = &quot;pairwise.complete.obs&quot;)</code></pre>
<p>The correlation between pMFQ and cMFQ was: 0.377. <br></p>
</div>
<div id="overlap-between-nssh-and-ssh" class="section level2">
<h2>Overlap between NSSH and SSH</h2>
<p>We also looked at the overlap between NSSH and SSH groups. Look for the phenotypic correlation between NSSH and SSH.</p>
<pre class="r"><code>overlap=complete3.6

corSH&lt;-polycor::hetcor(as.factor(overlap$NSSH1),as.factor(overlap$SSH1))
corSH</code></pre>
<pre><code>## 
## Two-Step Estimates
## 
## Correlations/Type of Correlation:
##                          as.factor(overlap$NSSH1) as.factor.overlap.SSH1.
## as.factor(overlap$NSSH1)                        1              Polychoric
## as.factor.overlap.SSH1.                    0.8693                       1
## 
## Standard Errors:
## as.factor(overlap$NSSH1)  as.factor.overlap.SSH1. 
##                                          0.005675 
## Levels:  0.005675
## 
## n = 9262 
## 
## P-values for Tests of Bivariate Normality:
## as.factor(overlap$NSSH1)  as.factor.overlap.SSH1. 
##                                         2.037e-08 
## Levels:  2.037e-08</code></pre>
<pre class="r"><code># Now recode NSSH and SSH into binary variables to study overlapping. 
bin_NSSH1&lt;-ifelse(overlap$NSSH1&gt;0,1,0)
bin_SSH1&lt;-ifelse(overlap$SSH1&gt;0,1,0)


## Plot without missing data
freq_table &lt;- as.data.frame(table(bin_NSSH1, bin_SSH1))

## count in proportion
freq_table_prop&lt;-as.data.frame(prop.table(table(bin_NSSH1, bin_SSH1)))%&gt;%
  mutate(bin_NSSH1=recode(bin_NSSH1, &quot;0&quot; = &quot;No&quot;,&quot;1&quot; = &quot;Yes&quot;))%&gt;%
  mutate(bin_SSH1=recode(bin_SSH1, &quot;0&quot; = &quot;No&quot;,&quot;1&quot; = &quot;Yes&quot;))%&gt;%
  add_column(N=freq_table$Freq)

freq_table_prop$Percentage=round(freq_table_prop$Freq*100,1)
freq_table_prop=freq_table_prop%&gt;%
  mutate_if(is.factor,as.character)

(FigS1&lt;-ggplot(freq_table_prop, aes(bin_NSSH1, bin_SSH1)) +
  geom_tile(aes(fill = Percentage), colour = &quot;black&quot;) +
  scale_fill_gradient(low= &quot;#A1C9F7&quot;,high=&quot;#B5179E&quot;)+
  geom_text(aes(label = paste0(Percentage,&quot;%&quot;, &quot;\n&quot;,&quot;(n = &quot;,N,&quot;)&quot;)), size=8)+
    theme(text = element_text(size=20),
          panel.grid = element_blank(),
          panel.background = element_blank(),
          axis.ticks = element_blank(),
          axis.text = element_text(margin=margin(0)),
          plot.title=element_text(hjust=0.5))+
  labs(y=&quot;Ever SSH&quot;, x=&quot;Ever NSSH&quot;, fill=&quot;Percentage (%)&quot;,title=&quot;Overlap between NSSH and SSH&quot;))</code></pre>
<p><img src="MR_DoC_RMarkDown_script_files/figure-html/NSSH-SSH-1.png" width="672" /></p>
<pre class="r"><code>#ggsave(&quot;../write_up/Figure_S1.jpg&quot;)</code></pre>
</div>
</div>
<div id="polygenic-scoring-analyses" class="section level1">
<h1>Polygenic scoring analyses</h1>
<p>For polygenic scoring analyses, we used the GEE package to run regression analyses and exploited the “exchangeable” argument to control for non-independence of the twin structure.</p>
<pre class="r"><code>results&lt;-&quot;C:/Users/k1756035/OneDrive - King&#39;s College London/PhD/MR_DOC/Results&quot;
#### try using gee from geepack ####
## firstly, create dummy variables first
dummydata&lt;-dummy_columns(self_harm_data_c, select_columns =c(&quot;Chip&quot;, &quot;Batch&quot;),remove_first_dummy = TRUE)
colnames(dummydata)[(length(colnames(dummydata))-9):length(colnames(dummydata))]&lt;-c(&quot;Chip_affy&quot;, &quot;Chip_oee&quot;,
                                &quot;Batch_affy&quot;,&quot;Batch_bt1&quot;,&quot;Batch_bt2&quot;,                          &quot;Batch_bt3&quot;,&quot;Batch_bt4&quot;,&quot;Batch_bt5&quot;,&quot;Batch_bt6&quot;,&quot;Batch_btDZ&quot;) #need to use one column only
identical(dummydata$Batch_affy, dummydata$Chip_affy) #chip and batch has same values, drop this from analyses</code></pre>
<div id="prs-analysis-using-gee-package" class="section level2 tabset">
<h2 class="tabset">PRS analysis using GEE package</h2>
<p>The scripts for GEE analyses are shown below in different tabs:</p>
<div id="mdd" class="section level3">
<h3>MDD</h3>
<pre class="r"><code>##### use GEE for MDD ####
MDDPRS=c( &quot;MDD001&quot;  , &quot;MDD030&quot;  , &quot;MDD100&quot;)
MDDOUT=c(&quot;pcbhmfqt1&quot;,&quot;ppbhmfqt1&quot;)
## for child-rated and parent-rated MFQ
GEE_MDD=matrix(nrow = length(MDDPRS)*length(MDDOUT),ncol=5)

for(i in seq(from=1,to=length(MDDOUT),by=1))
{dummydata$XO=NA;dummydata$XO=dummydata[,MDDOUT[i]]
for (j in seq(from=1,to=length(MDDPRS),by=1))
{ dummydata$XD=NA;dummydata$XD=dummydata[,MDDPRS[j]] #with=F, refer to data.table FAQ 1.1

gee1=gee(XO~scale(XD)+PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+Chip_affy+
                  Batch_bt1+Batch_bt2+Batch_bt3+Batch_bt4+Batch_bt5+Batch_bt6+
                  sex1+pcbhage1, 
                  id=randomfamid,
                  corstr=&quot;exchangeable&quot;,
                  data=dummydata)

gee2=gee(XO~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+Chip_affy+
            Batch_bt1+Batch_bt2+Batch_bt3+Batch_bt4+Batch_bt5+Batch_bt6+
            sex1+pcbhage1, 
          id=randomfamid,
          corstr=&quot;exchangeable&quot;,
          data=dummydata)
#get p-value
pval=2 * pnorm(abs(coef(summary(gee1))[2,5]), lower.tail = FALSE)
#get beta
beta=coef(summary(gee1))[2,1]
#get R2
Y_bar1 = mean(gee1$y, na.rm = T)
Y_bar2 = mean(gee2$y, na.rm = T)
rsquare_gee1 &lt;- 1-(sum((gee1$y - gee1$fitted.values)^2, na.rm = T)/sum((gee1$y - Y_bar1)^2, na.rm = T))
rsquare_gee2 &lt;- 1-(sum((gee2$y - gee2$fitted.values)^2, na.rm = T)/sum((gee2$y - Y_bar2)^2, na.rm = T))
R2=rsquare_gee1-rsquare_gee2
#get 95% CI
se &lt;- summary(gee1)$coefficients[&quot;scale(XD)&quot;,&quot;Robust S.E.&quot;]
CI=coef(gee1)[&quot;scale(XD)&quot;]+c(-1, 1) * se * qnorm(0.975)
#summarise results
k=3*(i-1)
GEE_MDD[j+k,1:5]=c(beta,CI, pval,R2)
}}

colnames(GEE_MDD)=c(&quot;beta coefficient&quot;,&quot;Lower 95% CI&quot;, &quot;Upper 95% CI&quot;,&quot;p-value&quot;,&quot;R2&quot;)
rownames(GEE_MDD)&lt;-as.vector(outer(MDDPRS, MDDOUT, paste, sep=&quot;.&quot;))
GEE_MDD</code></pre>
</div>
<div id="adhd" class="section level3">
<h3>ADHD</h3>
<pre class="r"><code>##### use GEE for ADHD ######
ADHDPRS=c( &quot;ADHD001&quot;  , &quot;ADHD030&quot;  , &quot;ADHD100&quot;)

## for parent-rated Conner&#39;s scale
GEE_ADHD=matrix(nrow = length(ADHDPRS),ncol=5)

for(i in seq(from=1,to=length(ADHDPRS),by=1))
{ dummydata$XD=NA;dummydata$XD=dummydata[,ADHDPRS[i]] #with=F, refer to data.table FAQ 1.1

gee1=gee(ppbhconnt1~scale(XD)+PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+Chip_affy+
           Batch_bt1+Batch_bt2+Batch_bt3+Batch_bt4+Batch_bt5+Batch_bt6+
           sex1+pcbhage1, 
         id=randomfamid,
         corstr=&quot;exchangeable&quot;,
         data=dummydata)

gee2=gee(ppbhconnt1~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+Chip_affy+
           Batch_bt1+Batch_bt2+Batch_bt3+Batch_bt4+Batch_bt5+Batch_bt6+
           sex1+pcbhage1, 
         id=randomfamid,
         corstr=&quot;exchangeable&quot;,
         data=dummydata)
#get p-value
pval=2 * pnorm(abs(coef(summary(gee1))[2,5]), lower.tail = FALSE)
#get beta
beta=coef(summary(gee1))[2,1]
#get R2
Y_bar1 = mean(gee1$y, na.rm = T)
Y_bar2 = mean(gee2$y, na.rm = T)
rsquare_gee1 &lt;- 1-(sum((gee1$y - gee1$fitted.values)^2, na.rm = T)/sum((gee1$y - Y_bar1)^2, na.rm = T))
rsquare_gee2 &lt;- 1-(sum((gee2$y - gee2$fitted.values)^2, na.rm = T)/sum((gee2$y - Y_bar2)^2, na.rm = T))
R2=rsquare_gee1-rsquare_gee2
#get 95% CI
se &lt;- summary(gee1)$coefficients[&quot;scale(XD)&quot;,&quot;Robust S.E.&quot;]
CI=coef(gee1)[&quot;scale(XD)&quot;]+c(-1, 1) * se * qnorm(0.975)
#summarise results
GEE_ADHD[i,1:5]=c(beta,CI, pval,R2)
}

colnames(GEE_ADHD)=c(&quot;beta coefficient&quot;,&quot;Lower 95% CI&quot;, &quot;Upper 95% CI&quot;,&quot;p-value&quot;,&quot;R2&quot;)
rownames(GEE_ADHD)&lt;-as.vector(outer(ADHDPRS, &quot;ppbhconnt1&quot;, paste, sep=&quot;.&quot;))
GEE_ADHD</code></pre>
</div>
<div id="schizophrenia" class="section level3">
<h3>Schizophrenia</h3>
<pre class="r"><code>##### use GEE for SCZ #####
SCZPRS=c( &quot;SCZ001&quot;  , &quot;SCZ030&quot;  , &quot;SCZ100&quot;)
SCZOUT=c(&quot;pcbhprndt1&quot;, &quot;pcbhcapst1&quot;, &quot;pcbhcgdst1&quot;,&quot;pcbhgrndt1&quot;,&quot;pcbhtepstr_1&quot;,&quot;ppbhsanst1&quot;)
## for child-rated and parent-rated MFQ
GEE_SCZ=matrix(nrow = length(SCZPRS)*length(SCZOUT),ncol=5)

for(i in seq(from=1,to=length(SCZOUT),by=1))
{dummydata$XO=NA;dummydata$XO=NA;dummydata$XO=dummydata[,SCZOUT[i]]
for (j in seq(from=1,to=length(SCZPRS),by=1))
{ dummydata$XD=NA;dummydata$XD=dummydata[,SCZPRS[j]] #with=F, refer to data.table FAQ 1.1

gee1=gee(XO~scale(XD)+PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+Chip_affy+
           Batch_bt1+Batch_bt2+Batch_bt3+Batch_bt4+Batch_bt5+Batch_bt6+
           sex1+pcbhage1, 
         id=randomfamid,
         corstr=&quot;exchangeable&quot;,
         data=dummydata)

gee2=gee(XO~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+Chip_affy+
           Batch_bt1+Batch_bt2+Batch_bt3+Batch_bt4+Batch_bt5+Batch_bt6+
           sex1+pcbhage1, 
         id=randomfamid,
         corstr=&quot;exchangeable&quot;,
         data=dummydata)
#get p-value
pval=2 * pnorm(abs(coef(summary(gee1))[2,5]), lower.tail = FALSE)
#get beta
beta=coef(summary(gee1))[2,1]
#get R2
Y_bar1 = mean(gee1$y, na.rm = T)
Y_bar2 = mean(gee2$y, na.rm = T)
rsquare_gee1 &lt;- 1-(sum((gee1$y - gee1$fitted.values)^2, na.rm = T)/sum((gee1$y - Y_bar1)^2, na.rm = T))
rsquare_gee2 &lt;- 1-(sum((gee2$y - gee2$fitted.values)^2, na.rm = T)/sum((gee2$y - Y_bar2)^2, na.rm = T))
R2=rsquare_gee1-rsquare_gee2
#get 95% CI
se &lt;- summary(gee1)$coefficients[&quot;scale(XD)&quot;,&quot;Robust S.E.&quot;]
CI=coef(gee1)[&quot;scale(XD)&quot;]+c(-1, 1) * se * qnorm(0.975)
#summarise results
k=3*(i-1)
GEE_SCZ[j+k,1:5]=c(beta,CI, pval,R2)
}}

colnames(GEE_SCZ)=c(&quot;beta coefficient&quot;,&quot;Lower 95% CI&quot;, &quot;Upper 95% CI&quot;,&quot;p-value&quot;,&quot;R2&quot;)
rownames(GEE_SCZ)&lt;-as.vector(outer(SCZPRS, SCZOUT, paste, sep=&quot;.&quot;))
GEE_SCZ</code></pre>
</div>
<div id="insomnia" class="section level3">
<h3>Insomnia</h3>
<pre class="r"><code>##### use GEE for INSOM #####
INSOMPRS=c( &quot;INSOM001&quot;  , &quot;INSOM030&quot;  , &quot;INSOM100&quot;)

## for parent-rated Conner&#39;s scale
GEE_INSOM=matrix(nrow = length(INSOMPRS),ncol=5)

for(i in seq(from=1,to=length(INSOMPRS),by=1))
{ dummydata$XD=NA;dummydata$XD=dummydata[,INSOMPRS[i]] #with=F, refer to data.table FAQ 1.1

gee1=gee(pcbhinsomt1~scale(XD)+PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+Chip_affy+
           Batch_bt1+Batch_bt2+Batch_bt3+Batch_bt4+Batch_bt5+Batch_bt6+
           sex1+pcbhage1, 
         id=randomfamid,
         corstr=&quot;exchangeable&quot;,
         data=dummydata)

gee2=gee(pcbhinsomt1~PC1+PC2+PC3+PC4+PC5+PC6+PC7+PC8+PC9+PC10+Chip_affy+
           Batch_bt1+Batch_bt2+Batch_bt3+Batch_bt4+Batch_bt5+Batch_bt6+
           sex1+pcbhage1, 
         id=randomfamid,
         corstr=&quot;exchangeable&quot;,
         data=dummydata)
#get p-value
pval=2 * pnorm(abs(coef(summary(gee1))[2,5]), lower.tail = FALSE)
#get beta
beta=coef(summary(gee1))[2,1]
#get R2
Y_bar1 = mean(gee1$y, na.rm = T)
Y_bar2 = mean(gee2$y, na.rm = T)
rsquare_gee1 &lt;- 1-(sum((gee1$y - gee1$fitted.values)^2, na.rm = T)/sum((gee1$y - Y_bar1)^2, na.rm = T))
rsquare_gee2 &lt;- 1-(sum((gee2$y - gee2$fitted.values)^2, na.rm = T)/sum((gee2$y - Y_bar2)^2, na.rm = T))
R2=rsquare_gee1-rsquare_gee2
#get 95% CI
se &lt;- summary(gee1)$coefficients[&quot;scale(XD)&quot;,&quot;Robust S.E.&quot;]
CI=coef(gee1)[&quot;scale(XD)&quot;]+c(-1, 1) * se * qnorm(0.975)
#summarise results
GEE_INSOM[i,1:5]=c(beta,CI, pval,R2)
}

colnames(GEE_INSOM)=c(&quot;beta coefficient&quot;,&quot;Lower 95% CI&quot;, &quot;Upper 95% CI&quot;,&quot;p-value&quot;,&quot;R2&quot;)
rownames(GEE_INSOM)&lt;-as.vector(outer(INSOMPRS, &quot;pcbhinsomt1&quot;, paste, sep=&quot;.&quot;))
GEE_INSOM</code></pre>
</div>
<div id="fdr-correction" class="section level3">
<h3>FDR correction</h3>
<pre class="r"><code>##### combine results from gee and FDR correction ######
gee_results&lt;-as.data.frame(rbind(GEE_MDD,GEE_ADHD,GEE_SCZ,GEE_INSOM))
gee_results$FDR=p.adjust(gee_results$`p-value`, method = &quot;fdr&quot;, n = length(gee_results$`p-value`))
gee.FDR.results&lt;-gee_results[gee_results$FDR&lt;0.05,] # only cMFQ, pMFQ and ADHD are significant after FDR correction. 
gee.FDR.results

# we only selected PRS threshold=1
gee_100&lt;-as.data.frame(rbind(GEE_MDD,GEE_ADHD,GEE_SCZ,GEE_INSOM))

gee_100&lt;-gee_100%&gt;%
  rownames_to_column()%&gt;%
  slice(c(grep(&quot;*100&quot;, rownames(gee_100))))

gee_100&lt;-gee_100%&gt;%add_column(FDR=p.adjust(gee_100$`p-value`, method = &quot;fdr&quot;, n = length(gee_100$`p-value`)))</code></pre>
</div>
</div>
<div id="print-prs-analysis-results" class="section level2">
<h2>Print PRS analysis results</h2>
<p>Print the results from gee() function.</p>
<pre class="r"><code>kableExtra::kable(gee_100,digits=4,align=&quot;c&quot;)%&gt;%
  kableExtra::kable_styling(font_size = 12)</code></pre>
<table class="table" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
rowname
</th>
<th style="text-align:center;">
beta coefficient
</th>
<th style="text-align:center;">
Lower 95% CI
</th>
<th style="text-align:center;">
Upper 95% CI
</th>
<th style="text-align:center;">
p-value
</th>
<th style="text-align:center;">
R2
</th>
<th style="text-align:center;">
FDR
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
MDD100.pcbhmfqt1
</td>
<td style="text-align:center;">
0.2766
</td>
<td style="text-align:center;">
0.1672
</td>
<td style="text-align:center;">
0.3860
</td>
<td style="text-align:center;">
0.0000
</td>
<td style="text-align:center;">
0.0041
</td>
<td style="text-align:center;">
0.0000
</td>
</tr>
<tr>
<td style="text-align:center;">
MDD100.ppbhmfqt1
</td>
<td style="text-align:center;">
0.1368
</td>
<td style="text-align:center;">
0.0742
</td>
<td style="text-align:center;">
0.1994
</td>
<td style="text-align:center;">
0.0000
</td>
<td style="text-align:center;">
0.0040
</td>
<td style="text-align:center;">
0.0001
</td>
</tr>
<tr>
<td style="text-align:center;">
ADHD100.ppbhconnt1
</td>
<td style="text-align:center;">
0.7705
</td>
<td style="text-align:center;">
0.5862
</td>
<td style="text-align:center;">
0.9548
</td>
<td style="text-align:center;">
0.0000
</td>
<td style="text-align:center;">
0.0111
</td>
<td style="text-align:center;">
0.0000
</td>
</tr>
<tr>
<td style="text-align:center;">
SCZ100.pcbhprndt1
</td>
<td style="text-align:center;">
-0.0329
</td>
<td style="text-align:center;">
-0.3120
</td>
<td style="text-align:center;">
0.2461
</td>
<td style="text-align:center;">
0.8171
</td>
<td style="text-align:center;">
0.0000
</td>
<td style="text-align:center;">
0.9079
</td>
</tr>
<tr>
<td style="text-align:center;">
SCZ100.pcbhcapst1
</td>
<td style="text-align:center;">
0.0090
</td>
<td style="text-align:center;">
-0.1491
</td>
<td style="text-align:center;">
0.1670
</td>
<td style="text-align:center;">
0.9115
</td>
<td style="text-align:center;">
0.0000
</td>
<td style="text-align:center;">
0.9115
</td>
</tr>
<tr>
<td style="text-align:center;">
SCZ100.pcbhcgdst1
</td>
<td style="text-align:center;">
0.0746
</td>
<td style="text-align:center;">
-0.0003
</td>
<td style="text-align:center;">
0.1495
</td>
<td style="text-align:center;">
0.0509
</td>
<td style="text-align:center;">
0.0006
</td>
<td style="text-align:center;">
0.1017
</td>
</tr>
<tr>
<td style="text-align:center;">
SCZ100.pcbhgrndt1
</td>
<td style="text-align:center;">
0.0738
</td>
<td style="text-align:center;">
-0.0421
</td>
<td style="text-align:center;">
0.1898
</td>
<td style="text-align:center;">
0.2119
</td>
<td style="text-align:center;">
0.0002
</td>
<td style="text-align:center;">
0.3027
</td>
</tr>
<tr>
<td style="text-align:center;">
SCZ100.pcbhtepstr_1
</td>
<td style="text-align:center;">
-0.2213
</td>
<td style="text-align:center;">
-0.4182
</td>
<td style="text-align:center;">
-0.0243
</td>
<td style="text-align:center;">
0.0277
</td>
<td style="text-align:center;">
0.0009
</td>
<td style="text-align:center;">
0.0692
</td>
</tr>
<tr>
<td style="text-align:center;">
SCZ100.ppbhsanst1
</td>
<td style="text-align:center;">
0.0747
</td>
<td style="text-align:center;">
-0.0305
</td>
<td style="text-align:center;">
0.1799
</td>
<td style="text-align:center;">
0.1639
</td>
<td style="text-align:center;">
0.0005
</td>
<td style="text-align:center;">
0.2732
</td>
</tr>
<tr>
<td style="text-align:center;">
INSOM100.pcbhinsomt1
</td>
<td style="text-align:center;">
0.0277
</td>
<td style="text-align:center;">
-0.0985
</td>
<td style="text-align:center;">
0.1540
</td>
<td style="text-align:center;">
0.6667
</td>
<td style="text-align:center;">
0.0001
</td>
<td style="text-align:center;">
0.8334
</td>
</tr>
</tbody>
</table>
<p>We then wrote the results to Excel sheets.</p>
<pre class="r"><code>setwd(results)
xlsx::write.xlsx(gee_results,&quot;PRS_results_14_September_2021.xlsx&quot;,sheetName = &quot;gee_all&quot;)
xlsx::write.xlsx(gee.FDR.results,&quot;PRS_results_14_September_2021.xlsx&quot;,sheetName = &quot;gee_FDR&quot;,append = T)
xlsx::write.xlsx(gee_100,&quot;PRS_results_14_September_2021.xlsx&quot;,sheetName = &quot;gee_100&quot;,append = T)
xlsx::write.xlsx(GEE_TEPSR,&quot;PRS_results_14_September_2021.xlsx&quot;,sheetName = &quot;anhedonia&quot;,append = T)</code></pre>
</div>
</div>
<div id="mr-doc-models" class="section level1">
<h1>MR-DoC Models</h1>
<p>The code chunk below will show the MR-DoC model codes for each MR-DoC models.</p>
<p>The scripts in each tab also include the sensitivity analyses that were carried out (fixing re at different values to test sensitivity of causal estimates). The results were then stored in RData format to be processed later.</p>
<div id="model-scripts" class="section level2 tabset">
<h2 class="tabset">Model scripts</h2>
<div id="cmfq-nssh" class="section level3">
<h3>cMFQ-NSSH</h3>
<pre class="r"><code>###### Regress out age, sex and transform cMFQ variable #####
#******************************************************
#**Regressing  out age &amp; sex **#
merged_data$res_basic_cMFQ1&lt;- residuals(lm(merged_data$pcbhmfqt1
                                           ~merged_data$age_161 + merged_data$sex1,
                                           na.action=&quot;na.exclude&quot;))
merged_data$res_trans_order_cMFQ1 &lt;-log(merged_data$res_basic_cMFQ1+6)*2

#do same thing for twin 2. 
merged_data$res_basic_cMFQ2&lt;- residuals(lm(merged_data$pcbhmfqt2
                                           ~merged_data$age_162 + merged_data$sex2,
                                           na.action=&quot;na.exclude&quot;))

merged_data$res_trans_order_cMFQ2 &lt;-log(merged_data$res_basic_cMFQ2+6)*2
#***************************************************************************************
#################################### MR-DoC model ######################################
#***************************************************************************************

#variables I will need for this cMFQ MR-DoC model:
vars        &lt;-c(&#39;MDD_PRS&#39;,&#39;cMFQ&#39;,&#39;SH&#39;)

#variables for the second ACE fit to compare results (residualised then transformed)
selVars &lt;-c(&#39;MDD100_res_t1&#39;, &#39;res_trans_order_cMFQ1&#39;,&#39;NSSH1&#39;,
            &#39;MDD100_res_t2&#39;, &#39;res_trans_order_cMFQ2&#39;,&#39;NSSH2&#39;) 


useVars &lt;-c(&#39;MDD100_res_t1&#39;, &#39;res_trans_order_cMFQ1&#39;,&#39;NSSH1&#39;,
            &#39;MDD100_res_t2&#39;, &#39;res_trans_order_cMFQ2&#39;,&#39;NSSH2&#39;,
            &#39;age1&#39;, &#39;age2&#39;, &#39;sex1&#39;,&#39;sex2&#39;) #age is for at age 21

#need to recode missing age into 999
table(is.na(merged_data$age1))
merged_data$NSSH1[is.na(merged_data$age1)] &lt;- NA
merged_data$NSSH2[is.na(merged_data$age2)] &lt;- NA
merged_data$age1[is.na(merged_data$age1)] &lt;- 999
merged_data$age2[is.na(merged_data$age2)] &lt;- 999
merged_data[1:20,1:8]

#mz and dzdata for using res_trans_order_cMFQ
mzdata&lt;-subset(merged_data, zygos%in%1&amp;random==1 , useVars)
dzdata&lt;-subset(merged_data, zygos%in%2&amp;random==1 , useVars)


head(mzdata)

#do ACE model #
nv          &lt;- 3                # number of variables for a twin = 1 in Univariate
nvo             &lt;- 1                #number of ordinal variables per twin
nvc             &lt;- nv-nvo           #number of continuous variables per twin
poso            &lt;- nvo          #position where ordinal variables start
ntv         &lt;- 2*nv         # number of variables for a pair = 2* 1 for Univariate
nth         &lt;- 4    # number of max thresholds
nfact       &lt;- 3                # number of Latent Factors 
ncor            &lt;- (nv*(nv+1)/2)-nv # number of free elements in a correlation matrix nv*nv
ninc            &lt;- nth-1            #number of max increments
ncovariates     &lt;- 2                #number of covariates


# Define definition variables to hold the Covariates

obsAge1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age1&quot;), name=&quot;Age1&quot;)
obsAge2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age2&quot;), name=&quot;Age2&quot;)
obsSex1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex1&quot;), name=&quot;Sex1&quot;)
obsSex2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex2&quot;), name=&quot;Sex2&quot;)

#effect of age and sex on ordinal variable
LabCovA &lt;-c(&#39;BageThNSSH&#39;, &#39;BageThNSSH&#39;,&#39;BageThNSSH&#39;, &#39;BageThNSSH&#39;)
LabCovS &lt;-c(&#39;BsexThNSSH&#39;, &#39;BsexThNSSH&#39;,&#39;BsexThNSSH&#39;, &#39;BsexThNSSH&#39;)

betaA       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovA, name=&quot;BageTH&quot; )
betaS       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovS, name=&quot;BsexTH&quot; )

#mean matrix, set NSSH to NA and fixed
StMZmean=c(colMeans(mzdata[,1:2],na.rm=TRUE),0)
Mean    &lt;-mxMatrix( &quot;Full&quot;, 1, ntv, free=c(T,T,F,T,T,F), values=StMZmean, labels=c(&quot;mPGS&quot;, &#39;mcMFQ&#39;,NA, &quot;mPGS&quot;, &#39;mcMFQ&#39;,NA), name=&quot;ExpMean&quot; )


#Threshold matrix
StTH        &lt;-c(-1,0.1,0.1,0.1)
LabTh   &lt;-c(&#39;Tmz_11&#39;,&#39;imz_11&#39;,&#39;imz_12&#39;,&#39;imz_13&#39;)
Tr      &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=StTH, lbound=c(-4,0.001,0.001,0.001), ubound=c(4,4),
                labels=LabTh, name=&quot;Th&quot;)

inc     &lt;-mxMatrix( type=&quot;Lower&quot;,nrow=nth, ncol=nth, free=F, values=1, name=&quot;Low&quot;)

Thres   &lt;-mxAlgebra( expression= cbind(Low%*%Th + BageTH%x%Age1 + BsexTH%x%Sex1,
                                     Low%*%Th + BageTH%x%Age2 + BsexTH%x%Sex2),
                   name=&quot;ExpThres&quot;)

#Matrix that holds loadings from observed to latent variables
PatFl   &lt;- c(F,F,F,
           F,F,F,
           F,F,F) # Fix observed to latent to be 1 for all variables
StFl        &lt;- c(1,0,0,
           0,1,0,
           0,0,1)
LabFl   &lt;- c(&#39;PGS&#39;,NA,NA,
           NA,&#39;X&#39;,NA,
           NA, NA,&#39;Y&#39;)
Load        &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nv, ncol=nfact, free=PatFl, values=StFl, labels=LabFl, name=&quot;Loadings&quot; )
Id2     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=2, ncol=2, free=F, name=&quot;I2&quot; )
LoadTw  &lt;-mxAlgebra(I2%x%Loadings, name=&quot;FactLTw&quot;) #this will be a 2*nv x 2*nfact matrix,making it possible for both twins

#beta matrix to hold causal relationships
# Define the matrix to hold the Single headed Arrows (causal paths) between the 3 latent variables
# NB: direction of causation goes DOWN the column &amp; OUT along the row
PatPhC&lt;-c(F,T,T,
          F,F,T,
          F,F,F)
StPhC&lt;-c(0,0.05,0.05,
         0,0,0.05,
         0,0,0)
LabPhC&lt;-c(NA,&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;,
          NA,NA,&quot;X_to_Y&quot;,
          NA,NA,NA)
PhCaus  &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nfact, ncol=nfact, free=PatPhC, values=StPhC, labels=LabPhC, name=&quot;PhC&quot; )

### Build the ACE components
# Define the matrices to hold the A and C effects: Common (upper) 
LabAc&lt;-c(&quot;Ax&quot;,&quot;Axy&quot;,&quot;Ay&quot;)
freeA&lt;-c(T,T,T)
stA&lt;-c(0.5,0.5,0.5)

LabCc&lt;-c(&quot;Cx&quot;,&quot;Cxy&quot;,&quot;Cy&quot;)
freeC&lt;-c(T,F,F)
stC&lt;-c(0.5,0,0)

LabEc&lt;-c(&quot;Ex&quot;,&quot;Exy&quot;,&quot;Ey&quot;)
freeE&lt;-c(T,F,T)
stE&lt;-c(0.5,0,0.5)



PathsAc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeA, values=stA, labels=LabAc , name=&quot;ac&quot; )
PathsCc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeC, values=stC, labels=LabCc , name=&quot;cc&quot; )
PathsEc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeE, values=stE, labels=LabEc , name=&quot;ec&quot; )
covAc       &lt;-mxAlgebra( expression= ac %*% t(ac), name=&quot;Ac&quot; ) #cannot parse PGS variance into ACE
covCc       &lt;-mxAlgebra( expression= cc %*% t(cc), name=&quot;Cc&quot; ) #use these for standardisation.
covEc       &lt;-mxAlgebra( expression= ec %*% t(ec), name=&quot;Ec&quot; )
covPc       &lt;-mxAlgebra( expression= Ac+Cc+Ec, name=&quot;Vc&quot; ) #use a 2 x 2 matrix only. 



MZcovPc     &lt;-mxAlgebra( expression= Ac+Cc, name=&quot;MZVc&quot; )
DZcovPc     &lt;-mxAlgebra( expression= 0.5%x%Ac+Cc, name=&quot;DZVc&quot; )

#then specify var for PGS with a unit matrix (freely estimated)
PGSpath &lt;-mxMatrix(type=&quot;Full&quot;, nrow=1, ncol=1, free=T, values=0.5, labels=&quot;PGS_sd&quot; , name=&quot;PGSp&quot; )
PGSvar&lt;-mxAlgebra(expression=PGSp%*%t(PGSp),name=&quot;varPGS&quot;) #this will be the double headed arrow for variance of PGS

#zero matrices
zeromat&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=2,ncol=1,free=F,name=&quot;zero&quot;)
zeromat2&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=1,ncol=2,free=F,name=&quot;zero2&quot;)

totV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,Vc)),name=&quot;total_var&quot;)

#matrix above is a 3 x 3 matrix, within-twin matrix 
totMZV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,MZVc)),name=&quot;MZ_covar&quot;) #this is between person
totDZV&lt;-mxAlgebra(expression=cbind(rbind(0.5%x%varPGS,zero),rbind(zero2,DZVc)),name=&quot;DZ_covar&quot;)

# Generate Covariance of Latent factor model Including Causal Paths between factors
Id3     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=nfact, ncol=nfact, name=&quot;I3&quot; )

covFV   &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% total_var, name =&quot;FV&quot;) #(I3-PhC) gives the expression for the removal of the loop effect of causal relationships between the factors
covMZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% MZ_covar, name =&quot;MZFV&quot;) 
covDZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% DZ_covar, name =&quot;DZFV&quot;) 


# Constraint on total variance of Ordinal variable (A+C+E=1)
varL        &lt;- mxConstraint( expression=FV[3,3]==1, name=&quot;L&quot; ) #total variablity after taking into account for causal effects

# Var-Cov of measured vars in terms of latent factors and AC, Cc, and Ec
#this results in a 6x6 matrix

covMZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, MZFV), cbind(MZFV, FV) )) , name=&quot;expCovMZ&quot; ) #This traces the path from vars to factors and back to vars
covDZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, DZFV), cbind(DZFV, FV) )) , name=&quot;expCovDZ&quot; )


# Algebra to compute standardized variance components
#generate a 2x2 matrix which has taken into account for causal effects from FV:
Var2by2&lt;-mxAlgebra(expression=FV[2:3,2:3],name=&quot;FV2by2&quot;)
StA &lt;- mxAlgebra( expression=Ac/FV2by2, name=&quot;h2&quot;)
StC &lt;- mxAlgebra( expression=Cc/FV2by2, name=&quot;c2&quot;)
StE &lt;- mxAlgebra( expression=Ec/FV2by2, name=&quot;e2&quot;)

# # Algebra to compute Phenotypic, A, C &amp; E correlations for exposure and outcome
matI    &lt;- mxMatrix( type=&quot;Iden&quot;, nrow=nv-1, ncol=nv-1, name=&quot;I2&quot;)
rph &lt;- mxAlgebra( expression= solve(sqrt(I3*FV)) %*% FV %*% solve(sqrt(I3*FV)), name=&quot;Rph&quot;) #get overall Rph
rAc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ac)) %*% Ac %*% solve(sqrt(I2*Ac)), name=&quot;Rac&quot; )


# Algebra to get standardised b1, b2 and g1 paths:
beta1=mxAlgebra(expression= (PhC[2,1]*sqrt(FV[1,1]))/(sqrt(FV[2,2])), name=&quot;stB1&quot;)
beta2=mxAlgebra(expression= (PhC[3,2]*sqrt(FV[2,2]))/(sqrt(FV[3,3])), name=&quot;stG1&quot;)
pleio=mxAlgebra(expression= (PhC[3,1]*sqrt(FV[1,1]))/(sqrt(FV[3,3])), name=&quot;stB2&quot;)


#algebra to get RPh due to A,C,E and causal effects: 
RphACE&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                   #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                   #(sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), #this should be zero because re will be fixed to zero.
                                   stB2*stB1, stG1),name=&quot;ACErph&quot;)

# Data objects for Multiple Groups
dataMZ  &lt;- mxData( observed=mzdata, type=&quot;raw&quot; )
dataDZ  &lt;- mxData( observed=dzdata, type=&quot;raw&quot; )


# Objective objects for Multiple Groups
objMZ       &lt;- mxExpectationNormal( covariance=&quot;expCovMZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;NSSH1&quot;,&quot;NSSH2&quot;) )
objDZ       &lt;- mxExpectationNormal( covariance=&quot;expCovDZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;NSSH1&quot;,&quot;NSSH2&quot;) )

fitFunction &lt;- mxFitFunctionML()
#fitFunction &lt;- mxFitFunctionWLS()

# Combine Groups

pars&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
           covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
           StA,StC,StE,matI,rph,rAc,beta1,beta2,pleio,Var2by2,RphACE)

modelMZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ&quot; )
modelDZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ&quot; )


minus2ll    &lt;-mxAlgebra( expression=MZ.objective + DZ.objective, name=&quot;m2LL&quot; )
obj     &lt;-mxFitFunctionAlgebra( &quot;m2LL&quot; )

ACEModel    &lt;-mxModel(&quot;ACE&quot;, pars, modelMZ, modelDZ, minus2ll, obj)

#### run the ACE model which already has the parameters set or constrained: 
ACEFit      &lt;-mxTryHardOrdinal(ACEModel, intervals=F)
(ACESum &lt;- summary(ACEFit))

tableMZ&lt;-as.table(mxEval(MZ.expCovMZ,ACEFit))
colnames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;cMFQ1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;cMFQ2&quot;,&quot;NSSH2&quot;)
rownames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;cMFQ1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;cMFQ2&quot;,&quot;NSSH2&quot;)
round(tableMZ,3)

tableDZ&lt;-as.table(mxEval(DZ.expCovDZ,ACEFit))
colnames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;cMFQ1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;cMFQ2&quot;,&quot;NSSH2&quot;)
rownames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;cMFQ1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;cMFQ2&quot;,&quot;NSSH2&quot;)
round(tableDZ,3)

mxEval(MZ.stg1,ACEFit)

pathsCI1    &lt;-mxCI (c (&#39;MZ.stB1&#39;,&#39;MZ.stB2&#39;,&#39;MZ.stG1&#39;))
pathsCI2&lt;-mxCI(c(&#39;MZ.h2[1,1]&#39;,&#39;MZ.c2[1,1]&#39;,&#39;MZ.e2[1,1]&#39;,
                 &#39;MZ.h2[2,2]&#39;,&#39;MZ.e2[2,2]&#39;))
pathsCI3&lt;-mxCI(c(&#39;MZ.Rac[2,1]&#39;,&#39;MZ.Rph[3,2]&#39;,
                 &#39;MZ.ACErph[1,1]&#39;,&#39;MZ.ACErph[1,2]&#39;,&#39;MZ.ACErph[1,3]&#39;))

#CI1
ACEModel1&lt;-mxModel(ACEFit,pathsCI1)
ACEFit1&lt;-mxRun(ACEModel1,intervals=T)
(ACESum1    &lt;- summary(ACEFit1))

#CI2
ACEModel2&lt;-mxModel(ACEFit,pathsCI2)
ACEFit2&lt;-mxRun(ACEModel2,intervals=T)
(ACESum2    &lt;- summary(ACEFit2))

#CI3
ACEModel3&lt;-mxModel(ACEFit,pathsCI3)
ACEFit3&lt;-mxRun(ACEModel3,intervals=T)
(ACESum3    &lt;- summary(ACEFit3))


sum(mxEval(MZ.ACErph[1:3],ACEFit))

ACESum1$CI
ACESum2$CI
ACESum3$CI

mxEval(MZ.MZcovPc,ACEFit)
mxEval(MZ.PhC,ACEFit)
##### create full bivariate model without direction of causation for comparison #####
## re = True, stG1= False, then compare BIC/AIC
FullBiMod&lt;-mxModel(ACEFit,name=&quot;Full_Bi&quot;)
FullBiMod&lt;-omxSetParameters(FullBiMod, labels=c(&quot;Exy&quot;,&quot;X_to_Y&quot;), free=c(T,F),values=c(0.5,0))
FullBiFit&lt;-mxRun(FullBiMod, intervals=F)
(FullBiSum&lt;-summary(FullBiFit,verbose=T))
#check re
Ec&lt;-mxEval(MZ.Ec,FullBiFit)
Itwo&lt;-mxEval(MZ.I2,FullBiFit)
(Rec&lt;-solve(sqrt(Itwo*Ec)) %*% Ec %*% solve(sqrt(Itwo*Ec)))

#check g1 (the causal effect)
mxEval(MZ.stG1,FullBiFit)

#other values
mxEval(MZ.stB1,FullBiFit)
mxEval(MZ.stg1,FullBiFit)
mxEval(MZ.h2,FullBiFit);mxEval(MZ.c2,FullBiFit);mxEval(MZ.e2,FullBiFit)
mxEval(MZ.Rac,FullBiFit)
mxEval(MZ.Rph,FullBiFit)

#get Rcc
Cc&lt;-mxEval(MZ.Cc,FullBiFit)
(Rcc&lt;-solve(sqrt(Itwo*Cc)) %*% Cc %*% solve(sqrt(Itwo*Cc)))
# compare the two models
mxCompare(FullBiFit,ACEFit)

## now run model without effect of PRS only but still with stG1 and rc,re dropped ###
DoC_Mod&lt;-mxModel(ACEFit,name=&quot;DOC&quot;)
DoC_Mod&lt;-omxSetParameters(DoC_Mod, labels=c(&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;), free=c(F,F),values=c(0,0))
DoC_Fit&lt;-mxRun(DoC_Mod, intervals=F)
#get CI for stG1
DoC_Mod_CI&lt;-mxModel(DoC_Fit,mxCI(&quot;MZ.stG1&quot;))
DoC_Fit_CI&lt;-mxRun(DoC_Mod_CI, intervals=T)
summary(DoC_Fit_CI,verbose=T)
(DoCSum&lt;-summary(DoC_Fit,verbose=T))

#check PGS effect
mxEval(MZ.stB1,DoC_Fit);mxEval(MZ.stB2,DoC_Fit)
#values for the path diagram
mxEval(MZ.stG1,DoC_Fit)
mxEval(MZ.h2,DoC_Fit);mxEval(MZ.c2,DoC_Fit);mxEval(MZ.e2,DoC_Fit)
mxEval(MZ.Rac,DoC_Fit)
mxEval(MZ.Rph,DoC_Fit)
mxEval(MZ.expCovMZ,DoC_Fit);mxEval(DZ.expCovDZ,DoC_Fit)
#compare the models
mxCompare(ACEFit,DoC_Fit)

##### sensitivity analysis: what if rE is not zero, e.g. fixed to 0.20? #####
#add re into the model
rEc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ec)) %*% Ec %*% solve(sqrt(I2*Ec)), name=&quot;Rec&quot; )
RphACE2&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                   
                                    (sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), 
                                    stB2*stB1, stG1),name=&quot;ACErph2&quot;)

pars2&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
            covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
            StA,StC,StE,matI,rph,rAc,rEc,beta1,beta2,pleio,Var2by2,RphACE2)

modelMZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ2&quot; )
modelDZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ2&quot; )
minus2ll2   &lt;-mxAlgebra( expression=MZ2.objective + DZ2.objective, name=&quot;m2LL2&quot; )
obj2        &lt;-mxFitFunctionAlgebra( &quot;m2LL2&quot; )
rE_fixed_Model  &lt;-mxModel(&quot;rE_fixed&quot;, pars2, modelMZ2, modelDZ2, minus2ll2, obj2)
rE_fixed_Model &lt;-omxSetParameters(rE_fixed_Model, labels=c(&quot;Exy&quot;, &quot;X_to_Y&quot;), free=c(T,T),values=c(0.5,0.2))

pathsCI_rEfix   &lt;-mxCI (c (&#39;MZ2.stG1&#39;))
#re = 0.05
rE_fixed_Model005&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.05, name=&quot;con1&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit1       &lt;- mxTryHardOrdinal(rE_fixed_Model005, intervals = T)

(rE_Fixed_FitSumm1&lt;-summary(rE_Fixed_Fit1,verbose=T))
mxEval(MZ2.stG1,rE_Fixed_Fit1)
mxEval(MZ2.Rec,rE_Fixed_Fit1)

## re=0.10
rE_fixed_Model010&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed2&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.10, name=&quot;con2&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit2       &lt;- mxTryHardOrdinal(rE_fixed_Model010, intervals = T)

(rE_Fixed_FitSumm2&lt;-summary(rE_Fixed_Fit2,verbose=T))

## re=0.15
rE_fixed_Model015&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed3&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.15, name=&quot;con3&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit3       &lt;- mxTryHardOrdinal(rE_fixed_Model015, intervals = T)

(rE_Fixed_FitSumm3&lt;-summary(rE_Fixed_Fit3,verbose=T))

## re=0.20
rE_fixed_Model020&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed4&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.20, name=&quot;con4&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit4       &lt;- mxTryHardOrdinal(rE_fixed_Model020, intervals = T)

(rE_Fixed_FitSumm4&lt;-summary(rE_Fixed_Fit4,verbose=T))

## re=0.25
rE_fixed_Model025&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed5&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.25, name=&quot;con5&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit5       &lt;- mxTryHardOrdinal(rE_fixed_Model025, intervals = T)

(rE_Fixed_FitSumm5&lt;-summary(rE_Fixed_Fit5,verbose=T))


rbind(mxCompare(ACEFit1,rE_Fixed_Fit1),
      mxCompare(ACEFit1,rE_Fixed_Fit2)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit3)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit4)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit5)[2,])


rbind(ACESum1$CI[2,],
      rE_Fixed_FitSumm1$CI,
      rE_Fixed_FitSumm2$CI,
      rE_Fixed_FitSumm3$CI,
      rE_Fixed_FitSumm4$CI,
      rE_Fixed_FitSumm5$CI)


rbind(mxEval(MZ2.stG1,rE_Fixed_Fit1),
      mxEval(MZ2.stG1,rE_Fixed_Fit2),
      mxEval(MZ2.stG1,rE_Fixed_Fit3),
      mxEval(MZ2.stG1,rE_Fixed_Fit4),
      mxEval(MZ2.stG1,rE_Fixed_Fit5))

mxEval(MZ2.stG1,rE_Fixed_Fit1);mxEval(MZ2.stG1,rE_Fixed_Fit2);mxEval(MZ2.stG1,rE_Fixed_Fit3);mxEval(MZ2.stG1,rE_Fixed_Fit4);mxEval(MZ2.stG1,rE_Fixed_Fit5)

## save the results as RData
save.image(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv5_cMFQ_NSSH_20_April_2021.RData&quot;)
load(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv5_cMFQ_NSSH_20_April_2021.RData&quot;)</code></pre>
</div>
<div id="cmfq-ssh" class="section level3">
<h3>cMFQ-SSH</h3>
<pre class="r"><code>#******************************************************

###### Regress out age, sex and transform cMFQ variable #####
merged_data$res_basic_cMFQ1&lt;- residuals(lm(merged_data$pcbhmfqt1
                                           ~merged_data$age_161 + merged_data$sex1,
                                           na.action=&quot;na.exclude&quot;))
merged_data$res_trans_order_cMFQ1 &lt;-log(merged_data$res_basic_cMFQ1+6)*2

#do same thing for twin 2. 
merged_data$res_basic_cMFQ2&lt;- residuals(lm(merged_data$pcbhmfqt2
                                           ~merged_data$age_162 + merged_data$sex2,
                                           na.action=&quot;na.exclude&quot;))

merged_data$res_trans_order_cMFQ2 &lt;-log(merged_data$res_basic_cMFQ2+6)*2

#***************************************************************************************
#################################### MR-DoC model ######################################
#***************************************************************************************

#variables I will need for this cMFQ MR-DoC model:
vars        &lt;-c(&#39;MDD_PRS&#39;,&#39;cMFQ&#39;,&#39;SH&#39;)

#variables for the second ACE fit to compare results (residualised then transformed)
selVars &lt;-c(&#39;MDD100_res_t1&#39;, &#39;res_trans_order_cMFQ1&#39;,&#39;SSH1&#39;,
            &#39;MDD100_res_t2&#39;, &#39;res_trans_order_cMFQ2&#39;,&#39;SSH2&#39;) 


useVars &lt;-c(&#39;MDD100_res_t1&#39;, &#39;res_trans_order_cMFQ1&#39;,&#39;SSH1&#39;,
            &#39;MDD100_res_t2&#39;, &#39;res_trans_order_cMFQ2&#39;,&#39;SSH2&#39;,
            &#39;age1&#39;, &#39;age2&#39;, &#39;sex1&#39;,&#39;sex2&#39;) #age is for at age 21

#need to recode missing age into 999
table(is.na(merged_data$age1))
merged_data$SSH1[is.na(merged_data$age1)] &lt;- NA
merged_data$SSH2[is.na(merged_data$age2)] &lt;- NA
merged_data$age1[is.na(merged_data$age1)] &lt;- 999
merged_data$age2[is.na(merged_data$age2)] &lt;- 999
merged_data[1:20,1:8]

#mz and dzdata for using res_trans_order_cMFQ
mzdata&lt;-subset(merged_data, zygos%in%1&amp;random==1 , useVars)
dzdata&lt;-subset(merged_data, zygos%in%2&amp;random==1 , useVars)



head(mzdata)

#do ACE model #
nv          &lt;- 3                # number of variables for a twin = 1 in Univariate
nvo             &lt;- 1                #number of ordinal variables per twin
nvc             &lt;- nv-nvo           #number of continuous variables per twin
poso            &lt;- nvo          #position where ordinal variables start
ntv         &lt;- 2*nv         # number of variables for a pair = 2* 1 for Univariate
nth         &lt;- 4    # number of max thresholds
nfact       &lt;- 3                # number of Latent Factors
ncor            &lt;- (nv*(nv+1)/2)-nv # number of free elements in a correlation matrix nv*nv
ninc            &lt;- nth-1            #number of max increments
ncovariates     &lt;- 2                #number of covariates


# Define definition variables to hold the Covariates

obsAge1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age1&quot;), name=&quot;Age1&quot;)
obsAge2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age2&quot;), name=&quot;Age2&quot;)
obsSex1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex1&quot;), name=&quot;Sex1&quot;)
obsSex2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex2&quot;), name=&quot;Sex2&quot;)

#effect of age and sex on ordinal variable
LabCovA &lt;-c(&#39;BageThSSH&#39;, &#39;BageThSSH&#39;,&#39;BageThSSH&#39;, &#39;BageThSSH&#39;)
LabCovS &lt;-c(&#39;BsexThSSH&#39;, &#39;BsexThSSH&#39;,&#39;BsexThSSH&#39;, &#39;BsexThSSH&#39;)

betaA       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovA, name=&quot;BageTH&quot; )
betaS       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovS, name=&quot;BsexTH&quot; )

#mean matrix, set NSSH to NA and fixed
StMZmean=c(colMeans(mzdata[,1:2],na.rm=TRUE),0)
Mean    &lt;-mxMatrix( &quot;Full&quot;, 1, ntv, free=c(T,T,F,T,T,F), values=StMZmean, labels=c(&quot;mPGS&quot;, &#39;mcMFQ&#39;,NA, &quot;mPGS&quot;, &#39;mcMFQ&#39;,NA), name=&quot;ExpMean&quot; )


#Threshold matrix
StTH        &lt;-c(-1,0.1,0.1,0.1)
LabTh   &lt;-c(&#39;Tmz_11&#39;,&#39;imz_11&#39;,&#39;imz_12&#39;,&#39;imz_13&#39;)
Tr      &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=StTH, lbound=c(-4,0.001,0.001,0.001), ubound=c(4,4),
                labels=LabTh, name=&quot;Th&quot;)

inc     &lt;-mxMatrix( type=&quot;Lower&quot;,nrow=nth, ncol=nth, free=F, values=1, name=&quot;Low&quot;)

Thres   &lt;-mxAlgebra( expression= cbind(Low%*%Th + BageTH%x%Age1 + BsexTH%x%Sex1,
                                     Low%*%Th + BageTH%x%Age2 + BsexTH%x%Sex2),
                   name=&quot;ExpThres&quot;)

#Matrix that holds loadings from observed to latent variables
PatFl   &lt;- c(F,F,F,
           F,F,F,
           F,F,F) # Fix observed to latent to be 1 for all variables
StFl        &lt;- c(1,0,0,
           0,1,0,
           0,0,1)
LabFl   &lt;- c(&#39;PGS&#39;,NA,NA,
           NA,&#39;X&#39;,NA,
           NA, NA,&#39;Y&#39;)
Load        &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nv, ncol=nfact, free=PatFl, values=StFl, labels=LabFl, name=&quot;Loadings&quot; )
Id2     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=2, ncol=2, free=F, name=&quot;I2&quot; )
LoadTw  &lt;-mxAlgebra(I2%x%Loadings, name=&quot;FactLTw&quot;) #this will be a 2*nv x 2*nfact matrix,making it possible for both twins

#beta matrix to hold causal relationships
# Define the matrix to hold the Single headed Arrows (causal paths) between the 3 latent variables
# NB: direction of causation goes DOWN the column &amp; OUT along the row
PatPhC&lt;-c(F,T,T,
          F,F,T,
          F,F,F)
StPhC&lt;-c(0,0.05,0.05,
         0,0,0.05,
         0,0,0)
LabPhC&lt;-c(NA,&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;,
          NA,NA,&quot;X_to_Y&quot;,
          NA,NA,NA)
PhCaus  &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nfact, ncol=nfact, free=PatPhC, values=StPhC, labels=LabPhC, name=&quot;PhC&quot; )

### Build the ACE components
# Define the matrices to hold the A and C effects: Common (upper) 
LabAc&lt;-c(&quot;Ax&quot;,&quot;Axy&quot;,&quot;Ay&quot;)
freeA&lt;-c(T,T,T)
stA&lt;-c(0.5,0.5,0.5)

LabCc&lt;-c(&quot;Cx&quot;,&quot;Cxy&quot;,&quot;Cy&quot;)
freeC&lt;-c(T,F,F)
stC&lt;-c(0.5,0,0)

LabEc&lt;-c(&quot;Ex&quot;,&quot;Exy&quot;,&quot;Ey&quot;)
freeE&lt;-c(T,F,T)
stE&lt;-c(0.5,0,0.5)



PathsAc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeA, values=stA, labels=LabAc , name=&quot;ac&quot; )
PathsCc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeC, values=stC, labels=LabCc , name=&quot;cc&quot; )
PathsEc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeE, values=stE, labels=LabEc , name=&quot;ec&quot; )
covAc       &lt;-mxAlgebra( expression= ac %*% t(ac), name=&quot;Ac&quot; ) #cannot parse PGS variance into ACE
covCc       &lt;-mxAlgebra( expression= cc %*% t(cc), name=&quot;Cc&quot; ) #use these for standardisation.
covEc       &lt;-mxAlgebra( expression= ec %*% t(ec), name=&quot;Ec&quot; )
covPc       &lt;-mxAlgebra( expression= Ac+Cc+Ec, name=&quot;Vc&quot; ) #use a 2 x 2 matrix only. 
MZcovPc     &lt;-mxAlgebra( expression= Ac+Cc, name=&quot;MZVc&quot; )
DZcovPc     &lt;-mxAlgebra( expression= 0.5%x%Ac+Cc, name=&quot;DZVc&quot; )

#then specify var for PGS with a unit matrix (freely estimated)
PGSpath &lt;-mxMatrix(type=&quot;Full&quot;, nrow=1, ncol=1, free=T, values=0.5, labels=&quot;PGS_sd&quot; , name=&quot;PGSp&quot; )
PGSvar&lt;-mxAlgebra(expression=PGSp%*%t(PGSp),name=&quot;varPGS&quot;) #this will be the double headed arrow for variance of PGS

#zero matrices
zeromat&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=2,ncol=1,free=F,name=&quot;zero&quot;)
zeromat2&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=1,ncol=2,free=F,name=&quot;zero2&quot;)

totV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,Vc)),name=&quot;total_var&quot;)#if it complains, switch rbind and cbind.
#matrix above is a 3 x 3 matrix, within-twin matrix 
totMZV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,MZVc)),name=&quot;MZ_covar&quot;) #this is between person
totDZV&lt;-mxAlgebra(expression=cbind(rbind(0.5%x%varPGS,zero),rbind(zero2,DZVc)),name=&quot;DZ_covar&quot;)

# Generate Covariance of Latent factor model Including Causal Paths between factors
Id3     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=nfact, ncol=nfact, name=&quot;I3&quot; )

covFV   &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% total_var, name =&quot;FV&quot;) #(I4-PhC) gives the expression for the removal of the loop effect of causal relationships between the factors (1-4).
covMZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% MZ_covar, name =&quot;MZFV&quot;) #(I4-PhC) gives the expression for the removal of the loop effect of causal relationships between the factors (1-4).
covDZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% DZ_covar, name =&quot;DZFV&quot;) #(I4-PhC) gives the expression for the removal of the loop effect of causal relationships between the factors (1-4).


# Constraint on total variance of Ordinal variable (A+C+E=1)
varL        &lt;- mxConstraint( expression=FV[3,3]==1, name=&quot;L&quot; ) #total variablity after taking into account for causal effects

# Var-Cov of measured vars in terms of latent factors and AC, Cc, and Ec
#this results in a 6x6 matrix

covMZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, MZFV), cbind(MZFV, FV) )) , name=&quot;expCovMZ&quot; )#This traces the path from vars to factors and back to vars
covDZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, DZFV), cbind(DZFV, FV) )) , name=&quot;expCovDZ&quot; )


# Algebra to compute standardized variance components
#generate a 2x2 matrix which has taken into account for causal effects from FV:
Var2by2&lt;-mxAlgebra(expression=FV[2:3,2:3],name=&quot;FV2by2&quot;)
StA &lt;- mxAlgebra( expression=Ac/FV2by2, name=&quot;h2&quot;)
StC &lt;- mxAlgebra( expression=Cc/FV2by2, name=&quot;c2&quot;)
StE &lt;- mxAlgebra( expression=Ec/FV2by2, name=&quot;e2&quot;)

# # Algebra to compute Phenotypic, A, C &amp; E correlations for exposure and outcome
matI    &lt;- mxMatrix( type=&quot;Iden&quot;, nrow=nv-1, ncol=nv-1, name=&quot;I2&quot;)
rph &lt;- mxAlgebra( expression= solve(sqrt(I3*FV)) %*% FV %*% solve(sqrt(I3*FV)), name=&quot;Rph&quot;)#get overall Rph
rAc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ac)) %*% Ac %*% solve(sqrt(I2*Ac)), name=&quot;Rac&quot; )



# Algebra to get standardised b1, b2 and g1 paths:
beta1=mxAlgebra(expression= (PhC[2,1]*sqrt(FV[1,1]))/(sqrt(FV[2,2])), name=&quot;stB1&quot;)
beta2=mxAlgebra(expression= (PhC[3,2]*sqrt(FV[2,2]))/(sqrt(FV[3,3])), name=&quot;stG1&quot;)
pleio=mxAlgebra(expression= (PhC[3,1]*sqrt(FV[1,1]))/(sqrt(FV[3,3])), name=&quot;stB2&quot;)


#algebra to get RPh due to A,C,E and causal effects: 
RphACE&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                   stg1*stB1, stb2),name=&quot;ACErph&quot;)

# Data objects for Multiple Groups
dataMZ  &lt;- mxData( observed=mzdata, type=&quot;raw&quot; )
dataDZ  &lt;- mxData( observed=dzdata, type=&quot;raw&quot; )


# Objective objects for Multiple Groups
objMZ       &lt;- mxExpectationNormal( covariance=&quot;expCovMZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;SSH1&quot;,&quot;SSH2&quot;) )
objDZ       &lt;- mxExpectationNormal( covariance=&quot;expCovDZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;SSH1&quot;,&quot;SSH2&quot;) )

fitFunction &lt;- mxFitFunctionML()

# Combine Groups

pars&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
           covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
           StA,StC,StE,matI,rph,rAc,beta1,beta2,pleio,Var2by2,RphACE)

modelMZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ&quot; )
modelDZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ&quot; )


minus2ll    &lt;-mxAlgebra( expression=MZ.objective + DZ.objective, name=&quot;m2LL&quot; )
obj     &lt;-mxFitFunctionAlgebra( &quot;m2LL&quot; )

ACEModel    &lt;-mxModel(&quot;ACE&quot;, pars, modelMZ, modelDZ, minus2ll, obj)

#### run the ACE model which already has the parameters set or constrained: 
ACEFit      &lt;-mxTryHardOrdinal(ACEModel, intervals=F)
(ACESum &lt;- summary(ACEFit))

tableMZ&lt;-as.table(mxEval(MZ.expCovMZ,ACEFit))
colnames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;cMFQ1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;cMFQ2&quot;,&quot;SSH2&quot;)
rownames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;cMFQ1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;cMFQ2&quot;,&quot;SSH2&quot;)
round(tableMZ,3)

tableDZ&lt;-as.table(mxEval(DZ.expCovDZ,ACEFit))
colnames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;cMFQ1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;cMFQ2&quot;,&quot;SSH2&quot;)
rownames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;cMFQ1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;cMFQ2&quot;,&quot;SSH2&quot;)
round(tableDZ,3)

mxEval(MZ.stB1,ACEFit);mxEval(MZ.stG1,ACEFit);mxEval(MZ.stB2,ACEFit)

pathsCI1    &lt;-mxCI (c (&#39;MZ.stB1&#39;,&#39;MZ.stG1&#39;,&#39;MZ.stB2&#39;))
pathsCI2&lt;-mxCI(c(&#39;MZ.h2[1,1]&#39;,&#39;MZ.c2[1,1]&#39;,&#39;MZ.e2[1,1]&#39;,
                 &#39;MZ.h2[2,2]&#39;,&#39;MZ.e2[2,2]&#39;))
pathsCI3&lt;-mxCI(c(&#39;MZ.Rac[2,1]&#39;,&#39;MZ.Rph[3,2]&#39;,
                 &#39;MZ.ACErph[1,1]&#39;,&#39;MZ.ACErph[1,2]&#39;,&#39;MZ.ACErph[1,3]&#39;))

#CI1
ACEModel1&lt;-mxModel(ACEFit,pathsCI1)
ACEFit1&lt;-mxRun(ACEModel1,intervals=T)
(ACESum1    &lt;- summary(ACEFit1))

#CI2
ACEModel2&lt;-mxModel(ACEFit,pathsCI2)
ACEFit2&lt;-mxRun(ACEModel2,intervals=T)
(ACESum2    &lt;- summary(ACEFit2))

#CI3
ACEModel3&lt;-mxModel(ACEFit,pathsCI3)
ACEFit3&lt;-mxRun(ACEModel3,intervals=T)
(ACESum3    &lt;- summary(ACEFit3))


sum(mxEval(MZ.ACErph[1:3],ACEFit))

ACESum1$CI
ACESum2$CI
ACESum3$CI


##### create full bivariate model without direction of causation for comparison #####
## re = True, stG1= False
FullBiMod&lt;-mxModel(ACEFit,name=&quot;Full_Bi&quot;)
FullBiMod&lt;-omxSetParameters(FullBiMod, labels=c(&quot;Exy&quot;,&quot;X_to_Y&quot;), free=c(TRUE,FALSE),values=c(0.5,0))
FullBiFit&lt;-mxRun(FullBiMod, intervals=F)
(FullBiSum&lt;-summary(FullBiFit,verbose=T))
#check re
Ec&lt;-mxEval(MZ.Ec,FullBiFit)
Itwo&lt;-mxEval(MZ.I2,FullBiFit)
(Rec&lt;-solve(sqrt(Itwo*Ec)) %*% Ec %*% solve(sqrt(Itwo*Ec)))

#check G1 (the causal effect)
mxEval(MZ.stG1,FullBiFit)

#other values
mxEval(MZ.stB1,FullBiFit)
mxEval(MZ.stB2,FullBiFit)
mxEval(MZ.h2,FullBiFit);mxEval(MZ.c2,FullBiFit);mxEval(MZ.e2,FullBiFit)
mxEval(MZ.Rac,FullBiFit)
mxEval(MZ.Rph,FullBiFit)

#get Rcc
Cc&lt;-mxEval(MZ.Cc,FullBiFit)
(Rcc&lt;-solve(sqrt(Itwo*Cc)) %*% Cc %*% solve(sqrt(Itwo*Cc)))
# compare the two models
mxCompare(FullBiFit,ACEFit)

## now run model without effect of PRS only but still with stb2 and rc,re dropped ###
DoC_Mod&lt;-mxModel(ACEFit,name=&quot;DOC&quot;)
DoC_Mod&lt;-omxSetParameters(DoC_Mod, labels=c(&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;), free=c(F,F),values=c(0,0))
DoC_Fit&lt;-mxRun(DoC_Mod, intervals=F)
(DoCSum&lt;-summary(DoC_Fit,verbose=T))

#check PGS effect
mxEval(MZ.stB1,DoC_Fit);mxEval(MZ.stB2,DoC_Fit)
#values for the path diagram
mxEval(MZ.stG1,DoC_Fit)
mxEval(MZ.h2,DoC_Fit);mxEval(MZ.c2,DoC_Fit);mxEval(MZ.e2,DoC_Fit)
mxEval(MZ.Rac,DoC_Fit)
mxEval(MZ.Rph,DoC_Fit)
mxEval(MZ.expCovMZ,DoC_Fit);mxEval(DZ.expCovDZ,DoC_Fit)
#compare the models
mxCompare(ACEFit,DoC_Fit)



##### sensitivity analysis: what if rE is not zero, e.g. fixed to 0.20? #####
#add re into the model
rEc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ec)) %*% Ec %*% solve(sqrt(I2*Ec)), name=&quot;Rec&quot; )
RphACE2&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                    #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                    (sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), 
                                    stB2*stB1, stG1),name=&quot;ACErph2&quot;)
pars2&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
            covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
            StA,StC,StE,matI,rph,rAc,rEc,beta1,beta2,pleio,Var2by2,RphACE2)

modelMZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ2&quot; )
modelDZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ2&quot; )
minus2ll2   &lt;-mxAlgebra( expression=MZ2.objective + DZ2.objective, name=&quot;m2LL2&quot; )
obj2        &lt;-mxFitFunctionAlgebra( &quot;m2LL2&quot; )
rE_fixed_Model  &lt;-mxModel(&quot;rE_fixed&quot;, pars2, modelMZ2, modelDZ2, minus2ll2, obj2)
rE_fixed_Model &lt;-omxSetParameters(rE_fixed_Model, labels=c(&quot;Exy&quot;, &quot;X_to_Y&quot;), free=c(T,T),values=c(0.5,0.2))

pathsCI_rEfix   &lt;-mxCI (c (&#39;MZ2.stG1&#39;))
#re = 0.05
rE_fixed_Model005&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.05, name=&quot;con1&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit1       &lt;- mxTryHardOrdinal(rE_fixed_Model005, intervals = T)

(rE_Fixed_FitSumm1&lt;-summary(rE_Fixed_Fit1,verbose=T))
mxEval(MZ2.stb2,rE_Fixed_Fit1)
mxEval(MZ2.Rec,rE_Fixed_Fit1)

## re=0.10
rE_fixed_Model010&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed2&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.10, name=&quot;con2&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit2       &lt;- mxTryHardOrdinal(rE_fixed_Model010, intervals = T)

(rE_Fixed_FitSumm2&lt;-summary(rE_Fixed_Fit2,verbose=T))

## re=0.15
rE_fixed_Model015&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed3&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.15, name=&quot;con3&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit3       &lt;- mxTryHardOrdinal(rE_fixed_Model015, intervals = T)

(rE_Fixed_FitSumm3&lt;-summary(rE_Fixed_Fit3,verbose=T))

## re=0.20
rE_fixed_Model020&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed4&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.20, name=&quot;con4&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit4       &lt;- mxTryHardOrdinal(rE_fixed_Model020, intervals = T)

(rE_Fixed_FitSumm4&lt;-summary(rE_Fixed_Fit4,verbose=T))

## re=0.25
rE_fixed_Model025&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed5&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.25, name=&quot;con5&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit5       &lt;- mxTryHardOrdinal(rE_fixed_Model025, intervals = T)

(rE_Fixed_FitSumm5&lt;-summary(rE_Fixed_Fit5,verbose=T))


rbind(mxCompare(ACEFit1,rE_Fixed_Fit1),
      mxCompare(ACEFit1,rE_Fixed_Fit2)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit3)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit4)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit5)[2,])

rbind(mxEval(MZ2.stG1,rE_Fixed_Fit1),
      mxEval(MZ2.stG1,rE_Fixed_Fit2),
      mxEval(MZ2.stG1,rE_Fixed_Fit3),
      mxEval(MZ2.stG1,rE_Fixed_Fit4),
      mxEval(MZ2.stG1,rE_Fixed_Fit5))

rbind(ACESum1$CI[2,],
      rE_Fixed_FitSumm1$CI,
      rE_Fixed_FitSumm2$CI,
      rE_Fixed_FitSumm3$CI,
      rE_Fixed_FitSumm4$CI,
      rE_Fixed_FitSumm5$CI)

## save the results as RData
save.image(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv5_cMFQ_SSH_20_April_2021.RData&quot;)
load(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv3_cMFQ_SSH_08_April_2021.RData&quot;)</code></pre>
</div>
<div id="pconn-nssh" class="section level3">
<h3>pCONN-NSSH</h3>
<pre class="r"><code>#******************************************************

###### Regress out age, sex and transform pCONN variable #####
#residualise first, then tranform
merged_data$res_basic_pCONN1&lt;- residuals(lm(merged_data$ppbhconnt1
                                            ~merged_data$age_161 + merged_data$sex1,
                                            na.action=&quot;na.exclude&quot;))
merged_data$res_trans_order_pCONN1 &lt;-log(merged_data$res_basic_pCONN1+10)*2

#do same thing for twin 2. 
merged_data$res_basic_pCONN2&lt;- residuals(lm(merged_data$ppbhconnt2
                                            ~merged_data$age_162 + merged_data$sex2,
                                            na.action=&quot;na.exclude&quot;))

merged_data$res_trans_order_pCONN2 &lt;-log(merged_data$res_basic_pCONN2+10)*2
#***************************************************************************************
#################################### MR-DoC model ######################################
#***************************************************************************************

#variables I will need for this pCONN MR-DoC model:
vars        &lt;-c(&#39;ADHD_PRS&#39;,&#39;pCONN&#39;,&#39;SH&#39;)
selVars &lt;-c(&#39;ADHD100_res_t1&#39;, &#39;res_trans_order_pCONN1&#39;,&#39;NSSH1&#39;,
            &#39;ADHD100_res_t2&#39;, &#39;res_trans_order_pCONN2&#39;,&#39;NSSH2&#39;)

useVars &lt;-c(&#39;ADHD100_res_t1&#39;, &#39;res_trans_order_pCONN1&#39;,&#39;NSSH1&#39;,
            &#39;ADHD100_res_t2&#39;, &#39;res_trans_order_pCONN2&#39;,&#39;NSSH2&#39;,
            &#39;age1&#39;, &#39;age2&#39;, &#39;sex1&#39;,&#39;sex2&#39;) #age is for at age 21


#need to recode missing age into 999
table(is.na(merged_data$age1))
merged_data$NSSH1[is.na(merged_data$age1)] &lt;- NA
merged_data$NSSH2[is.na(merged_data$age2)] &lt;- NA
merged_data$age1[is.na(merged_data$age1)] &lt;- 999
merged_data$age2[is.na(merged_data$age2)] &lt;- 999
merged_data[1:20,1:8]

#mz and dzdata for using res_trans_order_pCONN
mzdata&lt;-subset(merged_data, zygos%in%1&amp;random==1 , useVars)
dzdata&lt;-subset(merged_data, zygos%in%2&amp;random==1 , useVars)


head(mzdata)

#do ACE model #
nv          &lt;- 3                # number of variables for a twin = 1 in Univariate
nvo             &lt;- 1                #number of ordinal variables per twin
nvc             &lt;- nv-nvo           #number of continuous variables per twin
poso            &lt;- nvo          #position where ordinal variables start
ntv         &lt;- 2*nv         # number of variables for a pair = 2* 1 for Univariate
nth         &lt;- 4    # number of max thresholds
nfact       &lt;- 3                # number of Latent Factors
ncor            &lt;- (nv*(nv+1)/2)-nv # number of free elements in a correlation matrix nv*nv
ninc            &lt;- nth-1            #number of max increments
ncovariates     &lt;- 2                #number of covariates


# Define definition variables to hold the Covariates

obsAge1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age1&quot;), name=&quot;Age1&quot;)
obsAge2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age2&quot;), name=&quot;Age2&quot;)
obsSex1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex1&quot;), name=&quot;Sex1&quot;)
obsSex2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex2&quot;), name=&quot;Sex2&quot;)

#effect of age and sex on ordinal variable
LabCovA &lt;-c(&#39;BageThNSSH&#39;, &#39;BageThNSSH&#39;,&#39;BageThNSSH&#39;, &#39;BageThNSSH&#39;)
LabCovS &lt;-c(&#39;BsexThNSSH&#39;, &#39;BsexThNSSH&#39;,&#39;BsexThNSSH&#39;, &#39;BsexThNSSH&#39;)

betaA       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovA, name=&quot;BageTH&quot; )
betaS       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovS, name=&quot;BsexTH&quot; )

#mean matrix, set NSSH to NA and fixed
StMZmean=c(colMeans(mzdata[,1:2],na.rm=TRUE),0)
Mean    &lt;-mxMatrix( &quot;Full&quot;, 1, ntv, free=c(T,T,F,T,T,F), values=StMZmean, labels=c(&quot;mPGS&quot;, &#39;mpCONN&#39;,NA, &quot;mPGS&quot;, &#39;mpCONN&#39;,NA), name=&quot;ExpMean&quot; )


#Threshold matrix
StTH        &lt;-c(-1,0.1,0.1,0.1)
LabTh   &lt;-c(&#39;Tmz_11&#39;,&#39;imz_11&#39;,&#39;imz_12&#39;,&#39;imz_13&#39;)
Tr      &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=StTH, lbound=c(-4,0.001,0.001,0.001), ubound=c(4,4),
                labels=LabTh, name=&quot;Th&quot;)

inc     &lt;-mxMatrix( type=&quot;Lower&quot;,nrow=nth, ncol=nth, free=F, values=1, name=&quot;Low&quot;)

Thres   &lt;-mxAlgebra( expression= cbind(Low%*%Th + BageTH%x%Age1 + BsexTH%x%Sex1,
                                     Low%*%Th + BageTH%x%Age2 + BsexTH%x%Sex2),
                   name=&quot;ExpThres&quot;)

#Matrix that holds loadings from observed to latent variables
PatFl   &lt;- c(F,F,F,
           F,F,F,
           F,F,F) # Fix observed to latent to be 1 for all variables
StFl        &lt;- c(1,0,0,
           0,1,0,
           0,0,1)
LabFl   &lt;- c(&#39;PGS&#39;,NA,NA,
           NA,&#39;X&#39;,NA,
           NA, NA,&#39;Y&#39;)
Load        &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nv, ncol=nfact, free=PatFl, values=StFl, labels=LabFl, name=&quot;Loadings&quot; )
Id2     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=2, ncol=2, free=F, name=&quot;I2&quot; )
LoadTw  &lt;-mxAlgebra(I2%x%Loadings, name=&quot;FactLTw&quot;) #this will be a 2*nv x 2*nfact matrix,making it possible for both twins

#beta matrix to hold causal relationships
# Define the matrix to hold the Single headed Arrows (causal paths) between the 3 latent variables
# NB: direction of causation goes DOWN the column &amp; OUT along the row
PatPhC&lt;-c(F,T,T,
          F,F,T,
          F,F,F)
StPhC&lt;-c(0,0.05,0.05,
         0,0,0.05,
         0,0,0)
LabPhC&lt;-c(NA,&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;,
          NA,NA,&quot;X_to_Y&quot;,
          NA,NA,NA)
PhCaus  &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nfact, ncol=nfact, free=PatPhC, values=StPhC, labels=LabPhC, name=&quot;PhC&quot; )

### Build the ACE components
# Define the matrices to hold the A and C effects: Common (upper) 
LabAc&lt;-c(&quot;Ax&quot;,&quot;Axy&quot;,&quot;Ay&quot;)
freeA&lt;-c(T,T,T)
stA&lt;-c(0.5,0.5,0.5)

LabCc&lt;-c(&quot;Cx&quot;,&quot;Cxy&quot;,&quot;Cy&quot;)
freeC&lt;-c(T,F,F)
stC&lt;-c(0.5,0,0)

LabEc&lt;-c(&quot;Ex&quot;,&quot;Exy&quot;,&quot;Ey&quot;)
freeE&lt;-c(T,F,T)
stE&lt;-c(0.5,0,0.5)



PathsAc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeA, values=stA, labels=LabAc , name=&quot;ac&quot; )
PathsCc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeC, values=stC, labels=LabCc , name=&quot;cc&quot; )
PathsEc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeE, values=stE, labels=LabEc , name=&quot;ec&quot; )
covAc       &lt;-mxAlgebra( expression= ac %*% t(ac), name=&quot;Ac&quot; ) #cannot parse PGS variance into ACE
covCc       &lt;-mxAlgebra( expression= cc %*% t(cc), name=&quot;Cc&quot; ) #use these for standardisation.
covEc       &lt;-mxAlgebra( expression= ec %*% t(ec), name=&quot;Ec&quot; )
covPc       &lt;-mxAlgebra( expression= Ac+Cc+Ec, name=&quot;Vc&quot; ) #use a 2 x 2 matrix only. 


MZcovPc     &lt;-mxAlgebra( expression= Ac+Cc, name=&quot;MZVc&quot; )
DZcovPc     &lt;-mxAlgebra( expression= 0.5%x%Ac+Cc, name=&quot;DZVc&quot; )

#then specify var for PGS with a unit matrix (freely estimated)
PGSpath &lt;-mxMatrix(type=&quot;Full&quot;, nrow=1, ncol=1, free=T, values=0.5, labels=&quot;PGS_sd&quot; , name=&quot;PGSp&quot; )
PGSvar&lt;-mxAlgebra(expression=PGSp%*%t(PGSp),name=&quot;varPGS&quot;) #this will be the double headed arrow for variance of PGS

#zero matrices
zeromat&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=2,ncol=1,free=F,name=&quot;zero&quot;)
zeromat2&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=1,ncol=2,free=F,name=&quot;zero2&quot;)

totV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,Vc)),name=&quot;total_var&quot;)#if it complains, switch rbind and cbind.
#matrix above is a 3 x 3 matrix, within-twin matrix 
totMZV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,MZVc)),name=&quot;MZ_covar&quot;) #this is between person
totDZV&lt;-mxAlgebra(expression=cbind(rbind(0.5%x%varPGS,zero),rbind(zero2,DZVc)),name=&quot;DZ_covar&quot;)

# Generate Covariance of Latent factor model Including Causal Paths between factors
Id3     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=nfact, ncol=nfact, name=&quot;I3&quot; )

covFV   &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% total_var, name =&quot;FV&quot;) #(I3-PhC) gives the expression for the removal of the loop effect of causal relationships between the factors (1-4).
covMZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% MZ_covar, name =&quot;MZFV&quot;) 
covDZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% DZ_covar, name =&quot;DZFV&quot;) 

# Constraint on total variance of Ordinal variable (A+C+E=1)
varL        &lt;- mxConstraint( expression=FV[3,3]==1, name=&quot;L&quot; ) #total variablity after taking into account for causal effects

# Var-Cov of measured vars in terms of latent factors and AC, Cc, and Ec
#this results in a 6x6 matrix

covMZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, MZFV), cbind(MZFV, FV) )) , name=&quot;expCovMZ&quot; )#This traces the path from vars to factors and back to vars
covDZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, DZFV), cbind(DZFV, FV) )) , name=&quot;expCovDZ&quot; )


# Algebra to compute standardized variance components
#generate a 2x2 matrix which has taken into account for causal effects from FV:
Var2by2&lt;-mxAlgebra(expression=FV[2:3,2:3],name=&quot;FV2by2&quot;)
StA &lt;- mxAlgebra( expression=Ac/FV2by2, name=&quot;h2&quot;)
StC &lt;- mxAlgebra( expression=Cc/FV2by2, name=&quot;c2&quot;)
StE &lt;- mxAlgebra( expression=Ec/FV2by2, name=&quot;e2&quot;)

# # Algebra to compute Phenotypic, A, C &amp; E correlations for exposure and outcome
matI    &lt;- mxMatrix( type=&quot;Iden&quot;, nrow=nv-1, ncol=nv-1, name=&quot;I2&quot;)
rph &lt;- mxAlgebra( expression= solve(sqrt(I3*FV)) %*% FV %*% solve(sqrt(I3*FV)), name=&quot;Rph&quot;)#get overall Rph
rAc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ac)) %*% Ac %*% solve(sqrt(I2*Ac)), name=&quot;Rac&quot; )


# Algebra to get standardised b1, b2 and g1 paths:
beta1=mxAlgebra(expression= (PhC[2,1]*sqrt(FV[1,1]))/(sqrt(FV[2,2])), name=&quot;stB1&quot;)
beta2=mxAlgebra(expression= (PhC[3,2]*sqrt(FV[2,2]))/(sqrt(FV[3,3])), name=&quot;stG1&quot;)
pleio=mxAlgebra(expression= (PhC[3,1]*sqrt(FV[1,1]))/(sqrt(FV[3,3])), name=&quot;stB2&quot;)


#algebra to get RPh due to A,C,E and causal effects: 
RphACE&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                   #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                   #(sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), #this should be zero because re will be fixed to zero.
                                   stB2*stB1, stG1),name=&quot;ACErph&quot;)

# Data objects for Multiple Groups
dataMZ  &lt;- mxData( observed=mzdata, type=&quot;raw&quot; )
dataDZ  &lt;- mxData( observed=dzdata, type=&quot;raw&quot; )


# Objective objects for Multiple Groups
objMZ       &lt;- mxExpectationNormal( covariance=&quot;expCovMZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;NSSH1&quot;,&quot;NSSH2&quot;) )
objDZ       &lt;- mxExpectationNormal( covariance=&quot;expCovDZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;NSSH1&quot;,&quot;NSSH2&quot;) )

fitFunction &lt;- mxFitFunctionML()

# Combine Groups

pars&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
           covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
           StA,StC,StE,matI,rph,rAc,beta1,beta2,pleio,Var2by2,RphACE)

modelMZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ&quot; )
modelDZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ&quot; )


minus2ll    &lt;-mxAlgebra( expression=MZ.objective + DZ.objective, name=&quot;m2LL&quot; )
obj     &lt;-mxFitFunctionAlgebra( &quot;m2LL&quot; )

ACEModel    &lt;-mxModel(&quot;ACE&quot;, pars, modelMZ, modelDZ, minus2ll, obj)

#### run the ACE model which already has the parameters set or constrained: 
ACEFit      &lt;-mxTryHardOrdinal(ACEModel, intervals=F)
(ACESum &lt;- summary(ACEFit))
mxEval(MZ.ExpMean,ACEFit)

tableMZ&lt;-as.table(mxEval(MZ.expCovMZ,ACEFit))
colnames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;pCONN1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;pCONN2&quot;,&quot;NSSH2&quot;)
rownames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;pCONN1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;pCONN2&quot;,&quot;NSSH2&quot;)
round(tableMZ,3)

tableDZ&lt;-as.table(mxEval(DZ.expCovDZ,ACEFit))
colnames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;pCONN1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;pCONN2&quot;,&quot;NSSH2&quot;)
rownames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;pCONN1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;pCONN2&quot;,&quot;NSSH2&quot;)
round(tableDZ,3)

mxEval(MZ.stB1,ACEFit)

pathsCI1    &lt;-mxCI (c (&#39;MZ.stB1&#39;,&#39;MZ.stG1&#39;,&#39;MZ.stB2&#39;))
pathsCI2&lt;-mxCI(c(&#39;MZ.h2[1,1]&#39;,&#39;MZ.c2[1,1]&#39;,&#39;MZ.e2[1,1]&#39;,
                 &#39;MZ.h2[2,2]&#39;,&#39;MZ.e2[2,2]&#39;))
pathsCI3&lt;-mxCI(c(&#39;MZ.Rac[2,1]&#39;,&#39;MZ.Rph[3,2]&#39;,
                 &#39;MZ.ACErph[1,1]&#39;,&#39;MZ.ACErph[1,2]&#39;,&#39;MZ.ACErph[1,3]&#39;))

#CI1
ACEModel1&lt;-mxModel(ACEFit,pathsCI1)
ACEFit1&lt;-mxRun(ACEModel1,intervals=T)
(ACESum1    &lt;- summary(ACEFit1))

#CI2
ACEModel2&lt;-mxModel(ACEFit,pathsCI2)
ACEFit2&lt;-mxRun(ACEModel2,intervals=T)
(ACESum2    &lt;- summary(ACEFit2))

#CI3
ACEModel3&lt;-mxModel(ACEFit,pathsCI3)
ACEFit3&lt;-mxRun(ACEModel3,intervals=T)
(ACESum3    &lt;- summary(ACEFit3))


sum(mxEval(MZ.ACErph[1:3],ACEFit))

ACESum1$CI
ACESum2$CI
ACESum3$CI


##### create full bivariate model without direction of causation for comparison #####
## re = True, stb2= False
FullBiMod&lt;-mxModel(ACEFit,name=&quot;Full_Bi&quot;)
FullBiMod&lt;-omxSetParameters(FullBiMod, labels=c(&quot;Exy&quot;,&quot;X_to_Y&quot;), free=c(T,F),values=c(0.5,0))
FullBiFit&lt;-mxRun(FullBiMod, intervals=F)
(FullBiSum&lt;-summary(FullBiFit,verbose=T))
#check re
Ec&lt;-mxEval(MZ.Ec,FullBiFit)
Itwo&lt;-mxEval(MZ.I2,FullBiFit)
(Rec&lt;-solve(sqrt(Itwo*Ec)) %*% Ec %*% solve(sqrt(Itwo*Ec)))

#check b2 (the causal effect)
mxEval(MZ.stG1,FullBiFit)

#other values
mxEval(MZ.stB1,FullBiFit)
mxEval(MZ.stB2,FullBiFit)
mxEval(MZ.h2,FullBiFit);mxEval(MZ.c2,FullBiFit);mxEval(MZ.e2,FullBiFit)
mxEval(MZ.Rac,FullBiFit)
mxEval(MZ.Rph,FullBiFit)

#get Rcc
Cc&lt;-mxEval(MZ.Cc,FullBiFit)
(Rcc&lt;-solve(sqrt(Itwo*Cc)) %*% Cc %*% solve(sqrt(Itwo*Cc)))
# compare the two models
mxCompare(FullBiFit,ACEFit)

## now run model without effect of PRS only but still with stb2 and rc,re dropped ###
DoC_Mod&lt;-mxModel(ACEFit,name=&quot;DOC&quot;)
DoC_Mod&lt;-omxSetParameters(DoC_Mod, labels=c(&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;), free=c(F,F),values=c(0,0))
DoC_Fit&lt;-mxRun(DoC_Mod, intervals=F)
(DoCSum&lt;-summary(DoC_Fit,verbose=T))

#check PGS effect
mxEval(MZ.stB1,DoC_Fit);mxEval(MZ.stB2,DoC_Fit)
#values for the path diagram
mxEval(MZ.stG1,DoC_Fit)
mxEval(MZ.h2,DoC_Fit);mxEval(MZ.c2,DoC_Fit);mxEval(MZ.e2,DoC_Fit)
mxEval(MZ.Rac,DoC_Fit)
mxEval(MZ.Rph,DoC_Fit)
mxEval(MZ.expCovMZ,DoC_Fit);mxEval(DZ.expCovDZ,DoC_Fit)
#compare the models
mxCompare(ACEFit,DoC_Fit)


##### sensitivity analysis: what if rE is not zero, e.g. fixed to 0.20? #####
#add re into the model
rEc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ec)) %*% Ec %*% solve(sqrt(I2*Ec)), name=&quot;Rec&quot; )
RphACE2&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                    #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                    (sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), 
                                    stB2*stB1, stG1),name=&quot;ACErph2&quot;)
pars2&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
            covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
            StA,StC,StE,matI,rph,rAc,rEc,beta1,beta2,pleio,Var2by2,RphACE2)

modelMZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ2&quot; )
modelDZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ2&quot; )
minus2ll2   &lt;-mxAlgebra( expression=MZ2.objective + DZ2.objective, name=&quot;m2LL2&quot; )
obj2        &lt;-mxFitFunctionAlgebra( &quot;m2LL2&quot; )
rE_fixed_Model  &lt;-mxModel(&quot;rE_fixed&quot;, pars2, modelMZ2, modelDZ2, minus2ll2, obj2)
rE_fixed_Model &lt;-omxSetParameters(rE_fixed_Model, labels=c(&quot;Exy&quot;, &quot;X_to_Y&quot;), free=c(T,T),values=c(0.5,0.2))

pathsCI_rEfix   &lt;-mxCI (c (&#39;MZ2.stG1&#39;))
#re = 0.05
rE_fixed_Model005&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.05, name=&quot;con1&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit1       &lt;- mxTryHardOrdinal(rE_fixed_Model005, intervals = T)

(rE_Fixed_FitSumm1&lt;-summary(rE_Fixed_Fit1,verbose=T))
mxEval(MZ2.stb2,rE_Fixed_Fit1)
mxEval(MZ2.Rec,rE_Fixed_Fit1)

## re=0.10
rE_fixed_Model010&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed2&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.10, name=&quot;con2&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit2       &lt;- mxTryHardOrdinal(rE_fixed_Model010, intervals = T)

(rE_Fixed_FitSumm2&lt;-summary(rE_Fixed_Fit2,verbose=T))

## re=0.15
rE_fixed_Model015&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed3&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.15, name=&quot;con3&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit3       &lt;- mxTryHardOrdinal(rE_fixed_Model015, intervals = T)

(rE_Fixed_FitSumm3&lt;-summary(rE_Fixed_Fit3,verbose=T))

## re=0.20
rE_fixed_Model020&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed4&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.20, name=&quot;con4&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit4       &lt;- mxTryHardOrdinal(rE_fixed_Model020, intervals = T)

(rE_Fixed_FitSumm4&lt;-summary(rE_Fixed_Fit4,verbose=T))

## re=0.25
rE_fixed_Model025&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed5&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.25, name=&quot;con5&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit5       &lt;- mxTryHardOrdinal(rE_fixed_Model025, intervals = T,extraTries=20)

(rE_Fixed_FitSumm5&lt;-summary(rE_Fixed_Fit5,verbose=T))


rbind(mxCompare(ACEFit1,rE_Fixed_Fit1),
      mxCompare(ACEFit1,rE_Fixed_Fit2)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit3)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit4)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit5)[2,])

rbind(mxEval(MZ2.stG1,rE_Fixed_Fit1),
      mxEval(MZ2.stG1,rE_Fixed_Fit2),
      mxEval(MZ2.stG1,rE_Fixed_Fit3),
      mxEval(MZ2.stG1,rE_Fixed_Fit4),
      mxEval(MZ2.stG1,rE_Fixed_Fit5))


rbind(ACESum1$CI[2,],
      rE_Fixed_FitSumm1$CI,
      rE_Fixed_FitSumm2$CI,
      rE_Fixed_FitSumm3$CI,
      rE_Fixed_FitSumm4$CI,
      rE_Fixed_FitSumm5$CI)
## save the results as RData
save.image(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv5_pCONN_NSSH_20_April_2021.RData&quot;)
load(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv3_pCONN_NSSH_08_April_2021.RData&quot;)</code></pre>
</div>
<div id="pconn-ssh" class="section level3">
<h3>pCONN-SSH</h3>
<pre class="r"><code>#******************************************************

###### Regress out age, sex and transform pCONN variable #####

#residualise first, then tranform
merged_data$res_basic_pCONN1&lt;- residuals(lm(merged_data$ppbhconnt1
                                            ~merged_data$age_161 + merged_data$sex1,
                                            na.action=&quot;na.exclude&quot;))
merged_data$res_trans_order_pCONN1 &lt;-log(merged_data$res_basic_pCONN1+10)*2

#do same thing for twin 2. 
merged_data$res_basic_pCONN2&lt;- residuals(lm(merged_data$ppbhconnt2
                                            ~merged_data$age_162 + merged_data$sex2,
                                            na.action=&quot;na.exclude&quot;))

merged_data$res_trans_order_pCONN2 &lt;-log(merged_data$res_basic_pCONN2+10)*2
#***************************************************************************************
#################################### MR-DoC model ######################################
#***************************************************************************************

#variables I will need for this pCONN MR-DoC model:
vars        &lt;-c(&#39;ADHD_PRS&#39;,&#39;pCONN&#39;,&#39;SH&#39;)
selVars &lt;-c(&#39;ADHD100_res_t1&#39;, &#39;res_trans_order_pCONN1&#39;,&#39;SSH1&#39;,
            &#39;ADHD100_res_t2&#39;, &#39;res_trans_order_pCONN2&#39;,&#39;SSH2&#39;)

useVars &lt;-c(&#39;ADHD100_res_t1&#39;, &#39;res_trans_order_pCONN1&#39;,&#39;SSH1&#39;,
            &#39;ADHD100_res_t2&#39;, &#39;res_trans_order_pCONN2&#39;,&#39;SSH2&#39;,
            &#39;age1&#39;, &#39;age2&#39;, &#39;sex1&#39;,&#39;sex2&#39;) #age is for at age 21


#need to recode missing age into 999
table(is.na(merged_data$age1))
merged_data$SSH1[is.na(merged_data$age1)] &lt;- NA
merged_data$SSH2[is.na(merged_data$age2)] &lt;- NA
merged_data$age1[is.na(merged_data$age1)] &lt;- 999
merged_data$age2[is.na(merged_data$age2)] &lt;- 999
merged_data[1:20,1:8]

#mz and dzdata for using res_trans_order_cMFQ
mzdata&lt;-subset(merged_data, zygos%in%1&amp;random==1 , useVars)
dzdata&lt;-subset(merged_data, zygos%in%2&amp;random==1 , useVars)


head(mzdata)

#do ACE model #
nv          &lt;- 3                # number of variables for a twin = 1 in Univariate
nvo             &lt;- 1                #number of ordinal variables per twin
nvc             &lt;- nv-nvo           #number of continuous variables per twin
poso            &lt;- nvo          #position where ordinal variables start
ntv         &lt;- 2*nv         # number of variables for a pair = 2* 1 for Univariate
nth         &lt;- 4    # number of max thresholds
nfact       &lt;- 3                # number of Latent Factors 
ncor            &lt;- (nv*(nv+1)/2)-nv # number of free elements in a correlation matrix nv*nv
ninc            &lt;- nth-1            #number of max increments
ncovariates     &lt;- 2                #number of covariates


# Define definition variables to hold the Covariates

obsAge1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age1&quot;), name=&quot;Age1&quot;)
obsAge2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age2&quot;), name=&quot;Age2&quot;)
obsSex1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex1&quot;), name=&quot;Sex1&quot;)
obsSex2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex2&quot;), name=&quot;Sex2&quot;)

#effect of age and sex on ordinal variable
LabCovA &lt;-c(&#39;BageThSSH&#39;, &#39;BageThSSH&#39;,&#39;BageThSSH&#39;, &#39;BageThSSH&#39;)
LabCovS &lt;-c(&#39;BsexThSSH&#39;, &#39;BsexThSSH&#39;,&#39;BsexThSSH&#39;, &#39;BsexThSSH&#39;)

betaA       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovA, name=&quot;BageTH&quot; )
betaS       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovS, name=&quot;BsexTH&quot; )

#mean matrix, set NSSH to NA and fixed
StMZmean=c(colMeans(mzdata[,1:2],na.rm=TRUE),0)
Mean    &lt;-mxMatrix( &quot;Full&quot;, 1, ntv, free=c(T,T,F,T,T,F), values=StMZmean, labels=c(&quot;mPGS&quot;, &#39;mpCONN&#39;,NA, &quot;mPGS&quot;, &#39;mpCONN&#39;,NA), name=&quot;ExpMean&quot; )


#Threshold matrix
StTH        &lt;-c(-1,0.1,0.1,0.1)
LabTh   &lt;-c(&#39;Tmz_11&#39;,&#39;imz_11&#39;,&#39;imz_12&#39;,&#39;imz_13&#39;)
Tr      &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=StTH, lbound=c(-4,0.001,0.001,0.001), ubound=c(4,4),
                labels=LabTh, name=&quot;Th&quot;)

inc     &lt;-mxMatrix( type=&quot;Lower&quot;,nrow=nth, ncol=nth, free=F, values=1, name=&quot;Low&quot;)

Thres   &lt;-mxAlgebra( expression= cbind(Low%*%Th + BageTH%x%Age1 + BsexTH%x%Sex1,
                                     Low%*%Th + BageTH%x%Age2 + BsexTH%x%Sex2),
                   name=&quot;ExpThres&quot;)

#Matrix that holds loadings from observed to latent variables
PatFl   &lt;- c(F,F,F,
           F,F,F,
           F,F,F) # Fix observed to latent to be 1 for all variables
StFl        &lt;- c(1,0,0,
           0,1,0,
           0,0,1)
LabFl   &lt;- c(&#39;PGS&#39;,NA,NA,
           NA,&#39;X&#39;,NA,
           NA, NA,&#39;Y&#39;)
Load        &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nv, ncol=nfact, free=PatFl, values=StFl, labels=LabFl, name=&quot;Loadings&quot; )
Id2     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=2, ncol=2, free=F, name=&quot;I2&quot; ) 
LoadTw  &lt;-mxAlgebra(I2%x%Loadings, name=&quot;FactLTw&quot;) #this will be a 2*nv x 2*nfact matrix,making it possible for both twins

#beta matrix to hold causal relationships
# Define the matrix to hold the Single headed Arrows (causal paths) between the 3 latent variables
# NB: direction of causation goes DOWN the column &amp; OUT along the row
PatPhC&lt;-c(F,T,T,
          F,F,T,
          F,F,F)
StPhC&lt;-c(0,0.05,0.05,
         0,0,0.05,
         0,0,0)
LabPhC&lt;-c(NA,&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;,
          NA,NA,&quot;X_to_Y&quot;,
          NA,NA,NA)
PhCaus  &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nfact, ncol=nfact, free=PatPhC, values=StPhC, labels=LabPhC, name=&quot;PhC&quot; )

### Build the ACE components
# Define the matrices to hold the A and C effects: Common (upper) 
LabAc&lt;-c(&quot;Ax&quot;,&quot;Axy&quot;,&quot;Ay&quot;)
freeA&lt;-c(T,T,T)
stA&lt;-c(0.5,0.5,0.5)

LabCc&lt;-c(&quot;Cx&quot;,&quot;Cxy&quot;,&quot;Cy&quot;)
freeC&lt;-c(T,F,F)
stC&lt;-c(0.5,0,0)

LabEc&lt;-c(&quot;Ex&quot;,&quot;Exy&quot;,&quot;Ey&quot;)
freeE&lt;-c(T,F,T)
stE&lt;-c(0.5,0,0.5)



PathsAc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeA, values=stA, labels=LabAc , name=&quot;ac&quot; )
PathsCc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeC, values=stC, labels=LabCc , name=&quot;cc&quot; )
PathsEc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeE, values=stE, labels=LabEc , name=&quot;ec&quot; )
covAc       &lt;-mxAlgebra( expression= ac %*% t(ac), name=&quot;Ac&quot; ) #cannot parse PGS variance into ACE
covCc       &lt;-mxAlgebra( expression= cc %*% t(cc), name=&quot;Cc&quot; ) #use these for standardisation.
covEc       &lt;-mxAlgebra( expression= ec %*% t(ec), name=&quot;Ec&quot; )
covPc       &lt;-mxAlgebra( expression= Ac+Cc+Ec, name=&quot;Vc&quot; ) #use a 2 x 2 matrix only. 
MZcovPc     &lt;-mxAlgebra( expression= Ac+Cc, name=&quot;MZVc&quot; )
DZcovPc     &lt;-mxAlgebra( expression= 0.5%x%Ac+Cc, name=&quot;DZVc&quot; )

#then specify var for PGS with a unit matrix (freely estimated)
PGSpath &lt;-mxMatrix(type=&quot;Full&quot;, nrow=1, ncol=1, free=T, values=0.5, labels=&quot;PGS_sd&quot; , name=&quot;PGSp&quot; )
PGSvar&lt;-mxAlgebra(expression=PGSp%*%t(PGSp),name=&quot;varPGS&quot;) #this will be the double headed arrow for variance of PGS

#zero matrices
zeromat&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=2,ncol=1,free=F,name=&quot;zero&quot;)
zeromat2&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=1,ncol=2,free=F,name=&quot;zero2&quot;)

totV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,Vc)),name=&quot;total_var&quot;)#if it complains, switch rbind and cbind.
#matrix above is a 3 x 3 matrix, within-twin matrix 
totMZV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,MZVc)),name=&quot;MZ_covar&quot;) #this is between person
totDZV&lt;-mxAlgebra(expression=cbind(rbind(0.5%x%varPGS,zero),rbind(zero2,DZVc)),name=&quot;DZ_covar&quot;)

# Generate Covariance of Latent factor model Including Causal Paths between factors
Id3     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=nfact, ncol=nfact, name=&quot;I3&quot; )

covFV   &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% total_var, name =&quot;FV&quot;)
covMZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% MZ_covar, name =&quot;MZFV&quot;) 
covDZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% DZ_covar, name =&quot;DZFV&quot;) 


# Constraint on total variance of Ordinal variable (A+C+E=1)
varL        &lt;- mxConstraint( expression=FV[3,3]==1, name=&quot;L&quot; ) #total variablity after taking into account for causal effects

# Var-Cov of measured vars in terms of latent factors and AC, Cc, and Ec
#this results in a 6x6 matrix

covMZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, MZFV), cbind(MZFV, FV) )) , name=&quot;expCovMZ&quot; )#This traces the path from vars to factors and back to vars
covDZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, DZFV), cbind(DZFV, FV) )) , name=&quot;expCovDZ&quot; )


# Algebra to compute standardized variance components
#generate a 2x2 matrix which has taken into account for causal effects from FV:
Var2by2&lt;-mxAlgebra(expression=FV[2:3,2:3],name=&quot;FV2by2&quot;)
StA &lt;- mxAlgebra( expression=Ac/FV2by2, name=&quot;h2&quot;)
StC &lt;- mxAlgebra( expression=Cc/FV2by2, name=&quot;c2&quot;)
StE &lt;- mxAlgebra( expression=Ec/FV2by2, name=&quot;e2&quot;)

# # Algebra to compute Phenotypic, A, C &amp; E correlations for exposure and outcome
matI    &lt;- mxMatrix( type=&quot;Iden&quot;, nrow=nv-1, ncol=nv-1, name=&quot;I2&quot;)
rph &lt;- mxAlgebra( expression= solve(sqrt(I3*FV)) %*% FV %*% solve(sqrt(I3*FV)), name=&quot;Rph&quot;)#get overall Rph
rAc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ac)) %*% Ac %*% solve(sqrt(I2*Ac)), name=&quot;Rac&quot; )


# Algebra to get standardised b1, b2 and g1 paths:
beta1=mxAlgebra(expression= (PhC[2,1]*sqrt(FV[1,1]))/(sqrt(FV[2,2])), name=&quot;stB1&quot;)
beta2=mxAlgebra(expression= (PhC[3,2]*sqrt(FV[2,2]))/(sqrt(FV[3,3])), name=&quot;stG1&quot;)
pleio=mxAlgebra(expression= (PhC[3,1]*sqrt(FV[1,1]))/(sqrt(FV[3,3])), name=&quot;stB2&quot;)


#algebra to get RPh due to A,C,E and causal effects: 
RphACE&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                   #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                   #(sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), #this should be zero because re will be fixed to zero.
                                   stB2*stB1, stG1),name=&quot;ACErph&quot;)

# Data objects for Multiple Groups
dataMZ  &lt;- mxData( observed=mzdata, type=&quot;raw&quot; )
dataDZ  &lt;- mxData( observed=dzdata, type=&quot;raw&quot; )


# Objective objects for Multiple Groups
objMZ       &lt;- mxExpectationNormal( covariance=&quot;expCovMZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;SSH1&quot;,&quot;SSH2&quot;) )
objDZ       &lt;- mxExpectationNormal( covariance=&quot;expCovDZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;SSH1&quot;,&quot;SSH2&quot;) )

fitFunction &lt;- mxFitFunctionML()


# Combine Groups

pars&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
           covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
           StA,StC,StE,matI,rph,rAc,beta1,beta2,pleio,Var2by2,RphACE)

modelMZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ&quot; )
modelDZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ&quot; )


minus2ll    &lt;-mxAlgebra( expression=MZ.objective + DZ.objective, name=&quot;m2LL&quot; )
obj     &lt;-mxFitFunctionAlgebra( &quot;m2LL&quot; )

ACEModel    &lt;-mxModel(&quot;ACE&quot;, pars, modelMZ, modelDZ, minus2ll, obj)

#### run the ACE model which already has the parameters set or constrained: 
ACEFit      &lt;-mxTryHardOrdinal(ACEModel, intervals=F)
(ACESum &lt;- summary(ACEFit))
mxEval(MZ.ExpMean,ACEFit)

tableMZ&lt;-as.table(mxEval(MZ.expCovMZ,ACEFit))
colnames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;pCONN1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;pCONN2&quot;,&quot;SSH2&quot;)
rownames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;pCONN1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;pCONN2&quot;,&quot;SSH2&quot;)
round(tableMZ,3)

tableDZ&lt;-as.table(mxEval(DZ.expCovDZ,ACEFit))
colnames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;pCONN1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;pCONN2&quot;,&quot;SSH2&quot;)
rownames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;pCONN1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;pCONN2&quot;,&quot;SSH2&quot;)
round(tableDZ,3)

mxEval(MZ.stB1,ACEFit)

pathsCI1    &lt;-mxCI (c (&#39;MZ.stB1&#39;,&#39;MZ.stG1&#39;,&#39;MZ.stB2&#39;))
pathsCI2&lt;-mxCI(c(&#39;MZ.h2[1,1]&#39;,&#39;MZ.c2[1,1]&#39;,&#39;MZ.e2[1,1]&#39;,
                 &#39;MZ.h2[2,2]&#39;,&#39;MZ.e2[2,2]&#39;))
pathsCI3&lt;-mxCI(c(&#39;MZ.Rac[2,1]&#39;,&#39;MZ.Rph[3,2]&#39;,
                 &#39;MZ.ACErph[1,1]&#39;,&#39;MZ.ACErph[1,2]&#39;,&#39;MZ.ACErph[1,3]&#39;))

#CI1
ACEModel1&lt;-mxModel(ACEFit,pathsCI1)
ACEFit1&lt;-mxRun(ACEModel1,intervals=T)
(ACESum1    &lt;- summary(ACEFit1))

#CI2
ACEModel2&lt;-mxModel(ACEFit,pathsCI2)
ACEFit2&lt;-mxRun(ACEModel2,intervals=T)
(ACESum2    &lt;- summary(ACEFit2))

#CI3
ACEModel3&lt;-mxModel(ACEFit,pathsCI3)
ACEFit3&lt;-mxRun(ACEModel3,intervals=T)
(ACESum3    &lt;- summary(ACEFit3))


sum(mxEval(MZ.ACErph[1:3],ACEFit))

ACESum1$CI
ACESum2$CI
ACESum3$CI


##### create full bivariate model without direction of causation for comparison #####
## re = True, stb2= False
FullBiMod&lt;-mxModel(ACEFit,name=&quot;Full_Bi&quot;)
FullBiMod&lt;-omxSetParameters(FullBiMod, labels=c(&quot;Exy&quot;,&quot;X_to_Y&quot;), free=c(T,F),values=c(0.5,0))
FullBiFit&lt;-mxRun(FullBiMod, intervals=F)
(FullBiSum&lt;-summary(FullBiFit,verbose=T))
#check re
Ec&lt;-mxEval(MZ.Ec,FullBiFit)
Itwo&lt;-mxEval(MZ.I2,FullBiFit)
(Rec&lt;-solve(sqrt(Itwo*Ec)) %*% Ec %*% solve(sqrt(Itwo*Ec)))

#check G1 (the causal effect)
mxEval(MZ.stG1,FullBiFit)

#other values
mxEval(MZ.stB1,FullBiFit)
mxEval(MZ.stB2,FullBiFit)
mxEval(MZ.h2,FullBiFit);mxEval(MZ.c2,FullBiFit);mxEval(MZ.e2,FullBiFit)
mxEval(MZ.Rac,FullBiFit)
mxEval(MZ.Rph,FullBiFit)

#get Rcc
Cc&lt;-mxEval(MZ.Cc,FullBiFit)
(Rcc&lt;-solve(sqrt(Itwo*Cc)) %*% Cc %*% solve(sqrt(Itwo*Cc)))
# compare the two models
mxCompare(FullBiFit,ACEFit)

## now run model without effect of PRS only but still with stb2 and rc,re dropped ###
DoC_Mod&lt;-mxModel(ACEFit,name=&quot;DOC&quot;)
DoC_Mod&lt;-omxSetParameters(DoC_Mod, labels=c(&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;), free=c(F,F),values=c(0,0))
DoC_Fit&lt;-mxRun(DoC_Mod, intervals=F)
(DoCSum&lt;-summary(DoC_Fit,verbose=T))

#check PGS effect
mxEval(MZ.stB1,DoC_Fit);mxEval(MZ.stB2,DoC_Fit)
#values for the path diagram
mxEval(MZ.stG1,DoC_Fit)
mxEval(MZ.h2,DoC_Fit);mxEval(MZ.c2,DoC_Fit);mxEval(MZ.e2,DoC_Fit)
mxEval(MZ.Rac,DoC_Fit)
mxEval(MZ.Rph,DoC_Fit)
mxEval(MZ.expCovMZ,DoC_Fit);mxEval(DZ.expCovDZ,DoC_Fit)
#compare the models
mxCompare(ACEFit,DoC_Fit)

##### sensitivity analysis: what if rE is not zero, e.g. fixed to 0.20? #####
#add re into the model
##### sensitivity analysis: what if rE is not zero, e.g. fixed to 0.20? #####
#add re into the model
rEc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ec)) %*% Ec %*% solve(sqrt(I2*Ec)), name=&quot;Rec&quot; )
RphACE2&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                    #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                    (sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), 
                                    stB2*stB1, stb2),name=&quot;ACErph2&quot;)
pars2&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
            covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
            StA,StC,StE,matI,rph,rAc,rEc,beta1,beta2,pleio,Var2by2,RphACE2)

modelMZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ2&quot; )
modelDZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ2&quot; )
minus2ll2   &lt;-mxAlgebra( expression=MZ2.objective + DZ2.objective, name=&quot;m2LL2&quot; )
obj2        &lt;-mxFitFunctionAlgebra( &quot;m2LL2&quot; )
rE_fixed_Model  &lt;-mxModel(&quot;rE_fixed&quot;, pars2, modelMZ2, modelDZ2, minus2ll2, obj2)
rE_fixed_Model &lt;-omxSetParameters(rE_fixed_Model, labels=c(&quot;Exy&quot;, &quot;X_to_Y&quot;), free=c(T,T),values=c(0.5,0.2))

pathsCI_rEfix   &lt;-mxCI (c (&#39;MZ2.stb2&#39;))
#re = 0.05
rE_fixed_Model005&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.05, name=&quot;con1&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit1       &lt;- mxTryHardOrdinal(rE_fixed_Model005, intervals = T)

(rE_Fixed_FitSumm1&lt;-summary(rE_Fixed_Fit1,verbose=T))
mxEval(MZ2.stG1,rE_Fixed_Fit1)
mxEval(MZ2.Rec,rE_Fixed_Fit1)

## re=0.10
rE_fixed_Model010&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed2&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.10, name=&quot;con2&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit2       &lt;- mxTryHardOrdinal(rE_fixed_Model010, intervals = T)

(rE_Fixed_FitSumm2&lt;-summary(rE_Fixed_Fit2,verbose=T))

## re=0.15
rE_fixed_Model015&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed3&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.15, name=&quot;con3&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit3       &lt;- mxTryHardOrdinal(rE_fixed_Model015, intervals = T)

(rE_Fixed_FitSumm3&lt;-summary(rE_Fixed_Fit3,verbose=T))

## re=0.20
rE_fixed_Model020&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed4&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.20, name=&quot;con4&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit4       &lt;- mxTryHardOrdinal(rE_fixed_Model020, intervals = T)

(rE_Fixed_FitSumm4&lt;-summary(rE_Fixed_Fit4,verbose=T))

## re=0.25
rE_fixed_Model025&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed5&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.25, name=&quot;con5&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit5       &lt;- mxTryHardOrdinal(rE_fixed_Model025, intervals = T)

(rE_Fixed_FitSumm5&lt;-summary(rE_Fixed_Fit5,verbose=T))


rbind(mxCompare(ACEFit1,rE_Fixed_Fit1),
      mxCompare(ACEFit1,rE_Fixed_Fit2)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit3)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit4)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit5)[2,])

rbind(mxEval(MZ2.stG1,rE_Fixed_Fit1),
      mxEval(MZ2.stG1,rE_Fixed_Fit2),
      mxEval(MZ2.stG1,rE_Fixed_Fit3),
      mxEval(MZ2.stG1,rE_Fixed_Fit4),
      mxEval(MZ2.stG1,rE_Fixed_Fit5))


rbind(ACESum1$CI[2,],
      rE_Fixed_FitSumm1$CI,
      rE_Fixed_FitSumm2$CI,
      rE_Fixed_FitSumm3$CI,
      rE_Fixed_FitSumm4$CI,
      rE_Fixed_FitSumm5$CI)
## save the results as RData
save.image(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv5_pCONN_SSH_20_April_2021.RData&quot;)
load(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv5_pCONN_SSH_20_April_2021.RData&quot;)</code></pre>
</div>
<div id="pmfq-nssh" class="section level3">
<h3>pMFQ-NSSH</h3>
<pre class="r"><code>#******************************************************
#residualise first, then tranform
merged_data$res_basic_pMFQ1&lt;- residuals(lm(merged_data$ppbhmfqt1
                                           ~merged_data$age_161 + merged_data$sex1,
                                           na.action=&quot;na.exclude&quot;))
merged_data$res_trans_order_pMFQ1 &lt;-log(merged_data$res_basic_pMFQ1+1.5)*3

#do same thing for twin 2. 
merged_data$res_basic_pMFQ2&lt;- residuals(lm(merged_data$ppbhmfqt2
                                           ~merged_data$age_162 + merged_data$sex2,
                                           na.action=&quot;na.exclude&quot;))

merged_data$res_trans_order_pMFQ2 &lt;-log(merged_data$res_basic_pMFQ2+1.5)*3

#***************************************************************************************
#################################### MR-DoC model ######################################
#***************************************************************************************

#variables I will need for this pMFQ MR-DoC model:
vars        &lt;-c(&#39;MDD_PRS&#39;,&#39;pMFQ&#39;,&#39;SH&#39;)
selVars &lt;-c(&#39;MDD100_res_t1&#39;, &#39;res_trans_order_pMFQ1&#39;,&#39;NSSH1&#39;,
            &#39;MDD100_res_t2&#39;, &#39;res_trans_order_pMFQ2&#39;,&#39;NSSH2&#39;)

useVars &lt;-c(&#39;MDD100_res_t1&#39;, &#39;res_trans_order_pMFQ1&#39;,&#39;NSSH1&#39;,
            &#39;MDD100_res_t2&#39;, &#39;res_trans_order_pMFQ2&#39;,&#39;NSSH2&#39;,
            &#39;age1&#39;, &#39;age2&#39;, &#39;sex1&#39;,&#39;sex2&#39;) #age is for at age 21


#need to recode missing age into 999
table(is.na(merged_data$age1))
merged_data$NSSH1[is.na(merged_data$age1)] &lt;- NA
merged_data$NSSH2[is.na(merged_data$age2)] &lt;- NA
merged_data$age1[is.na(merged_data$age1)] &lt;- 999
merged_data$age2[is.na(merged_data$age2)] &lt;- 999
merged_data[1:20,1:8]

#mz and dzdata for using res_trans_order_cMFQ
mzdata&lt;-subset(merged_data, zygos%in%1&amp;random==1 , useVars)
dzdata&lt;-subset(merged_data, zygos%in%2&amp;random==1 , useVars)


head(mzdata)

#do ACE model #
nv          &lt;- 3                # number of variables for a twin = 1 in Univariate
nvo             &lt;- 1                #number of ordinal variables per twin
nvc             &lt;- nv-nvo           #number of continuous variables per twin
poso            &lt;- nvo          #position where ordinal variables start
ntv         &lt;- 2*nv         # number of variables for a pair = 2* 1 for Univariate
nth         &lt;- 4    # number of max thresholds
nfact       &lt;- 3                # number of Latent Factors 
ncor            &lt;- (nv*(nv+1)/2)-nv # number of free elements in a correlation matrix nv*nv
ninc            &lt;- nth-1            #number of max increments
ncovariates     &lt;- 2                #number of covariates


# Define definition variables to hold the Covariates

obsAge1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age1&quot;), name=&quot;Age1&quot;)
obsAge2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age2&quot;), name=&quot;Age2&quot;)
obsSex1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex1&quot;), name=&quot;Sex1&quot;)
obsSex2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex2&quot;), name=&quot;Sex2&quot;)

#effect of age and sex on ordinal variable
LabCovA &lt;-c(&#39;BageThNSSH&#39;, &#39;BageThNSSH&#39;,&#39;BageThNSSH&#39;, &#39;BageThNSSH&#39;)
LabCovS &lt;-c(&#39;BsexThNSSH&#39;, &#39;BsexThNSSH&#39;,&#39;BsexThNSSH&#39;, &#39;BsexThNSSH&#39;)

betaA       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovA, name=&quot;BageTH&quot; )
betaS       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovS, name=&quot;BsexTH&quot; )

#mean matrix, set NSSH to NA and fixed
StMZmean=c(colMeans(mzdata[,1:2],na.rm=TRUE),0)
Mean    &lt;-mxMatrix( &quot;Full&quot;, 1, ntv, free=c(T,T,F,T,T,F), values=StMZmean, labels=c(&quot;mPGS&quot;, &#39;mpMFQ&#39;,NA, &quot;mPGS&quot;, &#39;mpMFQ&#39;,NA), name=&quot;ExpMean&quot; )


#Threshold matrix
StTH        &lt;-c(-1,0.1,0.1,0.1)
LabTh   &lt;-c(&#39;Tmz_11&#39;,&#39;imz_11&#39;,&#39;imz_12&#39;,&#39;imz_13&#39;)
Tr      &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=StTH, lbound=c(-4,0.001,0.001,0.001), ubound=c(4,4),
                labels=LabTh, name=&quot;Th&quot;)

inc     &lt;-mxMatrix( type=&quot;Lower&quot;,nrow=nth, ncol=nth, free=F, values=1, name=&quot;Low&quot;)

Thres   &lt;-mxAlgebra( expression= cbind(Low%*%Th + BageTH%x%Age1 + BsexTH%x%Sex1,
                                     Low%*%Th + BageTH%x%Age2 + BsexTH%x%Sex2),
                   name=&quot;ExpThres&quot;)

#Matrix that holds loadings from observed to latent variables
PatFl   &lt;- c(F,F,F,
           F,F,F,
           F,F,F) # Fix observed to latent to be 1 for all variables
StFl        &lt;- c(1,0,0,
           0,1,0,
           0,0,1)
LabFl   &lt;- c(&#39;PGS&#39;,NA,NA,
           NA,&#39;X&#39;,NA,
           NA, NA,&#39;Y&#39;)
Load        &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nv, ncol=nfact, free=PatFl, values=StFl, labels=LabFl, name=&quot;Loadings&quot; )
Id2     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=2, ncol=2, free=F, name=&quot;I2&quot; ) 
LoadTw  &lt;-mxAlgebra(I2%x%Loadings, name=&quot;FactLTw&quot;) #this will be a 2*nv x 2*nfact matrix,making it possible for both twins

#beta matrix to hold causal relationships
# Define the matrix to hold the Single headed Arrows (causal paths) between the 3 latent variables
# NB: direction of causation goes DOWN the column &amp; OUT along the row
PatPhC&lt;-c(F,T,T,
          F,F,T,
          F,F,F)
StPhC&lt;-c(0,0.05,0.05,
         0,0,0.05,
         0,0,0)
LabPhC&lt;-c(NA,&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;,
          NA,NA,&quot;X_to_Y&quot;,
          NA,NA,NA)
PhCaus  &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nfact, ncol=nfact, free=PatPhC, values=StPhC, labels=LabPhC, name=&quot;PhC&quot; )

### Build the ACE components
# Define the matrices to hold the A and C effects: Common (upper) 
LabAc&lt;-c(&quot;Ax&quot;,&quot;Axy&quot;,&quot;Ay&quot;)
freeA&lt;-c(T,T,T)
stA&lt;-c(0.5,0.5,0.5)

LabCc&lt;-c(&quot;Cx&quot;,&quot;Cxy&quot;,&quot;Cy&quot;)
freeC&lt;-c(T,F,F)
stC&lt;-c(0.5,0,0)

LabEc&lt;-c(&quot;Ex&quot;,&quot;Exy&quot;,&quot;Ey&quot;)
freeE&lt;-c(T,F,T)
stE&lt;-c(0.5,0,0.5)



PathsAc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeA, values=stA, labels=LabAc , name=&quot;ac&quot; )
PathsCc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeC, values=stC, labels=LabCc , name=&quot;cc&quot; )
PathsEc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeE, values=stE, labels=LabEc , name=&quot;ec&quot; )
covAc       &lt;-mxAlgebra( expression= ac %*% t(ac), name=&quot;Ac&quot; ) #cannot parse PGS variance into ACE
covCc       &lt;-mxAlgebra( expression= cc %*% t(cc), name=&quot;Cc&quot; ) #use these for standardisation.
covEc       &lt;-mxAlgebra( expression= ec %*% t(ec), name=&quot;Ec&quot; )
covPc       &lt;-mxAlgebra( expression= Ac+Cc+Ec, name=&quot;Vc&quot; ) #use a 2 x 2 matrix only. 
MZcovPc     &lt;-mxAlgebra( expression= Ac+Cc, name=&quot;MZVc&quot; )
DZcovPc     &lt;-mxAlgebra( expression= 0.5%x%Ac+Cc, name=&quot;DZVc&quot; )

#then specify var for PGS with a unit matrix (freely estimated)
PGSpath &lt;-mxMatrix(type=&quot;Full&quot;, nrow=1, ncol=1, free=T, values=0.5, labels=&quot;PGS_sd&quot; , name=&quot;PGSp&quot; )
PGSvar&lt;-mxAlgebra(expression=PGSp%*%t(PGSp),name=&quot;varPGS&quot;) #this will be the double headed arrow for variance of PGS

#zero matrices
zeromat&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=2,ncol=1,free=F,name=&quot;zero&quot;)
zeromat2&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=1,ncol=2,free=F,name=&quot;zero2&quot;)

totV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,Vc)),name=&quot;total_var&quot;)#if it complains, switch rbind and cbind.
#matrix above is a 3 x 3 matrix, within-twin matrix 
totMZV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,MZVc)),name=&quot;MZ_covar&quot;) #this is between person
totDZV&lt;-mxAlgebra(expression=cbind(rbind(0.5%x%varPGS,zero),rbind(zero2,DZVc)),name=&quot;DZ_covar&quot;)

# Generate Covariance of Latent factor model Including Causal Paths between factors
Id3     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=nfact, ncol=nfact, name=&quot;I3&quot; )

covFV   &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% total_var, name =&quot;FV&quot;)
covMZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% MZ_covar, name =&quot;MZFV&quot;) 
covDZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% DZ_covar, name =&quot;DZFV&quot;) 

# Constraint on total variance of Ordinal variable (A+C+E=1)
varL        &lt;- mxConstraint( expression=FV[3,3]==1, name=&quot;L&quot; ) #total variablity after taking into account for causal effects

# Var-Cov of measured vars in terms of latent factors and AC, Cc, and Ec
#this results in a 6x6 matrix

covMZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, MZFV), cbind(MZFV, FV) )) , name=&quot;expCovMZ&quot; )#This traces the path from vars to factors and back to vars
covDZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, DZFV), cbind(DZFV, FV) )) , name=&quot;expCovDZ&quot; )


# Algebra to compute standardized variance components
#generate a 2x2 matrix which has taken into account for causal effects from FV:
Var2by2&lt;-mxAlgebra(expression=FV[2:3,2:3],name=&quot;FV2by2&quot;)
StA &lt;- mxAlgebra( expression=Ac/FV2by2, name=&quot;h2&quot;)
StC &lt;- mxAlgebra( expression=Cc/FV2by2, name=&quot;c2&quot;)
StE &lt;- mxAlgebra( expression=Ec/FV2by2, name=&quot;e2&quot;)

# # Algebra to compute Phenotypic, A, C &amp; E correlations for exposure and outcome
matI    &lt;- mxMatrix( type=&quot;Iden&quot;, nrow=nv-1, ncol=nv-1, name=&quot;I2&quot;)
rph &lt;- mxAlgebra( expression= solve(sqrt(I3*FV)) %*% FV %*% solve(sqrt(I3*FV)), name=&quot;Rph&quot;)#get overall Rph
rAc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ac)) %*% Ac %*% solve(sqrt(I2*Ac)), name=&quot;Rac&quot; )


# Algebra to get standardised b1, b2 and g1 paths:
beta1=mxAlgebra(expression= (PhC[2,1]*sqrt(FV[1,1]))/(sqrt(FV[2,2])), name=&quot;stB1&quot;)
beta2=mxAlgebra(expression= (PhC[3,2]*sqrt(FV[2,2]))/(sqrt(FV[3,3])), name=&quot;stG1&quot;)
pleio=mxAlgebra(expression= (PhC[3,1]*sqrt(FV[1,1]))/(sqrt(FV[3,3])), name=&quot;stB2&quot;)


#algebra to get RPh due to A,C,E and causal effects: 
RphACE&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                   #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                   #(sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), #this should be zero because re will be fixed to zero.
                                   stB2*stB1, stG1),name=&quot;ACErph&quot;)

# Data objects for Multiple Groups
dataMZ  &lt;- mxData( observed=mzdata, type=&quot;raw&quot; )
dataDZ  &lt;- mxData( observed=dzdata, type=&quot;raw&quot; )


# Objective objects for Multiple Groups
objMZ       &lt;- mxExpectationNormal( covariance=&quot;expCovMZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;NSSH1&quot;,&quot;NSSH2&quot;) )
objDZ       &lt;- mxExpectationNormal( covariance=&quot;expCovDZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;NSSH1&quot;,&quot;NSSH2&quot;) )

fitFunction &lt;- mxFitFunctionML()

# Combine Groups

pars&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
           covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
           StA,StC,StE,matI,rph,rAc,beta1,beta2,pleio,Var2by2,RphACE)

modelMZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ&quot; )
modelDZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ&quot; )


minus2ll    &lt;-mxAlgebra( expression=MZ.objective + DZ.objective, name=&quot;m2LL&quot; )
obj     &lt;-mxFitFunctionAlgebra( &quot;m2LL&quot; )

ACEModel    &lt;-mxModel(&quot;ACE&quot;, pars, modelMZ, modelDZ, minus2ll, obj)

#### run the ACE model which already has the parameters set or constrained: 
ACEFit      &lt;-mxTryHardOrdinal(ACEModel, intervals=F)
(ACESum &lt;- summary(ACEFit))
mxEval(MZ.ExpMean,ACEFit)

tableMZ&lt;-as.table(mxEval(MZ.expCovMZ,ACEFit))
colnames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;pMFQ1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;pMFQ2&quot;,&quot;NSSH2&quot;)
rownames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;pMFQ1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;pMFQ2&quot;,&quot;NSSH2&quot;)
round(tableMZ,3)

tableDZ&lt;-as.table(mxEval(DZ.expCovDZ,ACEFit))
colnames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;pMFQ1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;pMFQ2&quot;,&quot;NSSH2&quot;)
rownames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;pMFQ1&quot;,&quot;NSSH1&quot;,&quot;PGS2&quot;,&quot;pMFQ2&quot;,&quot;NSSH2&quot;)
round(tableDZ,3)

mxEval(MZ.stB1,ACEFit)

pathsCI1    &lt;-mxCI (c (&#39;MZ.stB1&#39;,&#39;MZ.stG1&#39;,&#39;MZ.stB2&#39;))
pathsCI2&lt;-mxCI(c(&#39;MZ.h2[1,1]&#39;,&#39;MZ.c2[1,1]&#39;,&#39;MZ.e2[1,1]&#39;,
                 &#39;MZ.h2[2,2]&#39;,&#39;MZ.e2[2,2]&#39;))
pathsCI3&lt;-mxCI(c(&#39;MZ.Rac[2,1]&#39;,&#39;MZ.Rph[3,2]&#39;,
                 &#39;MZ.ACErph[1,1]&#39;,&#39;MZ.ACErph[1,2]&#39;,&#39;MZ.ACErph[1,3]&#39;))

#CI1
ACEModel1&lt;-mxModel(ACEFit,pathsCI1)
ACEFit1&lt;-mxRun(ACEModel1,intervals=T)
(ACESum1    &lt;- summary(ACEFit1))

#CI2
ACEModel2&lt;-mxModel(ACEFit,pathsCI2)
ACEFit2&lt;-mxRun(ACEModel2,intervals=T)
(ACESum2    &lt;- summary(ACEFit2))

#CI3
ACEModel3&lt;-mxModel(ACEFit,pathsCI3)
ACEFit3&lt;-mxRun(ACEModel3,intervals=T)
(ACESum3    &lt;- summary(ACEFit3))


sum(mxEval(MZ.ACErph[1:3],ACEFit))

ACESum1$CI
ACESum2$CI
ACESum3$CI


##### create full bivariate model without direction of causation for comparison #####
## re = True, stG1= False
FullBiMod&lt;-mxModel(ACEFit,name=&quot;Full_Bi&quot;)
FullBiMod&lt;-omxSetParameters(FullBiMod, labels=c(&quot;Exy&quot;,&quot;X_to_Y&quot;), free=c(T,F),values=c(0.5,0))
FullBiFit&lt;-mxRun(FullBiMod, intervals=F)
(FullBiSum&lt;-summary(FullBiFit,verbose=T))
#check re
Ec&lt;-mxEval(MZ.Ec,FullBiFit)
Itwo&lt;-mxEval(MZ.I2,FullBiFit)
(Rec&lt;-solve(sqrt(Itwo*Ec)) %*% Ec %*% solve(sqrt(Itwo*Ec)))

#check G1 (the causal effect)
mxEval(MZ.stG1,FullBiFit)

#other values
mxEval(MZ.stB1,FullBiFit)
mxEval(MZ.stB2,FullBiFit)
mxEval(MZ.h2,FullBiFit);mxEval(MZ.c2,FullBiFit);mxEval(MZ.e2,FullBiFit)
mxEval(MZ.Rac,FullBiFit)
mxEval(MZ.Rph,FullBiFit)

#get Rcc
Cc&lt;-mxEval(MZ.Cc,FullBiFit)
(Rcc&lt;-solve(sqrt(Itwo*Cc)) %*% Cc %*% solve(sqrt(Itwo*Cc)))
# compare the two models
mxCompare(FullBiFit,ACEFit)

## now run model without effect of PRS only but still with stb2 and rc,re dropped ###
DoC_Mod&lt;-mxModel(ACEFit,name=&quot;DOC&quot;)
DoC_Mod&lt;-omxSetParameters(DoC_Mod, labels=c(&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;), free=c(F,F),values=c(0,0))
DoC_Fit&lt;-mxRun(DoC_Mod, intervals=F)
(DoCSum&lt;-summary(DoC_Fit,verbose=T))

#check PGS effect
mxEval(MZ.stB1,DoC_Fit);mxEval(MZ.stB2,DoC_Fit)
#values for the path diagram
mxEval(MZ.stG1,DoC_Fit)
mxEval(MZ.h2,DoC_Fit);mxEval(MZ.c2,DoC_Fit);mxEval(MZ.e2,DoC_Fit)
mxEval(MZ.Rac,DoC_Fit)
mxEval(MZ.Rph,DoC_Fit)
mxEval(MZ.expCovMZ,DoC_Fit);mxEval(DZ.expCovDZ,DoC_Fit)
#compare the models
mxCompare(ACEFit,DoC_Fit)

##### sensitivity analysis: what if rE is not zero, e.g. fixed to 0.20? #####
#add re into the model
rEc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ec)) %*% Ec %*% solve(sqrt(I2*Ec)), name=&quot;Rec&quot; )
RphACE2&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                    #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                    (sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), 
                                    stB2*stB1, stG1),name=&quot;ACErph2&quot;)
pars2&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
            covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
            StA,StC,StE,matI,rph,rAc,rEc,beta1,beta2,pleio,Var2by2,RphACE2)

modelMZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ2&quot; )
modelDZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ2&quot; )
minus2ll2   &lt;-mxAlgebra( expression=MZ2.objective + DZ2.objective, name=&quot;m2LL2&quot; )
obj2        &lt;-mxFitFunctionAlgebra( &quot;m2LL2&quot; )
rE_fixed_Model  &lt;-mxModel(&quot;rE_fixed&quot;, pars2, modelMZ2, modelDZ2, minus2ll2, obj2)
rE_fixed_Model &lt;-omxSetParameters(rE_fixed_Model, labels=c(&quot;Exy&quot;, &quot;X_to_Y&quot;), free=c(T,T),values=c(0.5,0.2))

pathsCI_rEfix   &lt;-mxCI (c (&#39;MZ2.stG1&#39;))
#re = 0.05
rE_fixed_Model005&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.05, name=&quot;con1&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit1       &lt;- mxTryHardOrdinal(rE_fixed_Model005, intervals = T)

(rE_Fixed_FitSumm1&lt;-summary(rE_Fixed_Fit1,verbose=T))
mxEval(MZ2.stG1,rE_Fixed_Fit1)
mxEval(MZ2.Rec,rE_Fixed_Fit1)

## re=0.10
rE_fixed_Model010&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed2&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.10, name=&quot;con2&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit2       &lt;- mxTryHardOrdinal(rE_fixed_Model010, intervals = T,extraTries=20)

(rE_Fixed_FitSumm2&lt;-summary(rE_Fixed_Fit2,verbose=T))

## re=0.15
rE_fixed_Model015&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed3&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.15, name=&quot;con3&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit3       &lt;- mxTryHardOrdinal(rE_fixed_Model015, intervals = T, extraTries=20)

(rE_Fixed_FitSumm3&lt;-summary(rE_Fixed_Fit3,verbose=T))

## re=0.20
rE_fixed_Model020&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed4&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.20, name=&quot;con4&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit4       &lt;- mxTryHardOrdinal(rE_fixed_Model020, intervals = T,extraTries=20)

(rE_Fixed_FitSumm4&lt;-summary(rE_Fixed_Fit4,verbose=T))

## re=0.25
rE_fixed_Model025&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed5&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.25, name=&quot;con5&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit5       &lt;- mxTryHardOrdinal(rE_fixed_Model025, intervals = T)

(rE_Fixed_FitSumm5&lt;-summary(rE_Fixed_Fit5,verbose=T))


rbind(mxCompare(ACEFit1,rE_Fixed_Fit1),
      mxCompare(ACEFit1,rE_Fixed_Fit2)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit3)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit4)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit5)[2,])

rbind(mxEval(MZ2.stG1,rE_Fixed_Fit1),
      mxEval(MZ2.stG1,rE_Fixed_Fit2),
      mxEval(MZ2.stG1,rE_Fixed_Fit3),
      mxEval(MZ2.stG1,rE_Fixed_Fit4),
      mxEval(MZ2.stG1,rE_Fixed_Fit5))


rbind(ACESum1$CI[2,],
      rE_Fixed_FitSumm1$CI,
      rE_Fixed_FitSumm2$CI,
      rE_Fixed_FitSumm3$CI,
      rE_Fixed_FitSumm4$CI,
      rE_Fixed_FitSumm5$CI)
## save the results as RData
save.image(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv5_pMFQ_NSSH_20_April_2021.RData&quot;)
load(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv3_pMFQ_NSSH_08_April_2021.RData&quot;)</code></pre>
</div>
<div id="pmfq-ssh" class="section level3">
<h3>pMFQ-SSH</h3>
<pre class="r"><code>#**Regressing  out age &amp; sex **#

#residualise first, then tranform
merged_data$res_basic_pMFQ1&lt;- residuals(lm(merged_data$ppbhmfqt1
                                           ~merged_data$age_161 + merged_data$sex1,
                                           na.action=&quot;na.exclude&quot;))
merged_data$res_trans_order_pMFQ1 &lt;-log(merged_data$res_basic_pMFQ1+1.5)*3

#do same thing for twin 2. 
merged_data$res_basic_pMFQ2&lt;- residuals(lm(merged_data$ppbhmfqt2
                                           ~merged_data$age_162 + merged_data$sex2,
                                           na.action=&quot;na.exclude&quot;))

merged_data$res_trans_order_pMFQ2 &lt;-log(merged_data$res_basic_pMFQ2+1.5)*3

#***************************************************************************************
#################################### MR-DoC model ######################################
#***************************************************************************************

#variables I will need for this pMFQ MR-DoC model:
vars        &lt;-c(&#39;MDD_PRS&#39;,&#39;pMFQ&#39;,&#39;SH&#39;)
selVars &lt;-c(&#39;MDD100_res_t1&#39;, &#39;res_trans_order_pMFQ1&#39;,&#39;SSH1&#39;,
            &#39;MDD100_res_t2&#39;, &#39;res_trans_order_pMFQ2&#39;,&#39;SSH2&#39;)

useVars &lt;-c(&#39;MDD100_res_t1&#39;, &#39;res_trans_order_pMFQ1&#39;,&#39;SSH1&#39;,
            &#39;MDD100_res_t2&#39;, &#39;res_trans_order_pMFQ2&#39;,&#39;SSH2&#39;,
            &#39;age1&#39;, &#39;age2&#39;, &#39;sex1&#39;,&#39;sex2&#39;) #age is for at age 21


#need to recode missing age into 999
table(is.na(merged_data$age1))
merged_data$SSH1[is.na(merged_data$age1)] &lt;- NA
merged_data$SSH2[is.na(merged_data$age2)] &lt;- NA
merged_data$age1[is.na(merged_data$age1)] &lt;- 999
merged_data$age2[is.na(merged_data$age2)] &lt;- 999
merged_data[1:20,1:8]

#mz and dzdata for using res_trans_order_cMFQ
mzdata&lt;-subset(merged_data, zygos%in%1&amp;random==1 , useVars)
dzdata&lt;-subset(merged_data, zygos%in%2&amp;random==1 , useVars)



head(mzdata)

#do ACE model #
nv          &lt;- 3                # number of variables for a twin = 1 in Univariate
nvo             &lt;- 1                #number of ordinal variables per twin
nvc             &lt;- nv-nvo           #number of continuous variables per twin
poso            &lt;- nvo          #position where ordinal variables start
ntv         &lt;- 2*nv         # number of variables for a pair = 2* 1 for Univariate
nth         &lt;- 4    # number of max thresholds
nfact       &lt;- 3                # number of Latent Factors
ncor            &lt;- (nv*(nv+1)/2)-nv # number of free elements in a correlation matrix nv*nv
ninc            &lt;- nth-1            #number of max increments
ncovariates     &lt;- 2                #number of covariates


# Define definition variables to hold the Covariates

obsAge1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age1&quot;), name=&quot;Age1&quot;)
obsAge2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.age2&quot;), name=&quot;Age2&quot;)
obsSex1 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex1&quot;), name=&quot;Sex1&quot;)
obsSex2 &lt;- mxMatrix( type=&quot;Full&quot;, nrow=1, ncol=1, free=F, labels=c(&quot;data.sex2&quot;), name=&quot;Sex2&quot;)

#effect of age and sex on ordinal variable
LabCovA &lt;-c(&#39;BageThSSH&#39;, &#39;BageThSSH&#39;,&#39;BageThSSH&#39;, &#39;BageThSSH&#39;)
LabCovS &lt;-c(&#39;BsexThSSH&#39;, &#39;BsexThSSH&#39;,&#39;BsexThSSH&#39;, &#39;BsexThSSH&#39;)

betaA       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovA, name=&quot;BageTH&quot; )
betaS       &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=.2, labels=LabCovS, name=&quot;BsexTH&quot; )

#mean matrix, set NSSH to NA and fixed
StMZmean=c(colMeans(mzdata[,1:2],na.rm=TRUE),0)
Mean    &lt;-mxMatrix( &quot;Full&quot;, 1, ntv, free=c(T,T,F,T,T,F), values=StMZmean, labels=c(&quot;mPGS&quot;, &#39;mpMFQ&#39;,NA, &quot;mPGS&quot;, &#39;mpMFQ&#39;,NA), name=&quot;ExpMean&quot; )


#Threshold matrix
StTH        &lt;-c(-1,0.1,0.1,0.1)
LabTh   &lt;-c(&#39;Tmz_11&#39;,&#39;imz_11&#39;,&#39;imz_12&#39;,&#39;imz_13&#39;)
Tr      &lt;-mxMatrix( type=&quot;Full&quot;, nrow=nth, ncol=nvo, free=T, values=StTH, lbound=c(-4,0.001,0.001,0.001), ubound=c(4,4),
                labels=LabTh, name=&quot;Th&quot;)

inc     &lt;-mxMatrix( type=&quot;Lower&quot;,nrow=nth, ncol=nth, free=F, values=1, name=&quot;Low&quot;)

Thres   &lt;-mxAlgebra( expression= cbind(Low%*%Th + BageTH%x%Age1 + BsexTH%x%Sex1,
                                     Low%*%Th + BageTH%x%Age2 + BsexTH%x%Sex2),
                   name=&quot;ExpThres&quot;)

#Matrix that holds loadings from observed to latent variables
PatFl   &lt;- c(F,F,F,
           F,F,F,
           F,F,F) # Fix observed to latent to be 1 for all variables
StFl        &lt;- c(1,0,0,
           0,1,0,
           0,0,1)
LabFl   &lt;- c(&#39;PGS&#39;,NA,NA,
           NA,&#39;X&#39;,NA,
           NA, NA,&#39;Y&#39;)
Load        &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nv, ncol=nfact, free=PatFl, values=StFl, labels=LabFl, name=&quot;Loadings&quot; )
Id2     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=2, ncol=2, free=F, name=&quot;I2&quot; ) 
LoadTw  &lt;-mxAlgebra(I2%x%Loadings, name=&quot;FactLTw&quot;) #this will be a 2*nv x 2*nfact matrix,making it possible for both twins

#beta matrix to hold causal relationships
# Define the matrix to hold the Single headed Arrows (causal paths) between the 3 latent variables
# NB: direction of causation goes DOWN the column &amp; OUT along the row
PatPhC&lt;-c(F,T,T,
          F,F,T,
          F,F,F)
StPhC&lt;-c(0,0.05,0.05,
         0,0,0.05,
         0,0,0)
LabPhC&lt;-c(NA,&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;,
          NA,NA,&quot;X_to_Y&quot;,
          NA,NA,NA)
PhCaus  &lt;-mxMatrix(type=&quot;Full&quot;, nrow=nfact, ncol=nfact, free=PatPhC, values=StPhC, labels=LabPhC, name=&quot;PhC&quot; )

### Build the ACE components
# Define the matrices to hold the A and C effects: Common (upper) 
LabAc&lt;-c(&quot;Ax&quot;,&quot;Axy&quot;,&quot;Ay&quot;)
freeA&lt;-c(T,T,T)
stA&lt;-c(0.5,0.5,0.5)

LabCc&lt;-c(&quot;Cx&quot;,&quot;Cxy&quot;,&quot;Cy&quot;)
freeC&lt;-c(T,F,F)
stC&lt;-c(0.5,0,0)

LabEc&lt;-c(&quot;Ex&quot;,&quot;Exy&quot;,&quot;Ey&quot;)
freeE&lt;-c(T,F,T)
stE&lt;-c(0.5,0,0.5)



PathsAc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeA, values=stA, labels=LabAc , name=&quot;ac&quot; )
PathsCc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeC, values=stC, labels=LabCc , name=&quot;cc&quot; )
PathsEc &lt;-mxMatrix(type=&quot;Lower&quot;, nrow=nfact-1, ncol=nfact-1, free=freeE, values=stE, labels=LabEc , name=&quot;ec&quot; )
covAc       &lt;-mxAlgebra( expression= ac %*% t(ac), name=&quot;Ac&quot; ) #cannot parse PGS variance into ACE
covCc       &lt;-mxAlgebra( expression= cc %*% t(cc), name=&quot;Cc&quot; ) #use these for standardisation.
covEc       &lt;-mxAlgebra( expression= ec %*% t(ec), name=&quot;Ec&quot; )
covPc       &lt;-mxAlgebra( expression= Ac+Cc+Ec, name=&quot;Vc&quot; ) #use a 2 x 2 matrix only. 


MZcovPc     &lt;-mxAlgebra( expression= Ac+Cc, name=&quot;MZVc&quot; )
DZcovPc     &lt;-mxAlgebra( expression= 0.5%x%Ac+Cc, name=&quot;DZVc&quot; )

#then specify var for PGS with a unit matrix (freely estimated)
PGSpath &lt;-mxMatrix(type=&quot;Full&quot;, nrow=1, ncol=1, free=T, values=0.5, labels=&quot;PGS_sd&quot; , name=&quot;PGSp&quot; )
PGSvar&lt;-mxAlgebra(expression=PGSp%*%t(PGSp),name=&quot;varPGS&quot;) #this will be the double headed arrow for variance of PGS

#zero matrices
zeromat&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=2,ncol=1,free=F,name=&quot;zero&quot;)
zeromat2&lt;-mxMatrix(type=&quot;Zero&quot;,nrow=1,ncol=2,free=F,name=&quot;zero2&quot;)

totV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,Vc)),name=&quot;total_var&quot;)#if it complains, switch rbind and cbind.
#matrix above is a 3 x 3 matrix, within-twin matrix 
totMZV&lt;-mxAlgebra(expression=cbind(rbind(varPGS,zero),rbind(zero2,MZVc)),name=&quot;MZ_covar&quot;) #this is between person
totDZV&lt;-mxAlgebra(expression=cbind(rbind(0.5%x%varPGS,zero),rbind(zero2,DZVc)),name=&quot;DZ_covar&quot;)

# Generate Covariance of Latent factor model Including Causal Paths between factors
Id3     &lt;-mxMatrix(type=&quot;Iden&quot;, nrow=nfact, ncol=nfact, name=&quot;I3&quot; )

covFV   &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% total_var, name =&quot;FV&quot;) 
covMZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% MZ_covar, name =&quot;MZFV&quot;) 
covDZFV &lt;-mxAlgebra( expression= solve(I3-PhC) %&amp;% DZ_covar, name =&quot;DZFV&quot;) 


# Constraint on total variance of Ordinal variable (A+C+E=1)
varL        &lt;- mxConstraint( expression=FV[3,3]==1, name=&quot;L&quot; ) #total variablity after taking into account for causal effects

# Var-Cov of measured vars in terms of latent factors and AC, Cc, and Ec
#this results in a 6x6 matrix

covMZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, MZFV), cbind(MZFV, FV) )) , name=&quot;expCovMZ&quot; )#This traces the path from vars to factors and back to vars
covDZ   &lt;-mxAlgebra( expression= (FactLTw  %&amp;% rbind ( cbind(FV, DZFV), cbind(DZFV, FV) )) , name=&quot;expCovDZ&quot; )


# Algebra to compute standardized variance components
#generate a 2x2 matrix which has taken into account for causal effects from FV:
Var2by2&lt;-mxAlgebra(expression=FV[2:3,2:3],name=&quot;FV2by2&quot;)
StA &lt;- mxAlgebra( expression=Ac/FV2by2, name=&quot;h2&quot;)
StC &lt;- mxAlgebra( expression=Cc/FV2by2, name=&quot;c2&quot;)
StE &lt;- mxAlgebra( expression=Ec/FV2by2, name=&quot;e2&quot;)

# # Algebra to compute Phenotypic, A, C &amp; E correlations for exposure and outcome
matI    &lt;- mxMatrix( type=&quot;Iden&quot;, nrow=nv-1, ncol=nv-1, name=&quot;I2&quot;)
rph &lt;- mxAlgebra( expression= solve(sqrt(I3*FV)) %*% FV %*% solve(sqrt(I3*FV)), name=&quot;Rph&quot;)#get overall Rph
rAc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ac)) %*% Ac %*% solve(sqrt(I2*Ac)), name=&quot;Rac&quot; )


# Algebra to get standardised b1, b2 and g1 paths:
beta1=mxAlgebra(expression= (PhC[2,1]*sqrt(FV[1,1]))/(sqrt(FV[2,2])), name=&quot;stB1&quot;)
beta2=mxAlgebra(expression= (PhC[3,2]*sqrt(FV[2,2]))/(sqrt(FV[3,3])), name=&quot;stG1&quot;)
pleio=mxAlgebra(expression= (PhC[3,1]*sqrt(FV[1,1]))/(sqrt(FV[3,3])), name=&quot;stB2&quot;)


#algebra to get RPh due to A,C,E and causal effects: 
RphACE&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                   #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                   #(sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), #this should be zero because re will be fixed to zero.
                                   stB2*stB1, stG1),name=&quot;ACErph&quot;)

# Data objects for Multiple Groups
dataMZ  &lt;- mxData( observed=mzdata, type=&quot;raw&quot; )
dataDZ  &lt;- mxData( observed=dzdata, type=&quot;raw&quot; )


# Objective objects for Multiple Groups
objMZ       &lt;- mxExpectationNormal( covariance=&quot;expCovMZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;SSH1&quot;,&quot;SSH2&quot;) )
objDZ       &lt;- mxExpectationNormal( covariance=&quot;expCovDZ&quot;, means=&quot;ExpMean&quot;, dimnames=selVars, thresholds=&quot;ExpThres&quot;, threshnames=c(&quot;SSH1&quot;,&quot;SSH2&quot;) )

fitFunction &lt;- mxFitFunctionML()

# Combine Groups

pars&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
           covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
           StA,StC,StE,matI,rph,rAc,beta1,beta2,pleio,Var2by2,RphACE)

modelMZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ&quot; )
modelDZ &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                  pars, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ&quot; )


minus2ll    &lt;-mxAlgebra( expression=MZ.objective + DZ.objective, name=&quot;m2LL&quot; )
obj     &lt;-mxFitFunctionAlgebra( &quot;m2LL&quot; )

ACEModel    &lt;-mxModel(&quot;ACE&quot;, pars, modelMZ, modelDZ, minus2ll, obj)

#### run the ACE model which already has the parameters set or constrained: 
ACEFit      &lt;-mxTryHardOrdinal(ACEModel, intervals=F)
(ACESum &lt;- summary(ACEFit))
mxEval(MZ.ExpMean,ACEFit)

tableMZ&lt;-as.table(mxEval(MZ.expCovMZ,ACEFit))
colnames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;pMFQ1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;pMFQ2&quot;,&quot;SSH2&quot;)
rownames(tableMZ)&lt;-c(&quot;PGS1&quot;,&quot;pMFQ1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;pMFQ2&quot;,&quot;SSH2&quot;)
round(tableMZ,3)

tableDZ&lt;-as.table(mxEval(DZ.expCovDZ,ACEFit))
colnames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;pMFQ1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;pMFQ2&quot;,&quot;SSH2&quot;)
rownames(tableDZ)&lt;-c(&quot;PGS1&quot;,&quot;pMFQ1&quot;,&quot;SSH1&quot;,&quot;PGS2&quot;,&quot;pMFQ2&quot;,&quot;SSH2&quot;)
round(tableDZ,3)

mxEval(MZ.stB1,ACEFit)

pathsCI1    &lt;-mxCI (c (&#39;MZ.stB1&#39;,&#39;MZ.stG1&#39;,&#39;MZ.stB2&#39;))
pathsCI2&lt;-mxCI(c(&#39;MZ.h2[1,1]&#39;,&#39;MZ.c2[1,1]&#39;,&#39;MZ.e2[1,1]&#39;,
                 &#39;MZ.h2[2,2]&#39;,&#39;MZ.e2[2,2]&#39;))
pathsCI3&lt;-mxCI(c(&#39;MZ.Rac[2,1]&#39;,&#39;MZ.Rph[3,2]&#39;,
                 &#39;MZ.ACErph[1,1]&#39;,&#39;MZ.ACErph[1,2]&#39;,&#39;MZ.ACErph[1,3]&#39;))

#CI1
ACEModel1&lt;-mxModel(ACEFit,pathsCI1)
ACEFit1&lt;-mxRun(ACEModel1,intervals=T)
(ACESum1    &lt;- summary(ACEFit1))

#CI2
ACEModel2&lt;-mxModel(ACEFit,pathsCI2)
ACEFit2&lt;-mxRun(ACEModel2,intervals=T)
(ACESum2    &lt;- summary(ACEFit2))

#CI3
ACEModel3&lt;-mxModel(ACEFit,pathsCI3)
ACEFit3&lt;-mxRun(ACEModel3,intervals=T)
(ACESum3    &lt;- summary(ACEFit3))


sum(mxEval(MZ.ACErph[1:3],ACEFit))

ACESum1$CI
ACESum2$CI
ACESum3$CI


##### create full bivariate model without direction of causation for comparison #####
## re = True, stG1= False
FullBiMod&lt;-mxModel(ACEFit,name=&quot;Full_Bi&quot;)
FullBiMod&lt;-omxSetParameters(FullBiMod, labels=c(&quot;Exy&quot;,&quot;X_to_Y&quot;), free=c(T,F),values=c(0.5,0))
FullBiFit&lt;-mxRun(FullBiMod, intervals=F)
(FullBiSum&lt;-summary(FullBiFit,verbose=T))
#check re
Ec&lt;-mxEval(MZ.Ec,FullBiFit)
Itwo&lt;-mxEval(MZ.I2,FullBiFit)
(Rec&lt;-solve(sqrt(Itwo*Ec)) %*% Ec %*% solve(sqrt(Itwo*Ec)))

#check G1 (the causal effect)
mxEval(MZ.stG1,FullBiFit)

#other values
mxEval(MZ.stB1,FullBiFit)
mxEval(MZ.stB2,FullBiFit)
mxEval(MZ.h2,FullBiFit);mxEval(MZ.c2,FullBiFit);mxEval(MZ.e2,FullBiFit)
mxEval(MZ.Rac,FullBiFit)
mxEval(MZ.Rph,FullBiFit)

#get Rcc
Cc&lt;-mxEval(MZ.Cc,FullBiFit)
(Rcc&lt;-solve(sqrt(Itwo*Cc)) %*% Cc %*% solve(sqrt(Itwo*Cc)))
# compare the two models
mxCompare(FullBiFit,ACEFit)

## now run model without effect of PRS only but still with stb2 and rc,re dropped ###
DoC_Mod&lt;-mxModel(ACEFit,name=&quot;DOC&quot;)
DoC_Mod&lt;-omxSetParameters(DoC_Mod, labels=c(&quot;PGS_to_X&quot;,&quot;PGS_to_Y&quot;), free=c(F,F),values=c(0,0))
DoC_Fit&lt;-mxRun(DoC_Mod, intervals=F)
(DoCSum&lt;-summary(DoC_Fit,verbose=T))

#check PGS effect
mxEval(MZ.stB1,DoC_Fit);mxEval(MZ.stB2,DoC_Fit)
#values for the path diagram
mxEval(MZ.stG1,DoC_Fit)
mxEval(MZ.h2,DoC_Fit);mxEval(MZ.c2,DoC_Fit);mxEval(MZ.e2,DoC_Fit)
mxEval(MZ.Rac,DoC_Fit)
mxEval(MZ.Rph,DoC_Fit)
mxEval(MZ.expCovMZ,DoC_Fit);mxEval(DZ.expCovDZ,DoC_Fit)
#compare the models
mxCompare(ACEFit,DoC_Fit)


##### sensitivity analysis: what if rE is not zero, e.g. fixed to 0.20? #####
#add re into the model
rEc &lt;- mxAlgebra( expression= solve(sqrt(I2*Ec)) %*% Ec %*% solve(sqrt(I2*Ec)), name=&quot;Rec&quot; )
RphACE2&lt;-mxAlgebra(expression=cbind((sqrt(h2[1,1])*Rac[2,1]*sqrt(h2[2,2])),
                                    #(sqrt(c2[1,1])*Rcc[2,1]*sqrt(c2[2,2])),
                                    (sqrt(e2[1,1])*Rec[2,1]*sqrt(e2[2,2])), 
                                    stB2*stB1, stb2),name=&quot;ACErph2&quot;)
pars2&lt;-list(Load,Id2,LoadTw,PhCaus,PathsAc,PathsCc,PathsEc,
            covAc,covCc,covEc,covPc, Id3,zeromat,zeromat2, PGSvar,PGSpath,totV,covFV,
            StA,StC,StE,matI,rph,rAc,rEc,beta1,beta2,pleio,Var2by2,RphACE2)

modelMZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, MZcovPc,totMZV,covMZFV,covMZ, dataMZ, objMZ, fitFunction, varL, name=&quot;MZ2&quot; )
modelDZ2    &lt;-mxModel(obsAge1,obsAge2,obsSex1,obsSex2,betaA,betaS,Tr,inc,Thres,Mean,
                   pars2, DZcovPc,totDZV,covDZFV,covDZ,dataDZ, objDZ, fitFunction, name=&quot;DZ2&quot; )
minus2ll2   &lt;-mxAlgebra( expression=MZ2.objective + DZ2.objective, name=&quot;m2LL2&quot; )
obj2        &lt;-mxFitFunctionAlgebra( &quot;m2LL2&quot; )
rE_fixed_Model  &lt;-mxModel(&quot;rE_fixed&quot;, pars2, modelMZ2, modelDZ2, minus2ll2, obj2)
rE_fixed_Model &lt;-omxSetParameters(rE_fixed_Model, labels=c(&quot;Exy&quot;, &quot;X_to_Y&quot;), free=c(T,T),values=c(0.5,0.2))

pathsCI_rEfix   &lt;-mxCI (c (&#39;MZ2.stG1&#39;))
#re = 0.05
rE_fixed_Model005&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.05, name=&quot;con1&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit1       &lt;- mxTryHardOrdinal(rE_fixed_Model005, intervals = T)

(rE_Fixed_FitSumm1&lt;-summary(rE_Fixed_Fit1,verbose=T))
mxEval(MZ2.stG1,rE_Fixed_Fit1)
mxEval(MZ2.Rec,rE_Fixed_Fit1)

## re=0.10
rE_fixed_Model010&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed2&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.10, name=&quot;con2&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit2       &lt;- mxTryHardOrdinal(rE_fixed_Model010, intervals = T)

(rE_Fixed_FitSumm2&lt;-summary(rE_Fixed_Fit2,verbose=T))

## re=0.15
rE_fixed_Model015&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed3&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.15, name=&quot;con3&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit3       &lt;- mxTryHardOrdinal(rE_fixed_Model015, intervals = T)

(rE_Fixed_FitSumm3&lt;-summary(rE_Fixed_Fit3,verbose=T))

## re=0.20
rE_fixed_Model020&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed4&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.20, name=&quot;con4&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit4       &lt;- mxTryHardOrdinal(rE_fixed_Model020, intervals = T)

(rE_Fixed_FitSumm4&lt;-summary(rE_Fixed_Fit4,verbose=T))

## re=0.25
rE_fixed_Model025&lt;-mxModel(rE_fixed_Model,name=&quot;rE_fixed5&quot;,
                           mxConstraint(MZ2.Rec[1,2]==0.25, name=&quot;con5&quot;),
                           pathsCI_rEfix)

rE_Fixed_Fit5       &lt;- mxTryHardOrdinal(rE_fixed_Model025, intervals = T,extraTries=20)

(rE_Fixed_FitSumm5&lt;-summary(rE_Fixed_Fit5,verbose=T))


rbind(mxCompare(ACEFit1,rE_Fixed_Fit1),
      mxCompare(ACEFit1,rE_Fixed_Fit2)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit3)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit4)[2,],
      mxCompare(ACEFit1,rE_Fixed_Fit5)[2,])

rbind(mxEval(MZ2.stG1,rE_Fixed_Fit1),
      mxEval(MZ2.stG1,rE_Fixed_Fit2),
      mxEval(MZ2.stG1,rE_Fixed_Fit3),
      mxEval(MZ2.stG1,rE_Fixed_Fit4),
      mxEval(MZ2.stG1,rE_Fixed_Fit5))

rbind(ACESum1$CI[2,],
      rE_Fixed_FitSumm1$CI,
      rE_Fixed_FitSumm2$CI,
      rE_Fixed_FitSumm3$CI,
      rE_Fixed_FitSumm4$CI,
      rE_Fixed_FitSumm5$CI)
## save the results as RData
save.image(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv5_pMFQ_SSH_20_April_2021.RData&quot;)
load(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_rc_re_zero_wSAv2_pMFQ_SSH_25_March_2021.RData&quot;)</code></pre>
</div>
</div>
<div id="extracting-mr-doc-results-into-excel-sheets" class="section level2">
<h2>Extracting MR-DoC results into Excel sheets</h2>
<p>The code chunk below was used to extract MR-DoC modelling results from Rdata format into Excel sheets. The results on Excel sheets were then manually arranged to have a more readable format.</p>
<pre class="r"><code>rm(list=ls())
setwd(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/results&quot;)
one_SH&lt;-grep(&quot;MR_DoC_rc_re_zero_wSAv5_&quot;,list.files())
(names&lt;-list.files()[c(one_SH)]) #Rdata files to be loaded. 

names[1]
load(names[1]) #load cMFQ NSSH
#use data from Model 2 in this cMFQ-NSSH Rdata: residualise CMFQ then transform. 
cMFQ_NSSH&lt;-rbind(ACESum1$CI,ACESum2$CI,ACESum3$CI)
cMFQ_NSSH$exposure&lt;-&quot;cMFQ&quot;
cMFQ_NSSH$outcome&lt;-&quot;NSSH&quot;

cMFQ_NSSH_bi_compare&lt;-as.data.frame(mxCompare(FullBiFit,ACEFit))
cMFQ_NSSH_bi_compare$exposure&lt;-&quot;cMFQ&quot;
cMFQ_NSSH_bi_compare$outcome&lt;-&quot;NSSH&quot;
cMFQ_NSSH_bi_compare$rE&lt;-c(Rec[1,2])

cMFQ_NSSH_DoC&lt;-as.data.frame(mxCompare(ACEFit,DoC_Fit))
cMFQ_NSSH_DoC$exposure&lt;-&quot;cMFQ&quot;
cMFQ_NSSH_DoC$outcome&lt;-&quot;NSSH&quot;

names[2]
load(names[2]) #load cMFQ SSH
cMFQ_SSH&lt;-rbind(ACESum1$CI,ACESum2$CI,ACESum3$CI)
cMFQ_SSH$exposure&lt;-&quot;cMFQ&quot;
cMFQ_SSH$outcome&lt;-&quot;SSH&quot;
cMFQ_SSH_bi_compare$rE&lt;-c(Rec[1,2])

cMFQ_SSH_bi_compare&lt;-as.data.frame(mxCompare(FullBiFit,ACEFit))
cMFQ_SSH_bi_compare$exposure&lt;-&quot;cMFQ&quot;
cMFQ_SSH_bi_compare$outcome&lt;-&quot;SSH&quot;

cMFQ_SSH_DoC&lt;-as.data.frame(mxCompare(ACEFit,DoC_Fit))
cMFQ_SSH_DoC$exposure&lt;-&quot;cMFQ&quot;
cMFQ_SSH_DoC$outcome&lt;-&quot;SSH&quot;

names[5]
load(names[5]) #load pMFQ NSSH
pMFQ_NSSH&lt;-rbind(ACESum1$CI,ACESum2$CI,ACESum3$CI)
pMFQ_NSSH$exposure&lt;-&quot;pMFQ&quot;
pMFQ_NSSH$outcome&lt;-&quot;NSSH&quot;

pMFQ_NSSH_bi_compare&lt;-as.data.frame(mxCompare(FullBiFit,ACEFit))
pMFQ_NSSH_bi_compare$exposure&lt;-&quot;pMFQ&quot;
pMFQ_NSSH_bi_compare$outcome&lt;-&quot;NSSH&quot;
pMFQ_NSSH_bi_compare$rE&lt;-c(Rec[1,2])


pMFQ_NSSH_DoC&lt;-as.data.frame(mxCompare(ACEFit,DoC_Fit))
pMFQ_NSSH_DoC$exposure&lt;-&quot;pMFQ&quot;
pMFQ_NSSH_DoC$outcome&lt;-&quot;NSSH&quot;

names[6]
load(names[6]) #load pMFQ SSH
pMFQ_SSH&lt;-rbind(ACESum1$CI,ACESum2$CI,ACESum3$CI)
pMFQ_SSH$exposure&lt;-&quot;pMFQ&quot;
pMFQ_SSH$outcome&lt;-&quot;SSH&quot;

pMFQ_SSH_bi_compare&lt;-as.data.frame(mxCompare(FullBiFit,ACEFit))
pMFQ_SSH_bi_compare$exposure&lt;-&quot;pMFQ&quot;
pMFQ_SSH_bi_compare$outcome&lt;-&quot;SSH&quot;
pMFQ_SSH_bi_compare$rE&lt;-c(Rec[1,2])

pMFQ_SSH_DoC&lt;-as.data.frame(mxCompare(ACEFit,DoC_Fit))
pMFQ_SSH_DoC$exposure&lt;-&quot;pMFQ&quot;
pMFQ_SSH_DoC$outcome&lt;-&quot;SSH&quot;

names[3]
load(names[3]) #load pCONN NSSH
pCONN_NSSH&lt;-rbind(ACESum1$CI,ACESum2$CI,ACESum3$CI)
pCONN_NSSH$exposure&lt;-&quot;pCONN&quot;
pCONN_NSSH$outcome&lt;-&quot;NSSH&quot;

pCONN_NSSH_bi_compare&lt;-as.data.frame(mxCompare(FullBiFit,ACEFit))
pCONN_NSSH_bi_compare$exposure&lt;-&quot;pCONN&quot;
pCONN_NSSH_bi_compare$outcome&lt;-&quot;NSSH&quot;
pCONN_NSSH_bi_compare$rE&lt;-c(Rec[1,2])

pCONN_NSSH_DoC&lt;-as.data.frame(mxCompare(ACEFit,DoC_Fit))
pCONN_NSSH_DoC$exposure&lt;-&quot;pCONN&quot;
pCONN_NSSH_DoC$outcome&lt;-&quot;NSSH&quot;


names[4]
load(names[4]) #load pCONN SSH
#load Model 1. 
pCONN_SSH&lt;-rbind(ACESum1$CI,ACESum2$CI,ACESum3$CI)
pCONN_SSH$exposure&lt;-&quot;pCONN&quot;
pCONN_SSH$outcome&lt;-&quot;SSH&quot;

pCONN_SSH_bi_compare&lt;-as.data.frame(mxCompare(FullBiFit,ACEFit))
pCONN_SSH_bi_compare$exposure&lt;-&quot;pCONN&quot;
pCONN_SSH_bi_compare$outcome&lt;-&quot;SSH&quot;
pCONN_SSH_bi_compare$rE&lt;-c(Rec[1,2])

pCONN_SSH_DoC&lt;-as.data.frame(mxCompare(ACEFit,DoC_Fit))
pCONN_SSH_DoC$exposure&lt;-&quot;pCONN&quot;
pCONN_SSH_DoC$outcome&lt;-&quot;SSH&quot;


## IMPORTANT: make sure g1 in the labels refer to the causal effect etc, following Minica&#39;s paper
whole_data&lt;-rbind(cMFQ_NSSH,cMFQ_SSH,pMFQ_NSSH,pMFQ_SSH,pCONN_NSSH,pCONN_SSH)
labels&lt;-c(&quot;b1&quot;,&quot;g1&quot;,&quot;b2&quot;,&quot;X_h2&quot;,&quot;X_c2&quot;,&quot;X_e2&quot;,&quot;Y_h2&quot;,&quot;Y_e2&quot;,&quot;Ra&quot;,&quot;Rph&quot;,&quot;RphA&quot;,&quot;RPh_PRS&quot;,&quot;RPh_Cause&quot;)
rownames(whole_data)&lt;-
  c(paste0(labels,c(rep(&quot;_cMFQ_NSSH&quot;,13))),
  paste0(labels,c(rep(&quot;_cMFQ_SSH&quot;,13))),
  paste0(labels,c(rep(&quot;_pMFQ_NSSH&quot;,13))),
  paste0(labels,c(rep(&quot;_pMFQ_SSH&quot;,13))),
  paste0(labels,c(rep(&quot;_pCONN_NSSH&quot;,13))),
  paste0(labels,c(rep(&quot;_pCONN_SSH&quot;,13))))

whole_data
library(tidyverse)
whole_data2&lt;-
  whole_data%&gt;%
  select(5,6,1,2,3)%&gt;%
  mutate_at(vars(-c(exposure,outcome)),funs(round(.,3)))%&gt;%
  add_column(names=rep(c(&quot;b1&quot;,&quot;g1&quot;,&quot;b2&quot;,&quot;X_h2&quot;,&quot;X_c2&quot;,&quot;X_e2&quot;,&quot;Y_h2&quot;,&quot;Y_e2&quot;,&quot;Ra&quot;,&quot;Rph&quot;,&quot;RPh_A&quot;,&quot;RPh_PRS&quot;,&quot;RPh_Cau&quot;),6))%&gt;%
  select(6,1:5)

whole_data2

b1b2g1&lt;-subset(whole_data2,
               whole_data2$names==&quot;b1&quot;|whole_data2$names==&quot;b2&quot;|whole_data2$names==&quot;g1&quot;)
b1b2g1

b1b2g1_wide&lt;-b1b2g1%&gt;%
          add_column(estimate_CI=paste0(format(b1b2g1$estimate,digits=3), &quot; (&quot;, 
                           format(b1b2g1$lbound,digits=3), &quot;,&quot;, 
                           format(b1b2g1$ubound,digits=3), &quot;)&quot;))%&gt;%
          select(c(1:3,7))%&gt;%
          spread(names, estimate_CI)%&gt;%
          select(c(1,2,3,5,4))

b1b2g1_wide
##h2c2e2
h2c2e2&lt;-subset(whole_data2,
               whole_data2$names==&quot;X_h2&quot;|whole_data2$names==&quot;X_c2&quot;|whole_data2$names==&quot;X_e2&quot;|
               whole_data2$names==&quot;Y_h2&quot;|whole_data2$names==&quot;Y_c2&quot;|whole_data2$names==&quot;Y_e2&quot;)

h2c2e2_wide&lt;-h2c2e2%&gt;%
  add_column(estimate_CI=paste0(format(h2c2e2$estimate,digits=3), &quot; (&quot;, 
                                format(h2c2e2$lbound,digits=3), &quot;,&quot;, 
                                format(h2c2e2$ubound,digits=3), &quot;)&quot;))%&gt;%
  select(1:3,7)%&gt;%
  spread(names,estimate_CI)%&gt;%
  select(1,2,5,3,4,7,6)
  
h2c2e2_wide

rarcrph&lt;-subset(whole_data2,
               whole_data2$names==&quot;Ra&quot;|whole_data2$names==&quot;Rc&quot;|whole_data2$names==&quot;Rph&quot;)
rarcrph
rarcrph_wide&lt;-rarcrph%&gt;%
  add_column(estimate_CI=paste0(format(rarcrph$estimate,digits=3), &quot; (&quot;, 
                                format(rarcrph$lbound,digits=3), &quot;,&quot;, 
                                format(rarcrph$ubound,digits=3), &quot;)&quot;))%&gt;%
  select(1:3,7)%&gt;%
  spread(names,estimate_CI)

rarcrph_wide

rphACC&lt;-subset(whole_data2,
                whole_data2$names==&quot;RPh_A&quot;|whole_data2$names==&quot;RPh_C&quot;|whole_data2$names==&quot;RPh_PRS&quot;|whole_data2$names==&quot;RPh_Cau&quot;)
rphACC
rphACC_wide&lt;-rphACC%&gt;%
  add_column(estimate_CI=paste0(format(rphACC$estimate,digits=3), &quot; (&quot;, 
                                format(rphACC$lbound,digits=3), &quot;,&quot;, 
                                format(rphACC$ubound,digits=3), &quot;)&quot;))%&gt;%
  select(1:3,7)%&gt;%
  spread(names,estimate_CI)
rphACC_wide

# merge rphACC_wide and b1b2g2_wide
merged_estimates&lt;-
  merge(merge(b1b2g1_wide,rphACC_wide, by=c(&quot;exposure&quot;, &quot;outcome&quot;)),
        rarcrph_wide,by=c(&quot;exposure&quot;, &quot;outcome&quot;))%&gt;%
  select(1,2,3,4,5,10,6,7,8)

  colnames(merged_estimates)&lt;-
    c(&quot;Exposure&quot;,&quot;Outcome&quot;,&quot;b1&quot;, &quot;g1 (causal effect)&quot;,
      &quot;b2 (pleiotropy)&quot;, &quot;RPh&quot;, &quot;RPh due to A&quot;, 
      &quot;RPh due to causal effect&quot;,&quot;RPh due to pleiotropy&quot;)

merged_estimates

## now collect data from bi_compare and DoC
bi_compare&lt;-rbind(cMFQ_NSSH_bi_compare,cMFQ_SSH_bi_compare,
                  pMFQ_NSSH_bi_compare,pMFQ_SSH_bi_compare,
                  pCONN_NSSH_bi_compare,pCONN_SSH_bi_compare)%&gt;%
  select(14,15,1:9,16)
bi_compare

DoC&lt;-rbind(cMFQ_NSSH_DoC,cMFQ_SSH_DoC,
           pMFQ_NSSH_DoC,pMFQ_SSH_DoC,
           pCONN_NSSH_DoC,pCONN_SSH_DoC)%&gt;%
  select(14,15,1:9)


xlsx::write.xlsx(whole_data2,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;whole_data&quot;)
xlsx::write.xlsx(b1b2g1_wide,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;causal_effects&quot;,append = T)
xlsx::write.xlsx(h2c2e2_wide,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;h2_c2_e2&quot;,append = T)
xlsx::write.xlsx(rarcrph_wide,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;Ra_Rc_Rph&quot;,append = T)
xlsx::write.xlsx(rphACC_wide,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;Rph_ACC&quot;,append = T)
xlsx::write.xlsx(whole_data,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;raw_data&quot;,append = T)
xlsx::write.xlsx(merged_estimates,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;table_for_paper&quot;,append = T)
## add bi_compare, DoC, ext MR
xlsx::write.xlsx(bi_compare,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;compare with full bi model&quot;,append = T)
xlsx::write.xlsx(DoC,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;compare with DoC model (no PGS)&quot;,append = T)




##### fixed rE results ####
fixed_confint&lt;-grep(&quot;MR_DoC_rc_re_zero_wSAv5_&quot;,list.files())
#zerolbound&lt;-grep(&quot;MR_DoC_rc_re_zero_wSAv4_&quot;,list.files())
(names_fixed_confint&lt;-list.files()[c(fixed_confint)]) #Rdata files to be loaded. 
(names_zerolbound&lt;-list.files()[c(zerolbound)])

#assess using confint
#for cMFQ-NSSH
names_fixed_confint[1]
load(names_fixed_confint[1]) #load cMFQ NSSH
AIC_cMFQ_NSSH&lt;-rbind(as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit1)),
      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit2))[2,],
      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit3))[2,],
      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit4))[2,],
      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit5))[2,])[,6]



confint_cMFQ_NSSH&lt;-rbind(
      ACESum1$CI[2,],
      rE_Fixed_FitSumm1$CI,
      rE_Fixed_FitSumm2$CI,
      rE_Fixed_FitSumm3$CI,
      rE_Fixed_FitSumm4$CI,
      rE_Fixed_FitSumm5$CI)

rE_values&lt;-c(seq(from=0, to=0.25,by=0.05))
fixed_rE_cMFQ_NSSH_CI&lt;-cbind(rE_values,AIC_cMFQ_NSSH,confint_cMFQ_NSSH)




#for cMFQ-SSH
names_fixed_confint[2]
load(names_fixed_confint[2]) #load cMFQ NSSH
AIC_cMFQ_SSH&lt;-rbind(as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit1)),
                     as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit2))[2,],
                     as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit3))[2,],
                     as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit4))[2,],
                     as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit5))[2,])[,6]



confint_cMFQ_SSH&lt;-rbind(
  ACESum1$CI[2,],
  rE_Fixed_FitSumm1$CI,
  rE_Fixed_FitSumm2$CI,
  rE_Fixed_FitSumm3$CI,
  rE_Fixed_FitSumm4$CI,
  rE_Fixed_FitSumm5$CI)

rE_values&lt;-c(seq(from=0, to=0.25,by=0.05))
fixed_rE_cMFQ_SSH_CI&lt;-cbind(rE_values,AIC_cMFQ_SSH,confint_cMFQ_SSH)

#for pCONN-NSSH
names_fixed_confint[3]
load(names_fixed_confint[3]) #load cMFQ NSSH
AIC_pCONN_NSSH&lt;-rbind(as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit1)),
                    as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit2))[2,],
                    as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit3))[2,],
                    as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit4))[2,],
                    as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit5))[2,])[,6]



confint_pCONN_NSSH&lt;-rbind(
  ACESum1$CI[2,],
  rE_Fixed_FitSumm1$CI,
  rE_Fixed_FitSumm2$CI,
  rE_Fixed_FitSumm3$CI,
  rE_Fixed_FitSumm4$CI,
  rE_Fixed_FitSumm5$CI)

rE_values&lt;-c(seq(from=0, to=0.25,by=0.05))
fixed_rE_pCONN_NSSH_CI&lt;-cbind(rE_values,AIC_pCONN_NSSH,confint_pCONN_NSSH)


#for pCONN-SSH
names_fixed_confint[4]
load(names_fixed_confint[4]) #load cMFQ NSSH
AIC_pCONN_SSH&lt;-rbind(as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit1)),
                      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit2))[2,],
                      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit3))[2,],
                      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit4))[2,],
                      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit5))[2,])[,6]



confint_pCONN_SSH&lt;-rbind(
  ACESum1$CI[2,],
  rE_Fixed_FitSumm1$CI,
  rE_Fixed_FitSumm2$CI,
  rE_Fixed_FitSumm3$CI,
  rE_Fixed_FitSumm4$CI,
  rE_Fixed_FitSumm5$CI)

rE_values&lt;-c(seq(from=0, to=0.25,by=0.05))
fixed_rE_pCONN_SSH_CI&lt;-cbind(rE_values,AIC_pCONN_SSH,confint_pCONN_SSH)


#for pMFQ-NSSH
names_fixed_confint[5]
load(names_fixed_confint[5]) #load pMFQ NSSH
AIC_pMFQ_NSSH&lt;-rbind(as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit1)),
                      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit2))[2,],
                      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit3))[2,],
                      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit4))[2,],
                      as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit5))[2,])[,6]



confint_pMFQ_NSSH&lt;-rbind(
  ACESum1$CI[2,],
  rE_Fixed_FitSumm1$CI,
  rE_Fixed_FitSumm2$CI,
  rE_Fixed_FitSumm3$CI,
  rE_Fixed_FitSumm4$CI,
  rE_Fixed_FitSumm5$CI)

rE_values&lt;-c(seq(from=0, to=0.25,by=0.05))
fixed_rE_pMFQ_NSSH_CI&lt;-cbind(rE_values,AIC_pMFQ_NSSH,confint_pMFQ_NSSH)


#pMFQ-SSH
names_fixed_confint[6]
load(names_fixed_confint[6]) #load pMFQ SSH
AIC_pMFQ_SSH&lt;-rbind(as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit1)),
                     as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit2))[2,],
                     as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit3))[2,],
                     as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit4))[2,],
                     as.data.frame(mxCompare(ACEFit1,rE_Fixed_Fit5))[2,])[,6]



confint_pMFQ_SSH&lt;-rbind(
  ACESum1$CI[2,],
  rE_Fixed_FitSumm1$CI,
  rE_Fixed_FitSumm2$CI,
  rE_Fixed_FitSumm3$CI,
  rE_Fixed_FitSumm4$CI,
  rE_Fixed_FitSumm5$CI)

rE_values&lt;-c(seq(from=0, to=0.25,by=0.05))
fixed_rE_pMFQ_SSH_CI&lt;-cbind(rE_values,AIC_pMFQ_SSH,confint_pMFQ_SSH)


fixed_rE_cMFQ_NSSH_CI$ID&lt;-&quot;cMFQ_NSSH&quot;
fixed_rE_cMFQ_SSH_CI$ID&lt;-&quot;cMFQ_SSH&quot;
fixed_rE_pMFQ_NSSH_CI$ID&lt;-&quot;pMFQ_NSSH&quot;
fixed_rE_pMFQ_SSH_CI$ID&lt;-&quot;pMFQ_SSH&quot;
fixed_rE_pCONN_NSSH_CI$ID&lt;-&quot;pCONN_NSSH&quot;
fixed_rE_pCONN_SSH_CI$ID&lt;-&quot;pCONN_SSH&quot;

colnames(fixed_rE_cMFQ_NSSH_CI)[2]&lt;-&quot;AIC&quot;
colnames(fixed_rE_cMFQ_SSH_CI)[2]&lt;-&quot;AIC&quot;
colnames(fixed_rE_pMFQ_NSSH_CI)[2]&lt;-&quot;AIC&quot;
colnames(fixed_rE_pMFQ_SSH_CI)[2]&lt;-&quot;AIC&quot;
colnames(fixed_rE_pCONN_NSSH_CI)[2]&lt;-&quot;AIC&quot;
colnames(fixed_rE_pCONN_SSH_CI)[2]&lt;-&quot;AIC&quot;

fixed_rE_data&lt;-rbind(fixed_rE_cMFQ_NSSH_CI,
                     fixed_rE_cMFQ_SSH_CI,
                     fixed_rE_pMFQ_NSSH_CI,
                     fixed_rE_pMFQ_SSH_CI,
                     fixed_rE_pCONN_NSSH_CI,
                     fixed_rE_pCONN_SSH_CI)
fixed_rE_data2&lt;-fixed_rE_data%&gt;%
  add_column(estimate_CI=paste0(format(fixed_rE_data$estimate,digits=1), &quot; (&quot;, 
                                format(fixed_rE_data$lbound,digits=1), &quot;,&quot;, 
                                round(fixed_rE_data$ubound,digits=3), &quot;)&quot;))%&gt;%
  select(7,1,2,8)



xlsx::write.xlsx(fixed_rE_data2,&quot;MR_DoC_results_27_April_2021.xlsx&quot;,sheetName = &quot;fixed_rE_data2&quot;,append = T)</code></pre>
</div>
<div id="mr-doc-results" class="section level2">
<h2>MR-DoC Results</h2>
<pre class="r"><code>MR_doc_results=xlsx::read.xlsx(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_results_27_April_2021.xlsx&quot;, sheetName = &quot;table_for_paper&quot;)

MR_doc_results$Exposure&lt;-c(&quot;cMFQ&quot;,&quot;cMFQ&quot;,&quot;pCONN&quot;,&quot;pCONN&quot;,&quot;pMFQ&quot;,&quot;pMFQ&quot;)
MR_doc_results=MR_doc_results[,-1]
kableExtra::kable(MR_doc_results,digits=3,align=&quot;c&quot;)%&gt;%
  kableExtra::kable_styling(font_size = 12, full_width = TRUE)%&gt;%
  collapse_rows()</code></pre>
<table class="table" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Exposure
</th>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
b1
</th>
<th style="text-align:center;">
g1..causal.effect.
</th>
<th style="text-align:center;">
b2..pleiotropy.
</th>
<th style="text-align:center;">
RPh
</th>
<th style="text-align:center;">
RPh.due.to.A
</th>
<th style="text-align:center;">
RPh.due.to.causal.effect
</th>
<th style="text-align:center;">
RPh.due.to.pleiotropy
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
cMFQ
</td>
<td style="text-align:center;">
NSSH
</td>
<td style="text-align:center;">
0.066 ( 0.042,0.090)
</td>
<td style="text-align:center;">
0.194 ( 0.131,0.257)
</td>
<td style="text-align:center;">
0.087 ( 0.050,0.124)
</td>
<td style="text-align:center;">
0.370 ( 0.342,0.396)
</td>
<td style="text-align:center;">
0.170 ( 0.108,0.231)
</td>
<td style="text-align:center;">
0.194 ( 0.131,0.257)
</td>
<td style="text-align:center;">
0.006 ( 0.003,0.010)
</td>
</tr>
<tr>
<td style="text-align:center;">
cMFQ
</td>
<td style="text-align:center;">
SSH
</td>
<td style="text-align:center;">
0.066 ( 0.041,0.090)
</td>
<td style="text-align:center;">
0.210 ( 0.125,0.295)
</td>
<td style="text-align:center;">
0.099 ( 0.052,0.144)
</td>
<td style="text-align:center;">
0.391 ( 0.357,0.423)
</td>
<td style="text-align:center;">
0.174 ( 0.092,0.255)
</td>
<td style="text-align:center;">
0.210 ( 0.125,0.295)
</td>
<td style="text-align:center;">
0.006 ( 0.003,0.011)
</td>
</tr>
<tr>
<td style="text-align:center;">
pCONN
</td>
<td style="text-align:center;">
NSSH
</td>
<td style="text-align:center;">
0.101 ( 0.076,0.126)
</td>
<td style="text-align:center;">
0.127 (-0.032,0.285)
</td>
<td style="text-align:center;">
0.041 (-0.001,0.083)
</td>
<td style="text-align:center;">
0.115 ( 0.078,0.152)
</td>
<td style="text-align:center;">
-0.016 (-0.174,0.142)
</td>
<td style="text-align:center;">
0.127 (-0.032,0.285)
</td>
<td style="text-align:center;">
0.004 ( 0.000,0.009)
</td>
</tr>
<tr>
<td style="text-align:center;">
pCONN
</td>
<td style="text-align:center;">
SSH
</td>
<td style="text-align:center;">
0.101 ( 0.076,0.126)
</td>
<td style="text-align:center;">
0.187 (-0.028,0.402)
</td>
<td style="text-align:center;">
0.079 ( 0.027,0.131)
</td>
<td style="text-align:center;">
0.164 ( 0.118,0.209)
</td>
<td style="text-align:center;">
-0.031 (-0.245,0.182)
</td>
<td style="text-align:center;">
0.187 (-0.028,0.402)
</td>
<td style="text-align:center;">
0.008 ( 0.003,0.014)
</td>
</tr>
<tr>
<td style="text-align:center;">
pMFQ
</td>
<td style="text-align:center;">
NSSH
</td>
<td style="text-align:center;">
0.064 ( 0.039,0.089)
</td>
<td style="text-align:center;">
0.092 ( 0.004,0.181)
</td>
<td style="text-align:center;">
0.093 ( 0.054,0.131)
</td>
<td style="text-align:center;">
0.194 ( 0.163,0.225)
</td>
<td style="text-align:center;">
0.097 ( 0.008,0.185)
</td>
<td style="text-align:center;">
0.092 ( 0.004,0.181)
</td>
<td style="text-align:center;">
0.006 ( 0.003,0.010)
</td>
</tr>
<tr>
<td style="text-align:center;">
pMFQ
</td>
<td style="text-align:center;">
SSH
</td>
<td style="text-align:center;">
0.064 ( 0.039,0.089)
</td>
<td style="text-align:center;">
0.165 ( 0.051,0.281)
</td>
<td style="text-align:center;">
0.097 ( 0.050,0.144)
</td>
<td style="text-align:center;">
0.240 ( 0.204,0.274)
</td>
<td style="text-align:center;">
0.068 (-0.047,0.181)
</td>
<td style="text-align:center;">
0.165 ( 0.051,0.281)
</td>
<td style="text-align:center;">
0.006 ( 0.003,0.011)
</td>
</tr>
</tbody>
</table>
</div>
<div id="sensitivity-analyses" class="section level2">
<h2>Sensitivity analyses</h2>
<p>Scripts for sensitivity analyses are part of the model scripts above. This section will only show results from sensitivity analyses.</p>
<pre class="r"><code>options(knitr.kable.NA = &#39;&#39;)
SA_results=xlsx::read.xlsx(&quot;/Users/kai/OneDrive - King&#39;s College London/PhD/MR_DOC/Results/MR_DoC_results_27_April_2021.xlsx&quot;, sheetName = &quot;fixed_rE_data2&quot;)

kableExtra::kable(SA_results,digits=3,align=&quot;c&quot;)%&gt;%
  kableExtra::kable_styling(font_size = 12, full_width = TRUE)%&gt;%
  collapse_rows()</code></pre>
<table class="table" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Exposure
</th>
<th style="text-align:center;">
Outcome
</th>
<th style="text-align:center;">
Value.of.fixed.rE
</th>
<th style="text-align:center;">
AIC
</th>
<th style="text-align:center;">
estimated.g1..95.CI.
</th>
<th style="text-align:center;">
rE.estimated.in.fully.bivariate.model
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
cMFQ
</td>
<td style="text-align:center;">
NSSH
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
63865.96
</td>
<td style="text-align:center;">
0.194 ( 0.131,0.257)
</td>
<td style="text-align:center;">
0.203
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
63868.21
</td>
<td style="text-align:center;">
0.148 ( 0.084,0.211)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
63868.49
</td>
<td style="text-align:center;">
0.102 ( 0.038,0.165)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
63868.79
</td>
<td style="text-align:center;">
0.054 (-0.010,0.119)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
63869.10
</td>
<td style="text-align:center;">
0.006 (-0.059,0.071)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.25
</td>
<td style="text-align:center;">
63869.44
</td>
<td style="text-align:center;">
-0.043 (-0.110,0.022)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
SSH
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
57845.23
</td>
<td style="text-align:center;">
0.210 ( 0.125,0.295)
</td>
<td style="text-align:center;">
0.206
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
57847.30
</td>
<td style="text-align:center;">
0.161 ( 0.075,0.246)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
57847.40
</td>
<td style="text-align:center;">
0.111 ( 0.025,0.197)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
57847.51
</td>
<td style="text-align:center;">
0.061 (-0.027,0.147)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
57847.65
</td>
<td style="text-align:center;">
0.009 (-0.080,0.097)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.25
</td>
<td style="text-align:center;">
57847.81
</td>
<td style="text-align:center;">
-0.044 (-0.135,0.045)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
pMFQ
</td>
<td style="text-align:center;">
NSSH
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
80198.68
</td>
<td style="text-align:center;">
0.092 ( 0.004,0.181)
</td>
<td style="text-align:center;">
0.070
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
80201.07
</td>
<td style="text-align:center;">
0.032 (-0.057,0.121)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
80201.51
</td>
<td style="text-align:center;">
-0.028 (-0.117,0.06)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
80201.98
</td>
<td style="text-align:center;">
-0.090 (-0.179,0)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
80202.48
</td>
<td style="text-align:center;">
-0.152 (-0.243,-0.062)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.25
</td>
<td style="text-align:center;">
80203.02
</td>
<td style="text-align:center;">
-0.217 (-0.309,-0.126)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
SSH
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
74019.07
</td>
<td style="text-align:center;">
0.165 ( 0.051,0.281)
</td>
<td style="text-align:center;">
0.122
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
74021.34
</td>
<td style="text-align:center;">
0.102 (-0.013,0.217)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
74021.65
</td>
<td style="text-align:center;">
0.038 (-0.078,0.153)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
74021.99
</td>
<td style="text-align:center;">
-0.027 (-0.144,0.089)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
74022.37
</td>
<td style="text-align:center;">
-0.094 (-0.212,0.024)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.25
</td>
<td style="text-align:center;">
74022.77
</td>
<td style="text-align:center;">
-0.162 (-0.282,-0.043)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
pCONN
</td>
<td style="text-align:center;">
NSSH
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
63413.83
</td>
<td style="text-align:center;">
0.127 (-0.032,0.285)
</td>
<td style="text-align:center;">
0.064
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
63416.08
</td>
<td style="text-align:center;">
0.039 (-0.121,0.197)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
63416.48
</td>
<td style="text-align:center;">
-0.050 (-0.210,0.109)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
63417.03
</td>
<td style="text-align:center;">
-0.141 (-0.302,0.019)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
63417.72
</td>
<td style="text-align:center;">
-0.233 (-0.395,-0.072)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.25
</td>
<td style="text-align:center;">
63418.54
</td>
<td style="text-align:center;">
-0.329 (-0.493,-0.166)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
SSH
</td>
<td style="text-align:center;">
0.00
</td>
<td style="text-align:center;">
57226.27
</td>
<td style="text-align:center;">
0.187 (-0.028,0.402)
</td>
<td style="text-align:center;">
0.076
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
57228.85
</td>
<td style="text-align:center;">
0.093 (-0.122,0.309)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
57229.53
</td>
<td style="text-align:center;">
-0.002 (-0.218,0.215)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
57230.30
</td>
<td style="text-align:center;">
-0.098 (-0.316,0.119)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
57231.16
</td>
<td style="text-align:center;">
-0.197 (-0.417,0.022)
</td>
<td style="text-align:center;">
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
0.25
</td>
<td style="text-align:center;">
57232.10
</td>
<td style="text-align:center;">
-0.300 (-0.522,-0.079)
</td>
<td style="text-align:center;">
</td>
</tr>
</tbody>
</table>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
